[{"Abstract":"Background: Tertiary lymphoid structures (TLS) are vascularized lymphocyte aggregates in the tumor microenvironment (TME) that correlate with better patient outcomes. Previous studies identified a 12 chemokine gene expression signature associated with disease progression and the type and degree of TLS. These signatures could provide insight important for clinical decision making during pathologic evaluation, but predicting gene expression from whole slide images (WSI) may be impeded by low prediction accuracy and lack of interpretability. Here we report an artificial intelligence (AI)-based, state-of-the-art workflow to predict the 12-chemokine TLS gene signature from lung cancer WSI, and identify histological features relevant to model predictions.<br \/>Methods: Models were trained using 538 cases of paired lung cancer WSI and mRNA-seq expression data (The Cancer Genome Atlas). Cell and tissue classifiers, based on convolutional neural networks (CNN) were trained on WSI, and a graph neural network (GNN) model that leverages the relative spatial arrangement of the CNN-identified cells and tissues was used to predict gene expression. GNN predictions of TLS signature genes were compared with the predictions of models trained using hand-crafted, task-specific features (TLS feature models) describing the number, size, and cellular composition of identified TLS. The Pearson correlation coefficient was used to assess the accuracy of GNN and TLS feature model predictions. GNNExplainer1, a tool that simultaneously identifies a subgraph and a subset of node features important for predictions, was applied to interpret the GNN model predictions.<br \/>Results: GNN model predictions show reasonable accuracy: GNN models significantly predicted mRNA expression of all 12 genes (p&#60;0.05), and the predicted expression of six genes was moderately correlated with ground-truth measurements (Pearson-r&#62;0.5). The correlation of GNN predictions was higher than that of the TLS feature models for all 12 signature genes. The GNNExplainer identified relevant features including the mean and standard deviation of lymphocyte count, and fraction of lymphocytes in cancer stroma. Subgraphs selected by the GNNExplainer focus on, but extend beyond, regions of human-annotated TLS objects, indicating that TLS may influence gene expression and the TME in regions beyond their immediate vicinity.<br \/>Conclusion: Here, we show a comparison of two interpretable AI methods for the prediction of TLS-induced gene expression from WSI. The outperforming GNN-based approach is highly reproducible and accurate, predicting histopathology features relevant to TLS that may be used to inform patient prognosis and treatment. These methods could be applied to predict additional clinically relevant transcriptomic signatures. 1. &#8203;&#8203;Ying, R, et al. 2019. arXiv:1903.03894v4","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/da13f542-e8e9-4121-8fa9-c000a0437619\/@s03B8ZAH\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Tumor microenvironment,Machine learning,Tertiary lymphoid structures,Gene expression profiling,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14793"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Ciyue Shen<\/i><\/u><\/presenter>, <presenter><i>Collin Schlager<\/i><\/presenter>, <presenter><i>Deepta Rajan<\/i><\/presenter>, <presenter><i>Maryam Pouryahya<\/i><\/presenter>, <presenter><i>Mary Lin<\/i><\/presenter>, <presenter><i>Victoria Mountain<\/i><\/presenter>, <presenter><i>Ilan Wapinski<\/i><\/presenter>, <presenter><i>Amaro Taylor-Weiner<\/i><\/presenter>, <presenter><i>Benjamin Glass<\/i><\/presenter>, <presenter><i>Robert Egger<\/i><\/presenter>, <presenter><i>Andrew Beck<\/i><\/presenter>. PathAI, Boston, MA","CSlideId":"","ControlKey":"f6ba41eb-c21c-461a-8ab1-025f4bf21082","ControlNumber":"5414","DisclosureBlock":"<b>&nbsp;C. Shen, <\/b> <br><b>PathAI<\/b> Employment, No. <br><b>C. Schlager, <\/b> <br><b>PathAI<\/b> Employment, No. <br><b>D. Rajan, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>M. Pouryahya, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>M. Lin, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>V. Mountain, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>I. Wapinski, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>A. Taylor-Weiner, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>B. Glass, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>R. Egger, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>A. Beck, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14793","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/da13f542-e8e9-4121-8fa9-c000a0437619\/@s03B8ZAH\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"1","PosterboardNumber":"1","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1922","PresenterBiography":null,"PresenterDisplayName":"Judy Shen, BS","PresenterKey":"e281df24-3c9e-4655-b65b-db46c0b6e488","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1922. Application of an interpretable graph neural network to predict gene expression signatures associated with tertiary lymphoid structures in histopathological images","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Application of an interpretable graph neural network to predict gene expression signatures associated with tertiary lymphoid structures in histopathological images","Topics":null,"cSlideId":""},{"Abstract":"We present a new approach to predict overall survival (OS) in untested oncology trial designs, which does not require the use of clinical covariates. This approach is based on generating a virtual population from a quantitative systems pharmacology (QSP) model of cancer immunology, and linking this virtual population to real patients from previous clinical trials.<br \/>QSP has emerged as a dominant paradigm in recent years for investigating disease mechanisms and allowing prediction of drug effects <i>in silico<\/i>. However, survival cannot be described mechanistically and intrinsically predicted from a QSP model. We develop a weakly supervised learning approach to impute labels of OS and censorship in the virtual population. This approach requires prior matching of the virtual patients to real patients on the basis of longitudinal tumor growth curves. The idea that there exists a predictive relationship between tumor dynamics and OS was motivated by previous work on tumor growth inhibition (TGI-OS) [Claret, L. et al., J. Clin. Onc., 2013]. In contrast to the TGI-OS framework, we rely solely on simulated QSP dynamical variables for predicting survival. This allows us to derive OS predictions for trial designs different than the ones used for model development.<br \/>Data from 5 clinical trials for atezolizumab in NSCLC (BIRCH, FIR, OAK, POPLAR, and IMpower110, total N = 1641) were used to link survival labels to virtual patients. 90% of the data was used for training, and 10% was held out for model validation. The imputed OS labels were used to train a log-normal accelerated failure time model on the training data, and predictions of survival in the test data were in good agreement with a Kaplan-Meier estimate of the clinical survival. The model predicted a median OS of 471 days (95% CI 453-490) compared to the observed 475 days, (95% CI 440-517). The rate of change of tumor size under treatment in the QSP model was the most predictive feature of survival, with a hazard ratio of 1.79 between 95th percentile and median of the dynamical range (95% CI 1.69-1.81). Model variables related to tumor antigens, cytotoxic cell death, and T cell dynamics were also relevant to the prediction of survival.<br \/>This work provides the first example of generating and validating predictions of OS without using covariates from actual clinical trials. We intend to expand this methodology across different trial designs and different subpopulations. For example, our approach could be used to estimate hazard ratios between different treatments or combination therapies, as well as for patients grouped by PDL1 expression or by line of therapy. While this work only considered overall survival as an endpoint, our approach can potentially be extended to endpoints like progression-free-survival.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/dd941569-eb75-4a50-a0bf-c177f5281bc2\/@s03B8ZAH\/vod?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Survival,Cancer immunotherapy,Machine learning,Systems biology,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14794"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Matthew West<\/i><\/u><\/presenter>, <presenter><i>Kenta Yoshida<\/i><\/presenter>, <presenter><i>Jiajie Yu<\/i><\/presenter>, <presenter><i>Vincent Lemaire<\/i><\/presenter>. Genentech, South San Francisco, CA","CSlideId":"","ControlKey":"c1697880-3781-4124-8950-094fce0c782a","ControlNumber":"2822","DisclosureBlock":"<b>&nbsp;M. West, <\/b> <br><b>Genentech<\/b> Employment, Yes. <br><b>K. Yoshida, <\/b> <br><b>Genentech<\/b> Employment, Yes. <br><b>J. Yu, <\/b> <br><b>Genentech<\/b> Employment, Yes. <br><b>V. Lemaire, <\/b> <br><b>Genentech<\/b> Employment, Yes.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14794","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/dd941569-eb75-4a50-a0bf-c177f5281bc2\/@s03B8ZAH\/vod?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"2","PosterboardNumber":"2","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1923","PresenterBiography":null,"PresenterDisplayName":"Matthew West","PresenterKey":"ad72c468-8c91-45f0-b22d-1d4cba99ac46","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1923. A treatment-agnostic approach to predict patient survival from virtual clinical trials","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A treatment-agnostic approach to predict patient survival from virtual clinical trials","Topics":null,"cSlideId":""},{"Abstract":"The need for developing new biomarkers is increasing with the emergence of many targeted therapies. In this study, we used artificial intelligence (AI) to develop a multimodal model (PULS-AI) predicting the survival of solid tumor patients treated with antiangiogenic treatments.<br \/>Our retrospective, multicentric study included 616 patients with 7 different cancer types: renal cell carcinoma, colorectal carcinoma, hepatocellular carcinoma, gastrointestinal carcinoma, melanoma, breast cancer, and sarcoma. A set of 196 patients was left out of the study for validation. Clinical data including patient, treatment, and cancer metadata were collected at baseline for all patients, as well as computed tomography (CT) and ultrasound (US) images. Radiologists annotated all metastases on the CT images and the visible tumor lesion on the US images. AI models were used to extract relevant features from the regions of interest on CT and US images. In addition, handcrafted features related to the tumor burden were extracted from the annotations of all lesions on CT such as the number of lesions and the tumor burden volume per organ (lungs, liver, skull, bone, other). Finally, a Cox regression model was fitted to the set of imaging features and clinical features.<br \/>The annotation process led to 1147 annotated US images with lesions delineation and 4564 reviewed CTs, of which 989 were selected and fully annotated with a total of 9516 annotated lesions.The developed model reaches an average concordance index of 0.71 (0.67-0.75, 95% CI). Using a risk threshold of 50%, PULS-AI model is able to significantly isolate (log-rank test P-value &#60; 0.001) high-risk patients from low-risk patients (respective median OS of 12 and 32 months) with a hazard ratio of 3.52 (2.35-5.28, 95% CI).<br \/>The results of this study show that AI algorithms are able to extract relevant information from radiology images and to aggregate data from multiple modalities to build powerful prognostic tools. Such tools may provide assistance to oncology clinicians in therapeutic decision-making.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/08991fcc-4bcd-43cc-9cc3-b4b20e7722ca\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Prognosis,Imaging,Antiangiogenic therapy,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14795"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Kathryn Schutte<\/i><\/u><\/presenter>, <presenter><i>Fabien Brulport<\/i><\/presenter>, <presenter><i>Sana Harguem-Zayani<\/i><\/presenter>, <presenter><i>Jean-Baptiste Schiratti<\/i><\/presenter>, <presenter><i>Ridouane Ghermi<\/i><\/presenter>, <presenter><i>Paul Jehanno<\/i><\/presenter>, <presenter><i>Alexandre Jaeger<\/i><\/presenter>, <presenter><i>Talal Alamri<\/i><\/presenter>, <presenter><i>Raphael Naccache<\/i><\/presenter>, <presenter><i>Leila Haddag-Miliani<\/i><\/presenter>, <presenter><i>Teresa Orsi<\/i><\/presenter>, <presenter><i>Jean-Philippe Lamarque<\/i><\/presenter>, <presenter><i>Isaline Hoferer<\/i><\/presenter>, <presenter><i>Littisha Lawrance<\/i><\/presenter>, <presenter><i>Baya Benatsou<\/i><\/presenter>, <presenter><i>Imad Bousaid<\/i><\/presenter>, <presenter><i>Mickael Azoulay<\/i><\/presenter>, <presenter><i>Antoine Verdon<\/i><\/presenter>, <presenter><i>François Bidault<\/i><\/presenter>, <presenter><i>Corinne Balleyguier<\/i><\/presenter>, <presenter><i>Victor Aubert<\/i><\/presenter>, <presenter><i>Etienne Bendjebbar<\/i><\/presenter>, <presenter><i>Charles Maussion<\/i><\/presenter>, <presenter><i>Nicolas Loiseau<\/i><\/presenter>, <presenter><i>Benoit Schmauch<\/i><\/presenter>, <presenter><i>Meriem Sefta<\/i><\/presenter>, <presenter><i>Gilles Wainrib<\/i><\/presenter>, <presenter><i>Thomas Clozel<\/i><\/presenter>, <presenter><i>Samy Ammari<\/i><\/presenter>, <presenter><i>Nathalie Lassau<\/i><\/presenter>. Owkin, New York, NY, Gustave Roussy, Villejuif, France, Calypse Consulting, Paris, France, Gustave Roussy, Villejuif, France","CSlideId":"","ControlKey":"634b50ba-77bd-4dbc-956b-0a2e8b71472a","ControlNumber":"2605","DisclosureBlock":"<b>&nbsp;K. Schutte, <\/b> <br><b>Owkin<\/b> Employment, Yes. <br><b>F. Brulport, <\/b> <br><b>Owkin<\/b> Employment.<br><b>S. Harguem-Zayani, <\/b> None.&nbsp;<br><b>J. Schiratti, <\/b> <br><b>Owkin<\/b> Employment. <br><b>R. Ghermi, <\/b> <br><b>Owkin<\/b> Employment. <br><b>P. Jehanno, <\/b> <br><b>Owkin<\/b> Employment.<br><b>A. Jaeger, <\/b> None..<br><b>T. Alamri, <\/b> None..<br><b>R. Naccache, <\/b> None..<br><b>L. Haddag-Miliani, <\/b> None..<br><b>T. Orsi, <\/b> None..<br><b>J. Lamarque, <\/b> None..<br><b>I. Hoferer, <\/b> None..<br><b>L. Lawrance, <\/b> None..<br><b>B. Benatsou, <\/b> None..<br><b>I. Bousaid, <\/b> None..<br><b>M. Azoulay, <\/b> None..<br><b>A. Verdon, <\/b> None..<br><b>F. Bidault, <\/b> None..<br><b>C. Balleyguier, <\/b> None.&nbsp;<br><b>V. Aubert, <\/b> <br><b>Owkin<\/b> Employment. <br><b>E. Bendjebbar, <\/b> <br><b>Owkin<\/b> Employment. <br><b>C. Maussion, <\/b> <br><b>Owkin<\/b> Employment. <br><b>N. Loiseau, <\/b> <br><b>Owkin<\/b> Employment. <br><b>B. Schmauch, <\/b> <br><b>Owkin<\/b> Employment. <br><b>M. Sefta, <\/b> <br><b>Owkin<\/b> Employment. <br><b>G. Wainrib, <\/b> <br><b>Owkin<\/b> Employment. <br><b>T. Clozel, <\/b> <br><b>Owkin<\/b> Employment.<br><b>S. Ammari, <\/b> None.&nbsp;<br><b>N. Lassau, <\/b> <br><b>Jazz Pharmaceuticals<\/b> Independent Contractor. <br><b>Guerbet<\/b> Grant\/Contract.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14795","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/08991fcc-4bcd-43cc-9cc3-b4b20e7722ca\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"3","PosterboardNumber":"3","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1924","PresenterBiography":null,"PresenterDisplayName":"Kathryn Schutte","PresenterKey":"ed20c238-0d0a-473a-9cad-2799a0022359","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1924. PULS-AI: A multimodal artificial intelligence model to predict survival of solid tumor patients treated with antiangiogenics","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"PULS-AI: A multimodal artificial intelligence model to predict survival of solid tumor patients treated with antiangiogenics","Topics":null,"cSlideId":""},{"Abstract":"Objective: Discrimination of ovarian tumors is a necessary procedure for proper treatment. In this study, we developed a convolutional neural network model with a convolutional autoencoder (CNN-CAE) to classify ovarian tumors.<br \/>Methods: A total of 1,613 ultrasound images of ovarian tumors with the known pathologic diagnosis were pre-processed and augmented for deep learning analysis. We designed the CNN-CAE model that removes the unnecessary information on ultrasound images (e.g. calipers and annotations) and classifies ovarian tumors into five classes. We assessed the CNN-CAE model performance using a validation set of 327 images with the following metrics: accuracy, sensitivity, specificity, and the area under the receiver operating characteristic curve (AUC). Gradient-weighted class activation mapping (Grad-CAM) was applied to visualize and verify the CNN-CAE model results qualitatively.<br \/>Results: In classifying normal versus ovarian tumors, the CNN-CAE model showed 96.0% accuracy, 96.5% sensitivity, and 0.9837 AUC with DenseNet161 CNN architecture. In determining malignancy of ovarian tumors, the CNN-CAE model showed 86.85% accuracy, 75.68% sensitivity, and 0.9225 AUC with DenseNet121 CNN architecture. The Grad-CAM results show that the CNN-CAE model finds valid texture and morphology features from the ultrasound images and classifies ovarian tumors from these features.<br \/>Conclusion: CNN-CAE is a feasible diagnostic tool that is capable of robustly classifying ovarian tumors by eliminating marks on ultrasound images. CNN-CAE demonstrates a significant application value in clinical conditions.<b><\/b>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Ovarian cancer,Machine learning,Ultrasound,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14796"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Youn Jin Choi<\/i><\/u><\/presenter>, <presenter><i>Yuyeon Jung<\/i><\/presenter>. Seoul St. Mary's Hospital, Seoul, Korea, Republic of, Catholic University of Medical College, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"7d855110-8a6b-445c-8a3f-22378142f171","ControlNumber":"6625","DisclosureBlock":"&nbsp;<b>Y. Choi, <\/b> None..<br><b>Y. Jung, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14796","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"4","PosterboardNumber":"4","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1925","PresenterBiography":null,"PresenterDisplayName":"Youn Jin Choi, MD;PhD","PresenterKey":"c648a09b-3a56-44ee-8b9d-d10c5d460bc6","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1925. Ovarian tumor diagnosis using deep convolutional neural networks and denoising convolutional autoencoder","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Ovarian tumor diagnosis using deep convolutional neural networks and denoising convolutional autoencoder","Topics":null,"cSlideId":""},{"Abstract":"<b>Introduction:<\/b> High dimensional imaging approaches such as imaging mass cytometry (IMC) are becoming widely used in cancer research. Such methods allow simultaneous observation of many cell types and their functional states and can provide valuable spatial information on cancer disease states when applied to clinical tissue samples. For example, in-situ immune and tumor cell interactions can be interrogated in their spatial context within the tumor microenvironment (TME). Analysis methods for the resultant complex data are not well formalized, and bespoke methods are usually required to fully capitalize on the underlying richness of information made available by IMC. Deep learning [DL] approaches, while highly accurate for other imaging modalities, have been slow to be adopted in IMC, as public resources for deep learning tasks in IMC are not abundant.<br \/><b>Methods: <\/b>We developed multiple DL and ML-based analysis pipelines for the following tasks in IMC data processing: [1] nucleus and necrotic tissue segmentation, [2] quantitative nuclear and cellular morphometry, [3] identification of cell type-specific niches. We applied these protocols to images and derived single cell spatial data from the TRACERx IMC cohort (n=81 non-small cell lung cancer patients, 561 images).<br \/><b>Results:<\/b> [1] We created a 120 image, 46,000+ labelled nucleus segmentation dataset for IMC data with representative images from lung adenocarcinoma, squamous cell carcinoma and other tissues. We achieved state-of-the-art performance in nuclear instance segmentation using a custom U-net++ neural network architecture trained using this dataset, which we benchmarked against traditional image processing methods, as well as publicly available deep learning architectures. Subsequently, we exploited transfer learning to retrain this model on a restricted dataset of labelled necrotic domains, which produced predictions in good agreement with independent pathologist assessment. [2] We developed an IMC morphometry pipeline utilizing ML-informed partitions of nuclear and cellular shape descriptors through which we performed cell-type specific morphometric characterization of all mapped cells in the non-small cell lung cancer TME, and which enabled a comparative analysis of the morphometries of each distinct cellular phenotype. [3] We established a high throughput density-based spatial clustering pipeline capable of identifying locally enriched niches of a given cell type of interest, as well as probing the composition and phenotypes of other cells within these niches.<br \/><b>Conclusions:<\/b> These approaches enhanced the quality as well as the breadth of spatial information derivable from TRACERx IMC data. Applying such tools to other clinical and pre-clinical datasets can improve our understanding of the spatial organization of cells both in non-small cell lung cancer and other cancer types.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/5e32ef89-d51b-46c0-ac26-599fd5101b80\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Image analysis,Deep learning,Imaging mass cytometry,Tumor microenvironment,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14797"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Alastair Magness<\/i><\/u><\/presenter>, <presenter><i>Katey Enfield<\/i><\/presenter>, <presenter><i>Mihaela Angelova<\/i><\/presenter>, <presenter><i>Emma Colliver<\/i><\/presenter>, <presenter><i>Emer Daly<\/i><\/presenter>, <presenter><i>Kristiana Grigoriadis<\/i><\/presenter>, <presenter><i>Claudia Lee<\/i><\/presenter>, <presenter><i>Oriol Pich<\/i><\/presenter>, <presenter><i>Philip Hobson<\/i><\/presenter>, <presenter><i>Dina Levi<\/i><\/presenter>, <presenter><i>Takahiro Karasaki<\/i><\/presenter>, <presenter><i>David Moore<\/i><\/presenter>, <presenter><i>Julian Downward<\/i><\/presenter>, <presenter><i>Erik Sahai<\/i><\/presenter>, <presenter><i>Mariam Jamal-Hanjani<\/i><\/presenter>, <presenter><i>Charles Swanton<\/i><\/presenter>, <presenter><i>TRACERx Consortium<\/i><\/presenter>. The Francis Crick Institute, London, United Kingdom, University College London Cancer Institute, London, United Kingdom, University College London, London, United Kingdom","CSlideId":"","ControlKey":"3401b233-d84c-4342-a23d-31e845f874f8","ControlNumber":"2297","DisclosureBlock":"<b>&nbsp;A. Magness, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Yes. <br><b>K. Enfield, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Yes. <br><b>M. Angelova, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract. <br><b>E. Colliver, <\/b> <br><b>Bristol Myers Squibb<\/b> Yes.<br><b>E. Daly, <\/b> None.&nbsp;<br><b>K. Grigoriadis, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Yes. <br><b>C. Lee, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Yes.<br><b>O. Pich, <\/b> None..<br><b>P. Hobson, <\/b> None.&nbsp;<br><b>D. Levi, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Yes.<br><b>T. Karasaki, <\/b> None.&nbsp;<br><b>D. Moore, <\/b> <br><b>AstraZeneca<\/b> Other, Consultancy & speaker fees, No. <br><b>Eli Lily<\/b> Other, Consultancy fees, No. <br><b>Thermo Fisher<\/b> Consultancy fees, No. <br><b>J. Downward, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, No. <br><b>Revolution Medicines<\/b> Grant\/Contract, No. <br><b>Jubilant<\/b> Other, Consultancy, No. <br><b>Theras<\/b> Other, Consultancy. <br><b>BridgeBio<\/b> Other, Consultancy, No. <br><b>Vividion<\/b> Other, Consultancy, No. <br><b>E. Sahai, <\/b> <br><b>Phenomic<\/b> Other, Scientific advisory board member, No. <br><b>AstraZeneca<\/b> Grant\/Contract. <br><b>MSD<\/b> Grant\/Contract, No. <br><b>GSK<\/b> Grant\/Contract, No. <br><b>M. Jamal-Hanjani, <\/b> <br><b>Achilles Therapeutics<\/b> Other, Scientific advisory board member, No. <br><b>C. Swanton, <\/b> <br><b>Pfizer<\/b> Grant\/Contract, Other, Consultancy, No. <br><b>AstraZeneca<\/b> Grant\/Contract, Other, Advisory Board Member; Chief Investigator for the MeRmaiD1 clinical trial, No. <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Other, Consultancy, Yes. <br><b>Roche-Ventana<\/b> Grant\/Contract, Other, Consultancy, No. <br><b>Boehringer-Ingelheim<\/b> Grant\/Contract, No. <br><b>Archer Dx Inc<\/b> Grant\/Contract, Other, Collaboration in minimal residual disease sequencing technologies, No. <br><b>Ono Pharmaceutical<\/b> Grant\/Contract, No. <br><b>Amgen<\/b> Other, Consultancy, No. <br><b>Novartis<\/b> Other, Consultancy, No. <br><b>GlaxoSmithKline<\/b> Other, Consultancy, No. <br><b>MSD<\/b> Other, Consultancy, No. <br><b>Illumina<\/b> Other, Consultancy, No. <br><b>Genentech<\/b> Other, Consultancy, No. <br><b>GRAIL<\/b> Stock Option, Other, Consultancy, No. <br><b>Medicxi<\/b> Other, Consultancy, No. <br><b>Bicycle Therapeutics<\/b> Other, Consultancy, No. <br><b>Metabomed<\/b> Other, Consultancy, No. <br><b>Achilles Therapeutics<\/b> Stock Option, Other, Co-founder, No. <br><b>Apogen Biotechnologies<\/b> Stock Option. <br><b>Epic Bioscience<\/b> Stock Option, No.<br><b>T. Consortium, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14797","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/5e32ef89-d51b-46c0-ac26-599fd5101b80\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"5","PosterboardNumber":"5","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1926","PresenterBiography":null,"PresenterDisplayName":"Alastair Magness, PhD","PresenterKey":"666aa7c7-327b-42e5-8b02-afb2bcefd4d2","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1926. Machine learning-enhanced image and spatial analytic pipelines for imaging mass cytometry applied to the TRACERx non-small cell lung cancer study","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Machine learning-enhanced image and spatial analytic pipelines for imaging mass cytometry applied to the TRACERx non-small cell lung cancer study","Topics":null,"cSlideId":""},{"Abstract":"Gene expression profiling of new or modified cell lines becomes routine today; however, obtaining comprehensive molecular characterization and cellular responses for a variety of cell lines, including those derived from underrepresented groups, is not trivial when resources are minimal. Using gene expression to predict other measurements has been actively explored; however, systematic investigation of its predictive power in various measurements has not been well studied. We present TransCell, a two-step deep transfer learning framework that utilizes the knowledge derived from pan-cancer tumor samples to predict molecular features and responses. Compared to the five state-of-art methods, TransCell has the best performance in predicting metabolite, gene effect score (or genetic dependency), and drug sensitivity, and has comparable performance in predicting mutation, copy number variation, and protein expression. Notably, TransCell improved the performance by over 50% in drug sensitivity prediction and achieved a correlation of 0.7 in gene effect score prediction. Furthermore, predicted drug sensitivities revealed potential repurposing candidates for new 100 pediatric cancer cell lines, and predicted gene effect scores reflected BRAF resistance in melanoma cell lines. Together, TransCell demonstrates its remarkable predictive power that enables in silico molecular characterization of understudied cell lines.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/840438ad-4c50-4ea2-acbc-6036929b67ca\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Drug sensitivity,Gene profiling,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14798"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Shan-Ju Yeh<\/i><\/presenter>, <presenter><i>Ruoqiao Chen<\/i><\/presenter>, <presenter><i>Jing Xing<\/i><\/presenter>, <presenter><i>Mengying Sun<\/i><\/presenter>, <presenter><i>Ke Liu<\/i><\/presenter>, <presenter><i>Shreya Paithankar<\/i><\/presenter>, <presenter><i>Jiayu Zhou<\/i><\/presenter>, <presenter><u><i>Bin Chen<\/i><\/u><\/presenter>. Michigan State University, Grand Rapids, MI, Michigan State University, East Lansing, MI","CSlideId":"","ControlKey":"9ee5cd09-12e6-48ce-b9f9-34c17c93a081","ControlNumber":"4602","DisclosureBlock":"&nbsp;<b>S. Yeh, <\/b> None..<br><b>R. Chen, <\/b> None..<br><b>J. Xing, <\/b> None..<br><b>M. Sun, <\/b> None..<br><b>K. Liu, <\/b> None..<br><b>S. Paithankar, <\/b> None..<br><b>J. Zhou, <\/b> None..<br><b>B. Chen, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14798","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/840438ad-4c50-4ea2-acbc-6036929b67ca\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"6","PosterboardNumber":"6","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1927","PresenterBiography":null,"PresenterDisplayName":"Bin Chen, PhD","PresenterKey":"d66ed95d-3f83-4085-bcdd-a94335cc879a","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1927. Transcell: In silico characterization of genomic landscape and cellular responses from gene expressions through a two-step transfer learning","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Transcell: In silico characterization of genomic landscape and cellular responses from gene expressions through a two-step transfer learning","Topics":null,"cSlideId":""},{"Abstract":"Neoadjuvant chemotherapy (NAC) is the standard of care for selected patients with high-risk early-stage breast cancer with pathologic complete response (pCR) being the most prominent predictor of favorable outcomes. Here, we sought to study the predictive capacity of integrating orthogonal diagnostic measures on predicting pCR relative to standard clinicopathologic features.<br \/>We developed a computational model integrating radiology and pathology images, and tumor genomics to automatically predict pCR from multimodal data. We present an interim analysis on a cohort of 957 patients with at least one available pre-NAC data modality. The baseline AUC for pCR prediction by a trained and tested logistic regression model on 857 patients using standard clinicopathologic features including receptor subtype, demographic information, and stage was 0.77. MR images were input into a convolutional neural network (CNN) and a radiomics model.<br \/>The trained CNN and radiomics models using selected images of 576 patients with pre-NAC MR images achieved AUCs of 0.65 and 0.60 on 164 hold-out test cases, respectively.<br \/>We trained a multiple instance learning-based weakly supervised learning (MIL-WSL) model using 537,762 extracted tiles from whole slide images (WSI) of digital histopathology scans from 522 patients. The MIL-WSL model achieved AUC of 0.63 for pCR prediction on a hold-out test set of pre-NAC biopsies from 239 patients. A feature based classifier trained on 76 cases using tumor genomic features such as mutational burden, microsatellite instability, fraction genome altered, ploidy, purity, mutation and copy number alterations in selected genes achieved an AUC of 0.72 on 83 hold-out test cases.<br \/>We then combined unimodal radiology, histopathology, and genomic predictions in a deterministic manner. This multimodal combination on an independent 68-patient test set achieved an AUC of 0.84, indicating increased power to resolve pCR than any modality alone, and over clinicopathologic baseline.<br \/>Together, we present approaches to train models end-to-end using tensor fusion networks and attention-gating combined with MIL. Automated multimodal methods are here shown to improve prediction over established clinical parameters alone, motivating our ongoing efforts to refine and improve the model so as to achieve higher levels of efficiency. We anticipate these interim results will be further improved through refinement of input features and increasing the number of patients included in the final validation cohort.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f77ef331-47d7-4036-8197-8c0973358982\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,Machine learning,Bioinformatics,Predictive biomarkers,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14799"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Pegah Khosravi<\/i><\/u><\/presenter>, <presenter><i>Elizabeth J. Sutton<\/i><\/presenter>, <presenter><i>Justin Jee<\/i><\/presenter>, <presenter><i>Timothy Dalfonso<\/i><\/presenter>, <presenter><i>Christopher J. Fong<\/i><\/presenter>, <presenter><i>Doori Rose<\/i><\/presenter>, <presenter><i>Edaise M. Da Silva<\/i><\/presenter>, <presenter><i>Armaan Kohli<\/i><\/presenter>, <presenter><i>David Joon Ho<\/i><\/presenter>, <presenter><i>Mehnaj S. Ahmed<\/i><\/presenter>, <presenter><i>Danny Martinez<\/i><\/presenter>, <presenter><i>Anika Begum<\/i><\/presenter>, <presenter><i>Elizabeth Zakszewski<\/i><\/presenter>, <presenter><i>Andrew Aukerman<\/i><\/presenter>, <presenter><i>Yanis Tazi<\/i><\/presenter>, <presenter><i>Katja Pinker-Domenig<\/i><\/presenter>, <presenter><i>Sarah Eskreis-Winkler<\/i><\/presenter>, <presenter><i>Atif J. Khan<\/i><\/presenter>, <presenter><i>Edi Brogi<\/i><\/presenter>, <presenter><i>Elizabeth Morris<\/i><\/presenter>, <presenter><i>Sarat Chandarlapaty<\/i><\/presenter>, <presenter><i>George Plitas<\/i><\/presenter>, <presenter><i>Simon Powell<\/i><\/presenter>, <presenter><i>Monica Morrow<\/i><\/presenter>, <presenter><i>Larry Norton<\/i><\/presenter>, <presenter><i>Jianjiong Gao<\/i><\/presenter>, <presenter><i>Mark Robson<\/i><\/presenter>, <presenter><i>Hong Zhang<\/i><\/presenter>, <presenter><i>Sohrab Shah<\/i><\/presenter>, <presenter><i>Pedram Razavi<\/i><\/presenter>, MSK-MIND Consortium. Memorial Sloan Kettering Cancer Center, New York, NY, University of California, Davis, Davis, CA","CSlideId":"","ControlKey":"35d68755-2f6d-4d9b-9c24-39e59f214469","ControlNumber":"6086","DisclosureBlock":"&nbsp;<b>P. Khosravi, <\/b> None..<br><b>E. J. Sutton, <\/b> None.&nbsp;<br><b>J. Jee, <\/b> <br><b>MDSeq Inc<\/b> Other Intellectual Property.<br><b>T. Dalfonso, <\/b> None..<br><b>C. J. Fong, <\/b> None..<br><b>D. Rose, <\/b> None..<br><b>E. M. Da Silva, <\/b> None..<br><b>A. Kohli, <\/b> None.&nbsp;<br><b>D. Joon Ho, <\/b> <br><b>Paige<\/b> Other Intellectual Property.<br><b>M. S. Ahmed, <\/b> None..<br><b>D. Martinez, <\/b> None..<br><b>A. Begum, <\/b> None..<br><b>E. Zakszewski, <\/b> None..<br><b>A. Aukerman, <\/b> None..<br><b>Y. Tazi, <\/b> None.&nbsp;<br><b>K. Pinker-Domenig, <\/b> <br><b>AURA Health Technologies GmbH<\/b> Independent Contractor, No. <br><b>European Society of Breast Imaging<\/b> Independent Contractor, No. <br><b>MX Healthcare GmbH<\/b> Independent Contractor, No. <br><b>Siemens Healthineers<\/b> Independent Contractor, No.<br><b>S. Eskreis-Winkler, <\/b> None.&nbsp;<br><b>A. J. Khan, <\/b> <br><b>Biohaven Pharmaceuticals<\/b> Other Intellectual Property, No. <br><b>Xtrava<\/b> Stock, Stock Option, No. <br><b>Novavax<\/b> Stock, Stock Option, No. <br><b>Merck<\/b> Grant\/Contract, No. <br><b>Clovis<\/b> Grant\/Contract, No.<br><b>E. Brogi, <\/b> None..<br><b>E. Morris, <\/b> None.&nbsp;<br><b>S. Chandarlapaty, <\/b> <br><b>Breast Cancer Research Foundation<\/b> Independent Contractor, No. <br><b>Eli Lilly<\/b> Independent Contractor, No. <br><b>National Comprehensive Cancer Network<\/b> Independent Contractor, No. <br><b>Novartis<\/b> Independent Contractor, No. <br><b>Inivata<\/b> Independent Contractor, No. <br><b>Sanofi<\/b> Independent Contractor, No. <br><b>Targeted Oncology<\/b> Independent Contractor, No. <br><b>AstraZeneca<\/b> Independent Contractor. <br><b>G. Plitas, <\/b> <br><b>Merck<\/b> Independent Contractor, No. <br><b>Takeda Pharmaceuticals<\/b> Independent Contractor, Other Intellectual Property, No. <br><b>Tizona Therapeutics<\/b> Independent Contractor, No. <br><b>Trishula Therapeutics<\/b> Independent Contractor. <br><b>S. Powell, <\/b> <br><b>Artios Pharam Limited<\/b> Independent Contractor, No. <br><b>AstraZeneca<\/b> Independent Contractor, No. <br><b>Elekta<\/b> Independent Contractor, No. <br><b>PharmaPier US LLC<\/b> Independent Contractor, No. <br><b>Rain Therapeutics Inc.<\/b> Independent Contractor, No. <br><b>Varian Medical Systems<\/b> Independent Contractor, No. <br><b>M. Morrow, <\/b> <br><b>Roche<\/b> Independent Contractor.<br><b>L. Norton, <\/b> None..<br><b>J. Gao, <\/b> None.&nbsp;<br><b>M. Robson, <\/b> <br><b>Artios Pharam Limited<\/b> Independent Contractor, No. <br><b>AstraZeneca<\/b> Independent Contractor, No. <br><b>Change Healthcare Inc<\/b> Independent Contractor, No. <br><b>Clinical Education Alliance, LLC<\/b> Independent Contractor, No. <br><b>Genome Quebec<\/b> Independent Contractor, No. <br><b>MJH Associates<\/b> Independent Contractor, No. <br><b>Physicians' Education Resource<\/b> Independent Contractor, No. <br><b>Pfizer<\/b> Independent Contractor, No. <br><b>myMedEd, Inc<\/b> Independent Contractor.<br><b>H. Zhang, <\/b> None.&nbsp;<br><b>S. Shah, <\/b> <br><b>Canexia Health, Inc<\/b> Stock, Stock Option, Other Intellectual Property, No. <br><b>P. Razavi, <\/b> <br><b>Novartis<\/b> Independent Contractor, Grant\/Contract, No. <br><b>AstraZeneca<\/b> Independent Contractor, Grant\/Contract, No. <br><b>Grail\/Illumina<\/b> Grant\/Contract, No. <br><b>Epic Sciences<\/b> Independent Contractor, Grant\/Contract, No. <br><b>ArhcerDx\/Invitae<\/b> Grant\/Contract, No. <br><b>Tempus<\/b> Independent Contractor, Grant\/Contract, No. <br><b>Foundation Medicine<\/b> Independent Contractor, No. <br><b>Natera<\/b> Independent Contractor, No. <br><b>Biovica<\/b> Independent Contractor, No. <br><b>Pfizer<\/b> Independent Contractor, No.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14799","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f77ef331-47d7-4036-8197-8c0973358982\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"7","PosterboardNumber":"7","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1928","PresenterBiography":null,"PresenterDisplayName":"Pegah Khosravi, PhD","PresenterKey":"4cb9f91e-f720-44b1-bbea-58aeec83ed09","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1928. Prediction of neoadjuvant treatment outcomes with multimodal data integration in breast cancer","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Prediction of neoadjuvant treatment outcomes with multimodal data integration in breast cancer","Topics":null,"cSlideId":""},{"Abstract":"<b>Background<\/b>: It has been widely established that breast density is an independent breast cancer risk factor. With the increasing utilization of digital breast tomosynthesis (DBT) in breast cancer screening, there is an opportunity to estimate volumetric breast density (VBD) routinely. However, current available methods extrapolate VBD from 2D images acquired with DBT and\/or depend on the existence of raw DBT data which is rarely archived by clinical centers due to cost and storage constraints. This study aims to harness deep learning to develop a computational tool for VBD assessment based solely on 3D reconstructed, &#8220;for presentation&#8221; DBT images.<br \/><b>Methods<\/b>: We retrospectively analyzed 1,080 negative DBT screening exams (09\/20\/2011 - 11\/25\/2016) from the Hospital of the University of Pennsylvania (mean age &#177; SD, 57 &#177; 11 years; mean BMI &#177; SD, 28.7 &#177; 7.1 kg\/m2; racial makeup, 41.2% White, 54.2% Black, 4.6% Other), for which both 3D reconstructed and 2D raw DBT images (Selenia Dimensions, Hologic Inc) were available. All available standard views (left and right mediolateral-oblique and cranio-caudal views) were included for each exam, leading to 7,850 DBT views. Corresponding 3D reference-standard tissue segmentations were generated from a previously validated software that uses both 3D reconstructed slices and raw 2D DBT data to provide VBD metrics, shown to be strongly correlated with VBD measures from MRI image volumes. We based our deep learning algorithm on the U-Net architecture within the open-source Generally Nuanced Deep Learning Framework (GaNDLF) and created a 3-label image segmentation task (background, dense tissue, and fatty tissue). Our dataset was randomly split into training (70%), validation (15%) and test (15%) sets, while ensuring that all views of the same DBT exam were assigned to the same set. The performance of our deep learning algorithm against the corresponding reference-standard segmentations was measured in terms of Dice scores (DSC), with 0 signifying no overlap and 1 signifying perfect overlap, overall, as well as separately for each label.<br \/><b>Results<\/b>: After training was complete, our deep learning algorithm achieved a DSC of 0.78 on the validation, as well as on the test set. Our method accurately segmented background from breast tissue (DSC = 0.94) and demonstrated moderate to high performance in segmenting dense and fatty tissue, respectively (DSC = 0.49 and 0.89).<br \/><b>Conclusion<\/b>: Our preliminary analysis suggests that deep learning shows promise in the estimation of VBD using 3D DBT reconstructed, &#8220;for presentation&#8221; images. Future work involving transfer learning based on ground truth masks by clinical radiologists could further enhance this method&#8217;s performance. In view of rapid clinical conversion to DBT screening, such a tool has the potential to enable large retrospective epidemiologic and personalized risk assessment studies of breast density with DBT.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/097a60d9-7f5b-4224-bd40-e1ccf4b8c4ff\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast density,Deep learning,Mammographic density,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14801"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Vinayak S. Ahluwalia<\/i><\/u><\/presenter>, <presenter><i>Walter Mankowski<\/i><\/presenter>, <presenter><i>Sarthak Pati<\/i><\/presenter>, <presenter><i>Spyridon Bakas<\/i><\/presenter>, <presenter><i>Ari Brooks<\/i><\/presenter>, <presenter><i>Celine M. Vachon<\/i><\/presenter>, <presenter><i>Emily F. Conant<\/i><\/presenter>, <presenter><i>Aimilia Gastounioti<\/i><\/presenter>, <presenter><i>Despina Kontos<\/i><\/presenter>. Perelman School of Medicine at the University of Pennsylvania, Philadelphia, PA, University of Pennsylvania, Philadelphia, PA, Hospital of the University of Pennsylvania, Philadelphia, PA, Mayo Clinic, Rochester, MN, Hospital of the University of Pennsylvania, Philadelphia, PA, Washington University School of Medicine, St. Louis, MO","CSlideId":"","ControlKey":"94464895-92ce-441a-816f-4852a6316ee4","ControlNumber":"4039","DisclosureBlock":"&nbsp;<b>V. S. Ahluwalia, <\/b> None..<br><b>W. Mankowski, <\/b> None..<br><b>S. Pati, <\/b> None..<br><b>S. Bakas, <\/b> None..<br><b>A. Brooks, <\/b> None..<br><b>C. M. Vachon, <\/b> None.&nbsp;<br><b>E. F. Conant, <\/b> <br><b>iCAD, Inc.<\/b> Grant\/Contract, Advisory board member, No. <br><b>Hologic, Inc.<\/b> Grant\/Contract, Other, Advisory board member, No.<br><b>A. Gastounioti, <\/b> None..<br><b>D. Kontos, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14801","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/097a60d9-7f5b-4224-bd40-e1ccf4b8c4ff\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"8","PosterboardNumber":"8","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1929","PresenterBiography":null,"PresenterDisplayName":"Vinayak Ahluwalia","PresenterKey":"0a32d6d0-3256-426a-a8e3-22a0e319d5e3","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1929. Deep-learning-enabled volumetric breast density estimation with digital breast tomosynthesis","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Deep-learning-enabled volumetric breast density estimation with digital breast tomosynthesis","Topics":null,"cSlideId":""},{"Abstract":"Spatial context of heterocellular interactions within solid tumor microenvironments (TMEs) is important for deciphering the mechanistic underpinnings of malignant TME phenotypes and leveraging that knowledge to improve personalized and precision medicine. Recent development of highly multiplexed imaging approaches, such as co-detection by indexing (CODEX), cyclic immunofluorescence (cycif), and imaging mass cytometry (IMC) has, for the first time, allowed deep interrogation of this heterocellular spatial complexity. Proper quantitation of this complexity, however, requires the ability to easily and accurately segment and localize cells and their sub-cellular compartments within the spatial context of the tumor microenvironment. Seminal approaches based on semi-supervised and supervised learning methods, including deep learning techniques, have been developed to segment cells and their nuclei. However, generalization of these methods to segmenting heterogenous and complex cell and tissue samples with varying resolution, magnification, and dynamic range, remains a persistent bottleneck. In case of deep learning, the requirement of large and accurate annotated datasets further adds to the challenge of seamless integration of systems-based methods in pathology and cancer research. Here, we demonstrate that by leveraging cell-compartment specific a priori knowledge captured by these imaging modalities, we can segment cells in complex tissue and cell samples in an unsupervised manner, without requiring model training. We specifically show that using nucleus and cell-membrane markers, we can accurately segment sub-cellular compartments of a diversity of tissue samples imaged at different resolutions, magnifications and dynamic ranges, and cell samples at varying levels of confluency. We also demonstrate that our method is fast. Given its ease of use, accuracy, robustness, and no requirement of large, annotated datasets, our unsupervised segmentation method fills a much-needed gap toward integration of spatial systems biology and cancer research within the convergence science paradigm.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2b67e84a-a935-4812-86d4-d73bee9ee932\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Microenvironment,Single cell segmentation,Systems biology,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14802"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[{"FileType":"mp3","Icon":"far fa-file-audio","Label":"Audio","Reference":"ea98f0d0-df3d-4b68-8d2f-e0d6c08a8af8","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/ea98f0d0-df3d-4b68-8d2f-e0d6c08a8af8\/@t03B8ZAJ\/mp3"}],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Bogdan Kochetov<\/i><\/presenter>, <presenter><i>Phoenix D. Bell<\/i><\/presenter>, <presenter><i>Rebecca Raphael<\/i><\/presenter>, <presenter><i>Benjamin J. Raymond<\/i><\/presenter>, <presenter><i>Brian J. Leibowitz<\/i><\/presenter>, <presenter><i>Jingshan Tong<\/i><\/presenter>, <presenter><i>Brenda Diergaarde<\/i><\/presenter>, <presenter><i>Jian Yu<\/i><\/presenter>, <presenter><i>Reetesh K. Pai<\/i><\/presenter>, <presenter><i>Robert E. Schoen<\/i><\/presenter>, <presenter><i>Lin Zhang<\/i><\/presenter>, <presenter><i>Aatur Singhi<\/i><\/presenter>, <presenter><u><i>Shikhar Uttam<\/i><\/u><\/presenter>. University of Pittsburgh, Pittsburgh, PA","CSlideId":"","ControlKey":"a61592b8-e35a-40b2-ae30-48b14c867299","ControlNumber":"587","DisclosureBlock":"&nbsp;<b>B. Kochetov, <\/b> None..<br><b>P. D. Bell, <\/b> None..<br><b>R. Raphael, <\/b> None..<br><b>B. J. Raymond, <\/b> None..<br><b>B. J. Leibowitz, <\/b> None..<br><b>J. Tong, <\/b> None..<br><b>B. Diergaarde, <\/b> None..<br><b>J. Yu, <\/b> None..<br><b>R. K. Pai, <\/b> None..<br><b>R. E. Schoen, <\/b> None..<br><b>L. Zhang, <\/b> None..<br><b>A. Singhi, <\/b> None..<br><b>S. Uttam, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14802","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2b67e84a-a935-4812-86d4-d73bee9ee932\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"9","PosterboardNumber":"9","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1930","PresenterBiography":null,"PresenterDisplayName":"Shikhar Uttam, PhD,MS,BS","PresenterKey":"90073363-2041-45ad-b75a-c276897e9510","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1930. Unsupervised sub-cellular segmentation of complex tissue and cell samples using highly multiplexed imaging-derived <i>a priori <\/i>knowledge","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Unsupervised sub-cellular segmentation of complex tissue and cell samples using highly multiplexed imaging-derived <i>a priori <\/i>knowledge","Topics":null,"cSlideId":""},{"Abstract":"<b>Background:<\/b> Often, in analysis of expression data, binary classification problems are considered, with the aim to separate a control group from a single cancer group (<i>e.g.<\/i>, ovarian cancer). Such models lack any cancer specific information, as they are only trained on one cancer type. It is more useful and efficient to train a model on multiple cancer types, and controls, simultaneously, so that a physician can be directed to the correct area of the body for further testing.<br \/><b>Results:<\/b> We introduce novel, data-driven neural network models to address the multi-cancer classification problem across a number of data types commonly applied in cancer prediction, including circulating miRNA expression (blood draw), protein (tissue sample), and mRNA (tissue sample). In particular, we present an analysis of neural network depth and complexity and investigate how this relates to classification performance. Comparisons of our models are also given to the state-of-the-art neural network models from the literature. The proposed models yield high accuracy (mean AUC greater than 0.95) across all data types considered and are shown to offer greater performance when compared to the models from the literature.<br \/><b>Conclusion:<\/b> We have introduced a simple neural network framework which can be applied to multiple data types and which yields the best performance when compared to similar models from the literature. Upon analysis of the neural network complexity, we discover that shallow, feed-forward neural net architectures offer greater performance when compared to more complex deep feed-forward, Convolutional Neural Network (CNN), and Graph CNN (GCNN) architectures considered in the literature. The depth analysis indicates that shallow neural nets (e.g., 1 or 2 layers) are more favorable for this problem, when compared to deep architectures (e.g., more than 3 layers). The results show that multiple cancers and controls can be classified simultaneously, and accurately using the proposed models, across a range of expression technologies in cancer prediction.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f11765a6-5499-4bb8-8c0f-f31c2c0d0cfa\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Modeling,Cancer,Diagnosis,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14803"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>James W. Webber<\/i><\/u><\/presenter>, <presenter><i>Kevin M. Elias<\/i><\/presenter>. Brigham and Women's Hospital, Boston, MA, Brigham and Women's Hospital, Boston, MA","CSlideId":"","ControlKey":"803c1bf1-4e95-4707-a6e9-4e75cfa7402b","ControlNumber":"732","DisclosureBlock":"&nbsp;<b>J. W. Webber, <\/b> None..<br><b>K. M. Elias, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14803","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f11765a6-5499-4bb8-8c0f-f31c2c0d0cfa\/@t03B8ZAJ\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"10","PosterboardNumber":"10","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1931","PresenterBiography":null,"PresenterDisplayName":"James Webber, PhD","PresenterKey":"27012e31-2606-49bc-b35c-14523d99dcdb","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1931. Multi-cancer classification: An analysis of neural network complexity","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Multi-cancer classification: An analysis of neural network complexity","Topics":null,"cSlideId":""},{"Abstract":"The use of single-cell methods is expanding at an ever-increasing rate. While multiple algorithms address the task of cell classification, they are limited in terms of cross platform compatibility, reliance on the availability of a reference dataset, and classification interpretability. Here, we introduce Pollock, a suite of algorithms for cell type identification that is compatible with popular single cell methods and analysis platforms, provides a series of pretrained human cancer reference models, and reports interpretability scores that identify the genes that drive cell type classifications. Our model combines two important approaches, one each from machine learning and deep learning: a variational autoencoder (VAE) and random forest classifier, to make cell type predictions. Pollock is highly versatile, being available as a command line tool, Python library (with scanpy integration), or R library (with Seurat integration), and can be installed as a conda package, or in containerized form via Docker. To allow for easier pan-disease and pan-tissue analyses, Pollock also ships with a library of pretrained cancer type specific and agnostic modules that were trained on expertly-curated single cell data that are ready to &#8220;plug and play&#8221; with no additional annotation or training required. Conversely, Pollock also allows for the training of custom classification modules, if an annotated reference single cell dataset is available. These pretrained models were fitted on manually curated and annotated single cell data from eight different cancer types spanning three single cell technologies (scRNA-seq, snRNA-seq, and snATAC-seq). Pollock also provides feature importance scores that allow for cell type classifications to be traced back to the genes influencing a particular cell type classification, further promoting biological interpretability. These scores could allow for new, technology-specific biomarker discovery. We also demonstrate the utility of Pollock by applying it in a pan-cancer single cell immune analysis.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/66f61c19-b398-45b0-843b-45d9dab0f7b3\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Cancer genomics,Single cell,Bioinformatics,Deep learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14804"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Erik Storrs<\/i><\/u><\/presenter>, <presenter><i>Daniel Cui Zhou<\/i><\/presenter>, <presenter><i>Michael C. Wendl<\/i><\/presenter>, <presenter><i>Matthew A. Wyczalkowski<\/i><\/presenter>, <presenter><i>Alla Karpova<\/i><\/presenter>, <presenter><i>Liang-Bo Wang<\/i><\/presenter>, <presenter><i>Yize Li<\/i><\/presenter>, <presenter><i>Austin Southard-Smith<\/i><\/presenter>, <presenter><i>Reyka G. Jayasinghe<\/i><\/presenter>, <presenter><i>Lijun Yao<\/i><\/presenter>, <presenter><i>Ruiyang Liu<\/i><\/presenter>, <presenter><i>Yige Wu<\/i><\/presenter>, <presenter><i>Nadezhda V. Terekhanova<\/i><\/presenter>, <presenter><i>Houxiang Zhu<\/i><\/presenter>, <presenter><i>John M. Herndon<\/i><\/presenter>, <presenter><i>Feng Chen<\/i><\/presenter>, <presenter><i>William E. Gillanders<\/i><\/presenter>, <presenter><i>Ryan C. Fields<\/i><\/presenter>, <presenter><i>Li Ding<\/i><\/presenter>. Washington University, Saint Louis, MO","CSlideId":"","ControlKey":"d8108b0d-ae5d-43e7-bae4-534386ac9b11","ControlNumber":"5700","DisclosureBlock":"&nbsp;<b>E. Storrs, <\/b> None..<br><b>D. Cui Zhou, <\/b> None..<br><b>M. C. Wendl, <\/b> None..<br><b>M. A. Wyczalkowski, <\/b> None..<br><b>A. Karpova, <\/b> None..<br><b>L. Wang, <\/b> None..<br><b>Y. Li, <\/b> None..<br><b>A. Southard-Smith, <\/b> None..<br><b>R. G. Jayasinghe, <\/b> None..<br><b>L. Yao, <\/b> None..<br><b>R. Liu, <\/b> None..<br><b>Y. Wu, <\/b> None..<br><b>N. V. Terekhanova, <\/b> None..<br><b>H. Zhu, <\/b> None..<br><b>J. M. Herndon, <\/b> None..<br><b>F. Chen, <\/b> None..<br><b>W. E. Gillanders, <\/b> None..<br><b>R. C. Fields, <\/b> None..<br><b>L. Ding, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14804","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/66f61c19-b398-45b0-843b-45d9dab0f7b3\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"11","PosterboardNumber":"11","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1932","PresenterBiography":null,"PresenterDisplayName":"Erik Storrs, BS","PresenterKey":"0ab25405-e583-4899-9396-464a9d1dc23a","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1932. Pollock: Fishing for cell states","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Pollock: Fishing for cell states","Topics":null,"cSlideId":""},{"Abstract":"Imaging-based machine learning models are promising tools for breast cancer risk prediction. Validating these models across diverse cohorts is necessary to establish performance and spur clinical implementation.<br \/>We conducted an independent, external validation study of Mirai, a mammography-based deep learning model, using the Chicago Multiethnic Epidemiologic Cohort (ChiMEC), comprising 1671 exams from 704 cases and 4947 exams from 1437 cancer-free controls. We preprocessed images by extracting metadata from mammograms and excluded non-screening exams. Only exams with the four standard mammographic views were included. Images were converted from DICOM to PNG format using the DCMTK library. We computed the area under the receiver-operating characteristic curve (AUC) to evaluate the model&#8217;s discriminating capacity for predicting breast cancer within 1-5 years. We analyzed the entire cohort and stratified by race and hormone-receptor (HR) status.<br \/>Mirai performed well in our study, but the performance is lower than that in the originally published validation of Mirai model. The AUC of the 1-year-risk is 0.72 in our full cohort, which is higher than that of the 5-year-risk (0.65). The 1-year AUC is high in African Americans but decreases over time. In contrast, the model showed lower but time-consistent AUC values in White patients. Performance is slightly better for predicting HR + compared to HR - cancers.<br \/>Our results suggest that Mirai has better accuracy for predicting short-term breast cancer risk than traditional risk factor-based models, such as the Gail and Tyrer-Cuzick models. This initial evaluation revealed some performance differences by race and HR status and underscores the need for more independent validations in diverse datasets to elucidate the generalizability of image-based deep learning for breast cancer risk prediction.<br \/><table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{24F3A0AF-A257-4FE9-A436-F90A1B44ACFC}\"><caption>Table 1: Evaluation of performance of Mirai in ChiMEC Cohort<\/caption><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">Subset<\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">Case exams<\/td><td rowspan=\"1\" colspan=\"1\">Control exams<\/td><td rowspan=\"1\" colspan=\"1\">Harrel's C-index<\/td><td rowspan=\"1\" colspan=\"1\">1-year AUC&nbsp;<\/td><td rowspan=\"1\" colspan=\"1\">2-year AUC<\/td><td rowspan=\"1\" colspan=\"1\">3-year AUC<\/td><td rowspan=\"1\" colspan=\"1\">4-year AUC<\/td><td rowspan=\"1\" colspan=\"1\">5-year AUC<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt; letter-spacing: -0.3pt;\">Full<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 1.1pt;\"> <\/span><span style=\"font-size: 10pt;\">cohort<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">(MGH)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 52pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">588<\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">25267<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 24.9pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.75<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.72<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">.78)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 18.95pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.84<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.80,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.87)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">78<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.75,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.82)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.77<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.74,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.80)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.76<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.73,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.79)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.76<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.73,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.79)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt; letter-spacing: -0.3pt;\">Full<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 1.1pt;\"> <\/span><span style=\"font-size: 10pt;\">cohort<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">(ChiMEC)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 35.3pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">1656<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 20.2pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 13.3333px;\">4765<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.62,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.66)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.72<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.68,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.75)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.67<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.65,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.69)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.63,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">African<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">American<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 57.95pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">829<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 22.7pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">2174<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.61,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.78<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.74,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.82)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.69<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.65,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.72)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.63,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.69)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.69)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.63,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">White<\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">711<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 22.7pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">1808<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.59,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.65)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.57,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.61,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.68)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.60,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.66)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.61,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.66)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.61,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">Hispanic<\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">20<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">164<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 28.5pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.45,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.86)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.31,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.96)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.74<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.51,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.97)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.70<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.51,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.89)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.67<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.50,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.83)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.67<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.51,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.83)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">Asian<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">and<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt; letter-spacing: -0.05pt;\">Native<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">American<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 16.7pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">80<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">178<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 28.5pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.59<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.49,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.70)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.67<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.53,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.81)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.52,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.73)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.54,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.72)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.52,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.71)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.53,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.72)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">Hormone<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">receptor<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">positive<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">1281<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">4765<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.62,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.74<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.70,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.78)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.68<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.66,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.71)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68<\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">Hormone<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">receptor<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt; letter-spacing: -0.05pt;\">negative<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">300<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">4765<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.58,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.68<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.61,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.75)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.60,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.70)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.59,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.59,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.60,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">HER2<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">positive<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 71.8pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">139<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">4765<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.54,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.71)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.74<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.61,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.86)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.56,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.72)<\/span><br><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.56,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.69)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.58,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.69)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.58,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.69)<\/span><span style=\"font-size: medium;\"><\/span><br><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">HER2<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt; letter-spacing: -0.05pt;\">negative<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 66.9pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">1138<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">4765<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.65<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.62,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.74<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.70,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.78)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.68<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">(.65,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\">&nbsp;<\/span><span style=\"font-size: 10pt;\">.71)<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.66<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.64,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.68)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt; letter-spacing: -0.2pt;\">Triple<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 1pt;\"> <\/span><span style=\"font-size: 10pt; letter-spacing: -0.05pt;\">negative<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 70.2pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\">207<\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">4765<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 26pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.61<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.55,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 17.55pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.64<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.54,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.74)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.63<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.57,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.69)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.57,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.57,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.66)<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 9.45pt;\"><\/span><span style=\"font-size: medium;\"><\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size: 10pt;\">.62<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.8pt;\"> <\/span><span style=\"font-size: 10pt;\">(.58,<\/span><span style=\"font-size: 10pt; font-family: &quot;Times New Roman&quot;, serif; letter-spacing: 0.85pt;\"> <\/span><span style=\"font-size: 10pt;\">.67)<\/span><span style=\"font-size: medium;\"><\/span><\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f8dca9c9-4e10-44ef-a46a-4319fcf26ebb\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,Machine learning,Image analysis,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14805"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Olasubomi J. Omoleye<\/i><\/u><\/presenter>, <presenter><i>Anna Woodard<\/i><\/presenter>, <presenter><i>Fangyuan Zhao<\/i><\/presenter>, <presenter><i>Maksim Levental<\/i><\/presenter>, <presenter><i>Toshio F. Yoshimatsu<\/i><\/presenter>, <presenter><i>Yonglan Zheng<\/i><\/presenter>, <presenter><i>Olufunmilayo I. Olopade<\/i><\/presenter>, <presenter><i>Dezheng Huo<\/i><\/presenter>. The University of Chicago, Chicago, IL, The University of Chicago, Chicago, IL, The University of Chicago, Chicago, IL","CSlideId":"","ControlKey":"499b10e7-a589-4ade-87ab-55e15739331e","ControlNumber":"6378","DisclosureBlock":"&nbsp;<b>O. J. Omoleye, <\/b> None..<br><b>A. Woodard, <\/b> None..<br><b>F. Zhao, <\/b> None..<br><b>M. Levental, <\/b> None..<br><b>T. F. Yoshimatsu, <\/b> None..<br><b>Y. Zheng, <\/b> None.&nbsp;<br><b>O. I. Olopade, <\/b> <br><b>CancerIQ<\/b> Co-founder, No. <br><b>Tempus<\/b> Other, Scientific Advisor, No. <br><b>54gene<\/b> Board of Directors, No.<br><b>D. Huo, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14805","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f8dca9c9-4e10-44ef-a46a-4319fcf26ebb\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"12","PosterboardNumber":"12","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1933","PresenterBiography":null,"PresenterDisplayName":"Olasubomi Omoleye, MBBS","PresenterKey":"38f514dd-041e-493d-9e0b-78b2e3d5b4a8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1933. Independent evaluation and validation of mammography-based breast cancer risk models in a diverse patient cohort","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Independent evaluation and validation of mammography-based breast cancer risk models in a diverse patient cohort","Topics":null,"cSlideId":""},{"Abstract":"The assessment of prognostic markers in routine clinical practice of breast cancer is currently performed using multi gene RNA panels. However, the unknown proportion of normal breast tissue in relation to malignant breast tissue can reduce the predictive value of such tests. Immunohistochemistry holds the potential for a better assessment of tumors because tumor cells can be separately analyzed.<b> <\/b>To enable automated prognosis marker detection (i.e. HER2, GATA3, progesterone receptor [PR], estrogen receptor [ER], androgen receptor [AR], TOP2A, Ki-67, TROP2, Mammaglobin), we have developed and validated a framework for automated breast cancer identification, which comprises three different artificial intelligence analysis steps and an algorithm for cell-distance analysis of 12+1 marker BLEACH&#38;STAIN multiplex fluorescence immunohistochemistry staining, in 2004 breast cancers. The optimal distance between Myosin<sup>+<\/sup> basal cells and benign panCK<sup>+<\/sup> benign cells was identified as 31&#181;m and used to exclude benign glands from the analysis combined with and deep learning-based algorithm for benign gland detection. Our deep learning-based framework discriminated normal glands from malignant glands with an area under receiver-operating characteristic curves (AUC) of 0.96 (95% confidence interval [CI], 0.92 to 0.99). The accuracy of the approach was also validated by several well-characterized biological findings, such as the identification of 13% HER2<sup>+<\/sup>, 73% PR<sup>+<\/sup>\/ER<sup>+<\/sup>, and 14% triple negative cases in the study cohort as well as a significant higher Fraction of TOP2A in the HER2<sup>+<\/sup> cases as compared to the HER2<sup>-<\/sup> cases (p&#60;0.001). Furthermore, the automated assessment of GATA3, PR, ER, TOP2A-LI, Ki-67-LI, TROP2, and Mammaglobin was significantly liked to the tumor grade (p&#60;0.001 each). Furthermore, a high expression level of HER2, GATA3, PR, and ER was associated with a prolonged overall survival (p&#8805;0.002 each). In conclusion, a deep learning-based framework for automated breast cancer identification using BLEACH&#38;STAIN multiplex fluorescence IHC facilitates automated prognosis marker quantification in breast cancer.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2983ffab-f969-49be-8573-c9f8753a162d\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,HER2,Deep learning,Immunohistochemistry,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14806"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Tim Mandelkow<\/i><\/presenter>, <presenter><i>Elena Bady<\/i><\/presenter>, <presenter><i>Magalie C. J. Lurati<\/i><\/presenter>, <presenter><i>Claudia Hube-Magg<\/i><\/presenter>, <presenter><i>Maximilian Lennartz<\/i><\/presenter>, <presenter><i>Guido Sauter<\/i><\/presenter>, <presenter><u><i>Niclas C. Blessin<\/i><\/u><\/presenter>, <presenter><i>Ronald Simon<\/i><\/presenter>. Clinical University Hamburg-Eppendorf, Hamburg, Germany","CSlideId":"","ControlKey":"d95d8436-2f80-47cf-aa13-573e9c168645","ControlNumber":"3564","DisclosureBlock":"&nbsp;<b>T. Mandelkow, <\/b> None..<br><b>E. Bady, <\/b> None..<br><b>M. C. J. Lurati, <\/b> None..<br><b>C. Hube-Magg, <\/b> None..<br><b>M. Lennartz, <\/b> None.&nbsp;<br><b>G. Sauter, <\/b> <br><b>MS Validated Antibodies GmbH<\/b> Other, MS Validated Antibodies GmbH is owned by a family member of Prof. Dr. Guido Sauter., Yes.<br><b>N. C. Blessin, <\/b> None..<br><b>R. Simon, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14806","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2983ffab-f969-49be-8573-c9f8753a162d\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"13","PosterboardNumber":"13","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1934","PresenterBiography":null,"PresenterDisplayName":"Niclas Blessin, MD","PresenterKey":"78f26db6-1dfe-4280-8ee5-c965257228dd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1934. An artificial intelligence-based framework for BLEACH&#38;STAIN mfIHC facilitates automated prognosis marker assessment in breast cancer","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"An artificial intelligence-based framework for BLEACH&#38;STAIN mfIHC facilitates automated prognosis marker assessment in breast cancer","Topics":null,"cSlideId":""},{"Abstract":"An increasing number of therapy regimens using a combination of different immune checkpoint inhibitors (ICIs) have shown remarkable results in several different tumor entities. However, the likelihood of a positive response rate to combined ICIs is poor in most tumor entities and depends on several parameters including the tumor microenvironment. Particularly little is known about the spatial orchestration and spatial interplay between different immune checkpoint expressing cells. Given that the T-cell immunoglobulin and mucin domain-containing protein 3 (TIM3) is expressed on both immune cells as well as tumor cells and that several phase I\/II studies are currently evaluating anti-TIM3 drugs, the interplay between these immune checkpoints in human cancers is of topical interest. To study the spatial orchestration and interplay between TIM3, CTLA-4, PD-1, and PD-L1 expression on T-cell subsets, macrophage subsets, CD11c<sup>+<\/sup> dendritic cells, CD20<sup>+<\/sup>B-cells in relation to panCK<sup>+<\/sup> malignant cells, CD31<sup>+<\/sup> vessels and other structural tumor compartments, a multiplex fluorescence immunohistochemistry approach was used to stain 18 different antibodies on a set of tissue microarrays containing samples from more than 3000 carcinoma samples. In addition, a deep learning-based framework for cell type identification was developed and validated in this study. TIM3, PD-1, PD-L1, and CTLA-4 expression was measured on tumor cells (panCK<sup>+<\/sup>), cytotoxic T-cells (CD3<sup>+<\/sup>CD8<sup>+<\/sup>), T-helper cells (CD3<sup>+<\/sup>CD4<sup>+<\/sup>), regulatory T-cells (CD3<sup>+<\/sup>CD4<sup>+<\/sup>FOXP3<sup>+<\/sup>), subsets of macrophages (CD68<sup>+<\/sup>CD163<sup>+<\/sup>\/ CD68<sup>+<\/sup>iNOS<sup>+<\/sup>) and dendritic cells (CD11c<sup>+<\/sup>). Interestingly, TIM3 as well as CTLA-4 expression on CD3<sup>+<\/sup>CD8<sup>+ <\/sup>cytotoxic T-cells and CD3<sup>+<\/sup>CD4<sup>+<\/sup>FOXP3<sup>+ <\/sup>regulatory T-cells showed a spatially more diverse expression pattern - particularly inverse expression profile - compared to PD-1 expression on all analyzed T-cells subsets that was consistently accompanied by PD-L1 expression on immune and tumor cells (p&#60;0.001). Combined analysis of cell densities, expression patterns, intensity measurements, interaction and distance analysis between immune cells and tumor cells revealed distinct changes in the immune cell infiltration pattern that was linked to several major immune checkpoint receptor expression profiles. Previously uncharacterized immune cell-composition dynamics in clustered tumor phenotypes, according to the immune checkpoint expression, were detected. This included for instance, a significant inverse association between CTLA-4 expression on T-cells and high expression levels of the PD-1\/PD-L1 axis. In conclusion, deep profiling of 18 biomarkers in more than 40 different carcinoma entities revealed complex changes in the spatial orchestration of a wide range of immune cell subsets that was driven by the expression profile and composition of TIM3, PD-1, PD-L1, and CTLA-4.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/8e17d34c-6b38-454a-a628-85c4db382f03\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Checkpoint Inhibitors,Fluorescence imaging,Immunohistochemistry,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14815"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Nicolaus F. Debatin<\/i><\/presenter>, <presenter><i>Elena Bady<\/i><\/presenter>, <presenter><i>Tim Mandelkow<\/i><\/presenter>, <presenter><i>Magalie C. J. Lurati<\/i><\/presenter>, <presenter><i>Ronald Simon<\/i><\/presenter>, <presenter><i>Claudia Hube-Magg<\/i><\/presenter>, <presenter><i>Maximilian Lennartz<\/i><\/presenter>, <presenter><i>Guido Sauter<\/i><\/presenter>, <presenter><u><i>Niclas C. Blessin<\/i><\/u><\/presenter>. Clinical University Hamburg-Eppendorf, Hamburg, Germany","CSlideId":"","ControlKey":"40121c40-d5bc-47af-b3f0-ddddfd0cdcf0","ControlNumber":"3515","DisclosureBlock":"&nbsp;<b>N. F. Debatin, <\/b> None..<br><b>E. Bady, <\/b> None..<br><b>T. Mandelkow, <\/b> None..<br><b>M. C. J. Lurati, <\/b> None..<br><b>R. Simon, <\/b> None..<br><b>C. Hube-Magg, <\/b> None..<br><b>M. Lennartz, <\/b> None.&nbsp;<br><b>G. Sauter, <\/b> <br><b>MS Validated Antibodies GmbH<\/b> Other, MS Validated Antibodies GmbH is owned by a family member of Prof. Dr. Guido Sauter., Yes.<br><b>N. C. Blessin, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14815","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/8e17d34c-6b38-454a-a628-85c4db382f03\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"14","PosterboardNumber":"14","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1935","PresenterBiography":null,"PresenterDisplayName":"Niclas Blessin, MD","PresenterKey":"78f26db6-1dfe-4280-8ee5-c965257228dd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1935. Interplay between TIM3<sup>+<\/sup> immune cells and other immune checkpoints in more than 40 different human carcinoma entities using 18+1 BLEACH&#38;STAIN mfIHC","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Interplay between TIM3<sup>+<\/sup> immune cells and other immune checkpoints in more than 40 different human carcinoma entities using 18+1 BLEACH&#38;STAIN mfIHC","Topics":null,"cSlideId":""},{"Abstract":"Gene regulation is critical for cell identity, and its dysregulation is a defining characteristic of common diseases including cancers. Although promoter activity is a strong predictor of gene expression, activities at other regulatory elements, including enhancers and super-enhancers (SE), are major contributors to gene regulation. For example, distinct transcription factor-regulating SEs define neuroblastoma (NB) subtypes with distinct clinical outcomes. However, technical limitations largely prevent ChIP-seq based enhancer\/SE activity profiling in primary patient samples. We previously developed MethylationToActivity (M2A) and demonstrated that high-order DNA methylation (DNAm) features are strong predictors of promoter activity measured by ChIP-seq. This tool is important because genomewide DNAm assays are widely used in clinic to classify tumors and stratify patients on clinical trials. However, it is limited by its reliance on known gene position annotations. Here we present MethylationToRegulation (M2R), a method that utilizes a convolutional neural network (CNN)-based deep learning framework to infer intergenic enhancer\/SE activities from DNA methylomes. We obtained paired WGBS and H3K27ac ChIP-seq data for 16 pediatric NB samples profiled in the Pediatric Cancer Genome Project. M2R was trained on 6 samples and tested on the remaining 10 samples. It achieved an average relative prediction accuracy of 84% on test samples when compared to the H3K27ac ChIP-seq replicate consistency from the ENCODE project. We adapted the Rank Ordering of Super-Enhancers algorithm to interpret H3K27ac signals inferred from DNA methylomes to identify SEs. M2R faithfully captured subtype-defining SEs with high specificity, including those associated with master NB transcription factors. Our results demonstrate that M2R accurately quantifies enhancer\/SE activities and infers critical epigenetic marks from DNA methylomes. Application of M2R will enable the profiling of epigenetic dysregulation in patient tumor samples, seeking to improve clinical outcomes.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/9c8f8a40-1e2c-4385-9812-0964587f2096\/@u03B8ZAK\/vod?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Epigenetics,Neuroblastoma,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14808"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Daniel K. Putnam<\/i><\/u><\/presenter>, <presenter><i>Brian J. Abraham<\/i><\/presenter>, <presenter><i>Xiang Chen<\/i><\/presenter>. St Jude Childrens Research Hospital, Memphis, TN","CSlideId":"","ControlKey":"77ccfd06-e336-4727-b7bf-5dca24c8ead6","ControlNumber":"4726","DisclosureBlock":"&nbsp;<b>D. K. Putnam, <\/b> None.&nbsp;<br><b>B. J. Abraham, <\/b> <br><b>Syros Pharmaceuticals<\/b> Stock, Yes.<br><b>X. Chen, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14808","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/9c8f8a40-1e2c-4385-9812-0964587f2096\/@u03B8ZAK\/vod?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"15","PosterboardNumber":"15","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1936","PresenterBiography":null,"PresenterDisplayName":"Daniel Putnam, PhD","PresenterKey":"3bec2b62-0c2b-4c9a-bf58-49b6c6e911c5","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1936. MethylationToRegulation: A deep-learning approach to infer chromatin properties from DNA methylomes","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"MethylationToRegulation: A deep-learning approach to infer chromatin properties from DNA methylomes","Topics":null,"cSlideId":""},{"Abstract":"Whether tracking patient progress for clinical decision making, or investigating novel therapies, automated analysis of Computed Tomography (CT) imaging data is essential for the future of digital radiomics. In digital radiomics, as in all medical imaging, well annotated data is scarce, whereas unlabelled images are relatively plentiful. In other fields of image processing and medical imaging, the application of self-supervised learning (SSL) to large quantities of unlabelled data has resulted in great strides forward for fast, scalable, and interpretable image analysis. In this work we present a new approach applying SSL to CT imaging data which allows for: 1) Improved performance on image classification tasks, based on 2) dramatically reduced quantity of annotated CT imaging data, whilst also 3) enabling easy exploration and interpretation of the image regions.<br \/>We applied a selection of self-supervised approaches (BYOL, DINO, SimCLR, &#38; inpainting) to CT imaging data. Because the high dimensionality of CT data prevents us from using them directly to out-of the box SSL models, we adopt a 3D patching approach to reduce the dimensionality of the neural net input, and process each patch independently.<br \/>We train our self-supervised models on public datasets (DeepLesion, NSCLC), and we specialize these models for tumor classification tasks that we evaluate on AstraZeneca sponsored clinical trials. The specialization is done in two different ways: 1) we use the pre-trained SSL model as an encoder that transforms the images of the clinical study into embeddings, on which we apply supervised classification models; 2) we use transfer learning to fine-tune supervised classification models that take the patches directly as inputs.<br \/>We find that self-supervised pre-training significantly improves the accuracy on tumor classification tasks compared against a supervised learning baseline. Additionally, using the SSL embeddings we build an interactive map of CT imaging data enabling quick and intuitive inspection of the relevant regions.<br \/>Our findings show that SSL constitutes an important tool for medical imaging analysis. SSL results in models that generalize better, and enable improved downstream interpretability and predictions. Furthermore, well trained SSL models can be re-applied to multiple indications because they are pre-trained on broad and diverse CT imaging data.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/b1bab700-502d-47af-aaa7-f99e9769ab7f\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Deep learning,Cancer detection,Image analysis,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14809"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Leon Fedden<\/i><\/u><\/presenter>, <presenter><i>Zhenning Zhang<\/i><\/presenter>, <presenter><i>Khan Baykaner<\/i><\/presenter>, <presenter><i>Qin Li<\/i><\/presenter>, <presenter><i>Lucas Bordeaux<\/i><\/presenter>. AstraZeneca, Cambridge, United Kingdom, AstraZeneca, Gaithersburg, MD, AstraZeneca, Waltham, MA","CSlideId":"","ControlKey":"5c4f619e-2587-4c65-b0f0-866983e440ab","ControlNumber":"5205","DisclosureBlock":"<b>&nbsp;L. Fedden, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>Z. Zhang, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>K. Baykaner, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>Q. Li, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>L. Bordeaux, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14809","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/b1bab700-502d-47af-aaa7-f99e9769ab7f\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"16","PosterboardNumber":"16","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1937","PresenterBiography":null,"PresenterDisplayName":"Leon Fedden, MS","PresenterKey":"b97ad825-3b67-45eb-b3b8-772fa23b561d","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1937. DIME-CT: Self-supervised learning for medical image analysis using patch-based embeddings","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"DIME-CT: Self-supervised learning for medical image analysis using patch-based embeddings","Topics":null,"cSlideId":""},{"Abstract":"Precision medicine has allowed for many drugs to be developed for frequently occurring well studied oncogenic mutations such as NTRK fusions or EGFR exon 19 mutations. However, large scale genomic sequencing of patient samples shows that tumors harbor many mutations classified as Variants of Uncertain Significance (VUS). Such mutations could have a significant role in tumor progression and can thus serve as potential drug targets. Therefore, understanding and characterizing the functional significance of VUSs and their response to targeted agents is essential. Here we present a novel machine learning (ML) model consisting of a multi-label, multi-task deep convolutional neural network followed by a decision tree-based regression model. Focusing on alterations in BRAF, we used data from a cell-based assay that measures the activity of signaling pathway activation. This is done using fluorescent imaging of cells expressing a mutated protein together with a fluorescently labeled signaling pathway reporter, providing the input to our model. We trained the model on 3 types of cell images: cells transfected with WT BRAF, BRAF V600E, and BRAF V600E treated with a high dose of Vemurafenib. We use two datasets to evaluate our performance: a set of 17 known active BRAF fusions, as well as a set of 16 known active non-V600E mutations. We also compare our performance to previously published single-task ML model that aims to detect both activity and response. The two methodologies are compared via two criteria: ability to detect activity of the mutations in the dataset, as well as ability to predict response to Vemurafenib or to FORE8394, a drug previously unseen by the model. We show that while both single-task and multi-task models identify all 17 known active fusions as oncogenic, the multi-task does slightly better on the non-V600E mutations, correctly identifying 15\/16 of the active mutations vs 10\/16 for the single-task model. Comparing drug response, the multi-task model has higher sensitivity in detecting active mutations as responsive to Vemurafenib or FORE8394, including all V600 mutations which are known responders to Vemurafenib and for whom the single-task model does not capture response. Following the training and validation, given a dataset of &#62;300 previously unseen BRAF mutations, the multi-task model is then able to predict both the mutation&#8217;s oncogenicity level as well as its expected response to the given drug. Interestingly, the multi-task model also suggests a different drug response profile for vemurafenib compared to FORE8394. We conclude that our novel multi-task model provides an accurate and efficient method for uncovering the actionable and treatable mutational landscape of a drug for patients with mutations in BRAF. It can thus be viewed as a step forward in developing sensitive methodologies for determining patients that are more susceptible to benefit from a potential drug.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/fdf149c4-d6e8-4c73-9980-304ccffd2a23\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,BRAF,High-throughput assay,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14810"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Ilona Kifer<\/i><\/presenter>, <presenter><i>Arie Aizenman<\/i><\/presenter>, <presenter><i>Natalie Fillipov-Levy<\/i><\/presenter>, <presenter><i>Zohar Barbash<\/i><\/presenter>, <presenter><i>Michael Vidne<\/i><\/presenter>, <presenter><u><i>Gabi Tarcic<\/i><\/u><\/presenter>. FORE Biotherapeutics, Jerusalem, Israel","CSlideId":"","ControlKey":"6f55865d-63e7-4429-b347-af42bdef82c2","ControlNumber":"832","DisclosureBlock":"<b>&nbsp;I. Kifer, <\/b> <br><b>FORE Biotherapeutics<\/b> Employment, Yes. <br><b>A. Aizenman, <\/b> <br><b>FORE Biotherapeutics<\/b> Employment, Yes. <br><b>N. Fillipov-Levy, <\/b> <br><b>FORE Biotherapeutics<\/b> Employment, Yes. <br><b>Z. Barbash, <\/b> <br><b>FORE Biotherapeutics<\/b> Employment, Yes. <br><b>M. Vidne, <\/b> <br><b>FORE Biotherapeutics<\/b> Employment, Yes. <br><b>G. Tarcic, <\/b> <br><b>FORE Biotherapeutics<\/b> Employment, Yes.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14810","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/fdf149c4-d6e8-4c73-9980-304ccffd2a23\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"17","PosterboardNumber":"17","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1938","PresenterBiography":null,"PresenterDisplayName":"Gabi Tarcic, MS;PhD","PresenterKey":"89295814-b00b-4efc-8f13-2be870b2e952","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1938. Large-scale identification of mutation activity and drug sensitivity in BRAF via a novel multi-label multi-task CNN model","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Large-scale identification of mutation activity and drug sensitivity in BRAF via a novel multi-label multi-task CNN model","Topics":null,"cSlideId":""},{"Abstract":"Soft Tissue sarcomas (STS) are a group of heterogeneous and complex diseases. Being able to predict the appearance of metastases is key to inform clinical decisions, especially the prescription of perioperative chemotherapy. While multiple methods including multivariable nomograms have been developed to tackle this issue, we leveraged artificial intelligence (AI) to extract information from raw images with Deep-Learning. In this study, we developed SarcNet: a multimodal deep-learning algorithm based on histological slides and clinical variables to predict metastatic relapse in patients affected with limbs and trunk wall STS. Two independent series were investigated simultaneously: Centre L&#233;on B&#233;rard, n=221 and Institut Bergoni&#233;, n=390. This study was able to gather a sufficient number of patients in this rare disease by training all the algorithms in a multicentric fashion using Federated Learning (FL). It is one of the first real-world applications of FL in Healthcare which allows to keep patients&#8217; data behind hospital firewalls. The SarcNet algorithm achieved unprecedented performance. By leveraging an AI-driven analysis of digitized whole slide images in addition to clinical variables, our multimodal model achieved a 0.80 AUC to predict 5-year MFS (metastatic free survival) compared to 0.77 for Sarculator (current state-of-the-art nomogram). It also greatly outperformed current standard of care practices like FNCLCC grading that reached an AUC of 0.70. Interpretability investigations of the SarcNet model highlighted histological patterns that drive the prediction of metastatic relapse such as atypia, tumoral cellularity and mitosis. This model could lead to more informed clinical decisions by identifying high-risk patients that could benefit from perioperative chemotherapy. Finally, deeper investigations of the model and the highlighted biomarkers could lead to a better understanding of metastatic relapse in STS<br \/><table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{E9AB82C4-71EF-4374-B1D7-52032D1664A8}\"><caption>Performance of models to predict 5y MFS (AUC evaluated in 5 repeated 5-fold cross validation)<\/caption><tr><td rowspan=\"1\" colspan=\"1\">Methods<\/td><td rowspan=\"1\" colspan=\"1\">Whole cohort (n=611)<\/td><td rowspan=\"1\" colspan=\"1\">IB (n=390)<\/td><td rowspan=\"1\" colspan=\"1\">CLB (n=221)<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>SarcNet<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.800, 95% CI [0.786-0.814]<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.770, 95% CI [0.750-0.791]<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.842, 95% CI [0.824-0.859]<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Sarculator<\/td><td rowspan=\"1\" colspan=\"1\">0.767, 95% CI [0.752-0.783]<\/td><td rowspan=\"1\" colspan=\"1\">0.736, 95% CI [0.718-0.755]<\/td><td rowspan=\"1\" colspan=\"1\">0.808, 95% CI [0.785-0.831]<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">FNCLCC (French Federation of Centers for the Fight against Cancer) grading<\/td><td rowspan=\"1\" colspan=\"1\">0.699, 95% CI [0.684-0.714]<\/td><td rowspan=\"1\" colspan=\"1\">0.723, 95% CI [0.708-0.738]<\/td><td rowspan=\"1\" colspan=\"1\">0.637, 95% CI [0.612-0.663]<\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2aee4250-198d-4284-8fea-131f63fa57b8\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Sarcoma\/soft-tissue malignancies,Metastasis,Federated Learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14811"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Charles Maussion<\/i><\/u><\/presenter>, <presenter><i>Jean-Michel Coindre<\/i><\/presenter>, <presenter><i>Jean-Yves Blay<\/i><\/presenter>, <presenter><i>Kathryn Schutte<\/i><\/presenter>, <presenter><i>Axel Camara<\/i><\/presenter>, <presenter><i>François Le Loarer<\/i><\/presenter>, <presenter><i>Raul Perret<\/i><\/presenter>, <presenter><i>Myriam Jean-Denis<\/i><\/presenter>, <presenter><i>Alexandra Meurgey<\/i><\/presenter>, <presenter><i>Françoise Ducimetiere<\/i><\/presenter>, <presenter><i>Antoine Giraud<\/i><\/presenter>, <presenter><i>Jean-Baptiste Courrèges<\/i><\/presenter>, <presenter><i>Clément Gautier<\/i><\/presenter>, <presenter><i>Etienne Bendjebbar<\/i><\/presenter>, <presenter><i>Jean Du Terrail<\/i><\/presenter>, <presenter><i>Antoine Italiano<\/i><\/presenter>, <presenter><i>Marie Karanian<\/i><\/presenter>. Owkin Inc, Paris, France, Institut Bergonié, Bordeaux, France, Center Léon Bérard, Lyon, France","CSlideId":"","ControlKey":"a1fd66e1-f7c7-4841-9bec-b3db6b0ae19f","ControlNumber":"4605","DisclosureBlock":"<b>&nbsp;C. Maussion, <\/b> <br><b>Owkin<\/b> Employment, No.<br><b>J. Coindre, <\/b> None..<br><b>J. Blay, <\/b> None.&nbsp;<br><b>K. Schutte, <\/b> <br><b>Owkin<\/b> Employment. <br><b>A. Camara, <\/b> <br><b>Owkin<\/b> Employment.<br><b>F. Le Loarer, <\/b> None..<br><b>R. Perret, <\/b> None..<br><b>M. Jean-Denis, <\/b> None..<br><b>A. Meurgey, <\/b> None..<br><b>F. Ducimetiere, <\/b> None..<br><b>A. Giraud, <\/b> None..<br><b>J. Courrèges, <\/b> None.&nbsp;<br><b>C. Gautier, <\/b> <br><b>Owkin<\/b> Employment. <br><b>E. Bendjebbar, <\/b> <br><b>Owkin<\/b> Employment. <br><b>J. Du Terrail, <\/b> <br><b>Owkin<\/b> Employment.<br><b>A. Italiano, <\/b> None..<br><b>M. Karanian, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14811","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2aee4250-198d-4284-8fea-131f63fa57b8\/@u03B8ZAK\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"18","PosterboardNumber":"18","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1939","PresenterBiography":null,"PresenterDisplayName":"Charles Maussion","PresenterKey":"74124b8f-9931-4e46-a53f-6d79ef5414ba","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1939. Multimodal prediction of metastatic relapse using federated deep learning outperforms state-of-the-art methods in soft-tissue sarcoma","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Multimodal prediction of metastatic relapse using federated deep learning outperforms state-of-the-art methods in soft-tissue sarcoma","Topics":null,"cSlideId":""},{"Abstract":"Tumors are complex masses composed of malignant and non-malignant cells. Variation in tumor purity (malignant cell fraction) can both confound integrative analysis and enable studies of tumor heterogeneity. Here we developed PUREE, which uses a weakly supervised learning approach to infer tumor purity from a tumor gene expression profile. PUREE was trained on gene expression data and genomic consensus purity estimates from approximately 8000 solid tumor samples. Using a linear model based on 170 input genes, PUREE predicted purity with high accuracy across distinct solid tumor types and generalized to tumor samples from unseen tumor types. PUREE input genes features were further validated using single-cell RNA-seq data from distinct tumor types. In a comprehensive benchmark, PUREE outperformed all existing transcriptome-based purity estimation approaches. We also show that the accuracy of a pan-cancer model is comparable to models optimized for individual tumor types, highlighting compositional properties of the tumor microenvironment conserved across tumor types. Overall, PUREE is a highly accurate and versatile method for estimating tumor purity and interrogating tumor heterogeneity from bulk tumor gene expression data.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/b7d8ca07-253b-447c-9416-d84be5344801\/@v03B8ZAL\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Tumor microenvironment,Gene expression,Tumor purity,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14813"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Egor Revkov<\/i><\/u><\/presenter>, <presenter><i>Ken W.-K. Sung<\/i><\/presenter>, <presenter><i>Anders J. Skanderup<\/i><\/presenter>. Genome Institute of Singapore, Singapore, Singapore","CSlideId":"","ControlKey":"fbe21c2b-cec1-4e92-bf5f-c009839e0289","ControlNumber":"568","DisclosureBlock":"&nbsp;<b>E. Revkov, <\/b> None..<br><b>K. W. Sung, <\/b> None..<br><b>A. J. Skanderup, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14813","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/b7d8ca07-253b-447c-9416-d84be5344801\/@v03B8ZAL\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"19","PosterboardNumber":"20","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1941","PresenterBiography":null,"PresenterDisplayName":"Egor Revkov, BS","PresenterKey":"f7e31550-54ad-430e-acc6-5e03848cd1d1","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1941. Accurate pan-cancer tumor purity estimation from gene expression data","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Accurate pan-cancer tumor purity estimation from gene expression data","Topics":null,"cSlideId":""},{"Abstract":"Neural networks are powerful tools for modeling genetic contributions to cancer risk that can theoretically capture nonlinear, epistatic interactions between disease-associated loci in heritable cancers. Recent studies applying neural networks and other machine learning methods to complex trait risk prediction from single nucleotide polymorphism (SNP) array data have shown promise in improving risk stratification. However, current performance gains for neural networks when compared to traditional polygenic risk scoring (PRS) approaches and other nonlinear and linear machine learning methods have been modest. Moreover, there remains substantial debate as to the effect of capturing epistatic interactions between SNPs in risk modeling. Central to the debate has been the difficulty in interpreting the complex, nonlinear mapping learned by neural networks and other nonlinear modeling approaches.<br \/>To decipher the importance of capturing nonlinear interactions in cancer risk modeling, we first applied several PRS approaches to the prediction of breast and prostate cancer status for individuals in the Discovery, Biology, and Risk of Inherited Variants in Breast Cancer (DRIVE) and Elucidating Loci Involved in Prostate Cancer Susceptibility (ELLIPSE) datasets respectively. Consistent with previous studies of complex disease prediction using machine learning, we noted greater predictive capability upon inclusion of more loci in our modeling but only small performance gains when nonlinearity was captured in both cancer types. We then applied machine learning interpretation methods to derive a score for each variant per method, including several neural network interpretation methods which, to our knowledge, have not been applied in this context. We noted varying degrees of concordance between the scores assigned by each method. Finally, we performed pairwise in silico perturbations on salient features and techniques from network biology to identify epistatic interactions between loci captured by each model. Our work represents a comprehensive study of methods for inferring both variant level and epistatic interaction contributions to cancer risk.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/36514e88-90fb-44d1-aa13-af1c987d3da2\/@v03B8ZAL\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Cancer risk,Prostate cancer,Single nucleotide polymorphism (SNP),"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14814"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Adam Klie<\/i><\/u><\/presenter>, <presenter><i>James Talwar<\/i><\/presenter>, <presenter><i>Meghana Pagadala<\/i><\/presenter>, <presenter><i>Hannah Carter<\/i><\/presenter>. UC San Diego, La Jolla, CA","CSlideId":"","ControlKey":"2f65b428-0bf8-4e2e-93f5-cb69f502615d","ControlNumber":"5122","DisclosureBlock":"&nbsp;<b>A. Klie, <\/b> None..<br><b>J. Talwar, <\/b> None..<br><b>M. Pagadala, <\/b> None..<br><b>H. Carter, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14814","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/36514e88-90fb-44d1-aa13-af1c987d3da2\/@v03B8ZAL\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"20","PosterboardNumber":"21","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1942","PresenterBiography":null,"PresenterDisplayName":"Adam Klie, BS","PresenterKey":"77553cad-bf2e-4707-87ac-44bcd7257547","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1942. Interpretation of machine learning methods for the prediction of breast and prostate cancer risk","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Interpretation of machine learning methods for the prediction of breast and prostate cancer risk","Topics":null,"cSlideId":""},{"Abstract":"Gallbladder cancer (GBC) is one of the deadliest cancers, with a 5-year-survival-rate of less than 5 percent for late-stage disease. The response rate to chemotherapy among GBC patients is generally poor. Recent research has attempted to identify diagnostic, prognostic, and predictive biomarkers, however, currently, no biomarkers can accurately diagnose GBC and predict patients&#8217; prognosis. Integrative analysis of molecular and clinical characterization has not been fully established, and minimal improvement has been made to the survival of these patients, in part due to the heterogeneity of GBC. Machine learning techniques have been proven to empower analysis of big data in oncology, allowing for improvement in the generation of biomarkers to predict patient outcomes. Using machine learning, we can utilize high-throughput RNA sequencing with clinicopathologic data to develop a predictive tool for GBC prognosis. Current predictive models for GBC outcomes often utilize clinical data only, with the highest C-statistic reported being 0.71. C-statistic values over 0.7 generally indicate good models, however 0.8 is the threshold for strong predictive models. We aim to build a superior algorithm to predict overall survival in GBC patients with advanced disease, using machine learning approaches to prioritize biomarkers for GBC prognosis. We have identified over 80 fresh frozen GBC tissue samples from Mayo Clinic Rochester, Dongsan Medical Center in Daegu, Korea, University of the Witwatersrand, in Johannesburg, South Africa, Lithuanian University of Health Science in Vilnius, Lithuania, and University of Calgary in Calgary, Canada, from patients enrolled between 2012 and 2021. We will perform next-generation RNA sequencing on these tissue samples. The patients&#8217; clinical, pathologic and survival data will be abstracted from the medical record uniformly across sites. Feature engineering and dimensionality reduction will be performed. Then random forests, support vector machines, and gradient boosting machines will be applied to train the data. Variable importance will prioritize multi-omic markers. Standard 5-fold cross validation will be used to assess performance of each ML algorithm. If overall survival can be better predicted with the addition patients&#8217; transcriptional sequencing data compared to using clinical profiles alone, we can gain a greater understanding of key biomarkers driving the tumor phenotype.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/e5cacb06-a27b-4c63-a4e5-b25e203d4e04\/@v03B8ZAL\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"RNA sequencing (RNA-Seq),Personalized medicine,Prognostic markers,Gastrointestinal cancers: other,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14848"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Linsey Jackson<\/i><\/u><\/presenter>, <presenter><i>Loretta Allotey<\/i><\/presenter>, <presenter><i>Valles Kenneth<\/i><\/presenter>, <presenter><i>Gavin Oliver<\/i><\/presenter>, <presenter><i>Asha Nair<\/i><\/presenter>, <presenter><i>Daniel O'Brien<\/i><\/presenter>, <presenter><i>Rondell Graham<\/i><\/presenter>, <presenter><i>Mitesh Borad<\/i><\/presenter>, <presenter><i>Arjun Athreya<\/i><\/presenter>, <presenter><i>Lewis Roberts<\/i><\/presenter>. Mayo Clinic, Rochester, MN","CSlideId":"","ControlKey":"7a490aac-a4fa-4fe8-a8ea-212d4a7420f4","ControlNumber":"4266","DisclosureBlock":"&nbsp;<b>L. Jackson, <\/b> None..<br><b>L. Allotey, <\/b> None..<br><b>V. Kenneth, <\/b> None..<br><b>G. Oliver, <\/b> None..<br><b>A. Nair, <\/b> None..<br><b>D. O'Brien, <\/b> None..<br><b>R. Graham, <\/b> None..<br><b>M. Borad, <\/b> None..<br><b>A. Athreya, <\/b> None..<br><b>L. Roberts, <\/b> None.","End":"4\/11\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14848","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/e5cacb06-a27b-4c63-a4e5-b25e203d4e04\/@v03B8ZAL\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"22","PosterboardNumber":"23","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"1944","PresenterBiography":null,"PresenterDisplayName":"Linsey Jackson, BS","PresenterKey":"1db6827b-9672-4997-8902-31e239dea8c3","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"1944. Prognostic biomarkers for gallbladder cancer: A machine learning approach","SearchResultFooter":"","SearchResultHeader":"Apr 11 2022  1:30PM","SessionId":"301","SessionOnDemand":"False","SessionTitle":"Machine Learning Across Cancer Research","ShowChatLink":"false","Start":"4\/11\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Prognostic biomarkers for gallbladder cancer: A machine learning approach","Topics":null,"cSlideId":""}]