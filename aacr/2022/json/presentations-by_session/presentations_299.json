[{"Abstract":"Antibody-Drug-Conjugates (ADCs) are biopharmaceutical drugs designed for targeted tumor therapy, meant to improve therapeutic index by restricting drug delivery to tumor cells that express the target antigen. ADCs bind to the target molecule on the cell membrane, which triggers internalization, linker cleavage, and ultimately drug release inside the target cell. Prospective patient selection can be done by quantifying the level of target expression in the tumor using immuno-histochemistry (IHC). However, this process typically involves pathologists and is time consuming, expensive, and prone to human bias. We have developed a supervised deep learning algorithm that segments IHC images of invasive tumor epithelium into individual epithelial cells and their membrane, cytoplasm and nucleus with high accuracy. On unseen test data its performance for epithelial cell detection and segmentation is comparable to the inter-pathologist consensus. With our algorithm, we can describe the target molecule distribution of individual cells in a fully quantitative fashion after using standard IHC methods: we call our approach Quantitative Continuous Score (QCS). We applied QCS to interrogate the mechanism of action of AZD8205, a B7-H4 directed ADC incorporating a novel topoisomerase I linker-warhead. Pharmacodynamic effects were evaluated in vivo, using a human tumor xenograft mouse model and the cell line HT29-huB7-H4 Clone 26, engineered to express human B7-H4. After tumors grew in volume to approximately 250 to 300 mm<sup>3<\/sup>, animals were randomized and each mouse received an IV injection of either AZD8205 (1.25, 3.5, or 7 mg\/kg) or control articles. Tumors were collected at designated timepoints, fixed in 10% neutral buffered formalin and subsequently embedded into paraffin blocks. IHC and QCS were then used to examine human IgG, &#947;H2AX foci, cleaved caspase-3, and epithelial cell density in tumor samples over time. Using our novel approach we could quantitatively measure the level of AZD8205 bound to tumor cells, with the highest level of ADC on the cell membrane detected at 24-48 hrs. Increased dose levels accelerated the binding kinetics of the drug and led to to a 4- and 3-fold excess of &#947;H2AX and CC-3 respectively, as well as more cells being killed, with up to 2\/3 of all epithelial cells dead at the highest dose studied. In summary, we here set the basis for future mechanistic investigation of model systems using computational pathology to improve our understanding of ADC effects. Computational pathology has the potential to determine molecule abundance quantitatively, increase throughput and avoid human bias. Our data implies QCS has the potential to identify patients who may respond to AZD8205, which we will interrogate further and integrate into future clinical studies.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/3183989d-5f81-44fa-a61f-ffeb1d523b42\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Antibody-drug conjugate (ADC),Deep learning,Pharmacodynamics,Xenografts,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14708"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Philipp Wortmann<\/i><\/u><\/presenter>, <presenter><i>Tze Heng Tan<\/i><\/presenter>, <presenter><i>Susanne Haneder<\/i><\/presenter>, <presenter><i>Andrea Ennio Storti<\/i><\/presenter>, <presenter><i>Ansh Kapil<\/i><\/presenter>, <presenter><i>Jon Chesebrough<\/i><\/presenter>, <presenter><i>Daniel Sutton<\/i><\/presenter>, <presenter><i>Michal Sulikowski<\/i><\/presenter>, <presenter><i>Arthur Lewis<\/i><\/presenter>, <presenter><i>Sofia Koch<\/i><\/presenter>, <presenter><i>Steve Sweet<\/i><\/presenter>, <presenter><i>Zifeng Song<\/i><\/presenter>, <presenter><i>David Chain<\/i><\/presenter>, <presenter><i>Yeoun Jin Kim<\/i><\/presenter>, <presenter><i>Nadia Luheshi<\/i><\/presenter>, <presenter><i>Krista Kinneer<\/i><\/presenter>, <presenter><i>Zachary A. Cooper<\/i><\/presenter>, <presenter><i>Marlon Rebelatto<\/i><\/presenter>, <presenter><i>Günter Schmidt<\/i><\/presenter>, <presenter><i>Hadassah Sade<\/i><\/presenter>, <presenter><i>J. Carl Barrett<\/i><\/presenter>. AstraZeneca, Munich, Germany, AstraZeneca, Gaithersburg, MD, AstraZeneca, Cambridge, United Kingdom, AstraZeneca, Cambridge, United Kingdom, AstraZeneca, Cambridge, MA","CSlideId":"","ControlKey":"e6c25833-911b-430c-a019-44795df2f14a","ControlNumber":"1879","DisclosureBlock":"<b>&nbsp;P. Wortmann, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>T. H. Tan, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>S. Haneder, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>A. E. Storti, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>A. Kapil, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>J. Chesebrough, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>D. Sutton, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>M. Sulikowski, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>A. Lewis, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>S. Koch, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>S. Sweet, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>Z. Song, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>D. Chain, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>Y. J. Kim, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>N. Luheshi, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>K. Kinneer, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>Z. A. Cooper, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>M. Rebelatto, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>G. Schmidt, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>H. Sade, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>J. Barrett, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14708","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/3183989d-5f81-44fa-a61f-ffeb1d523b42\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"1","PosterboardNumber":"3","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"452","PresenterBiography":null,"PresenterDisplayName":"Philipp Wortmann, MS;PhD","PresenterKey":"a0fb6b33-58b5-4d5d-b5a1-43837e0bbd00","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"452. Development and implementation of image analysis-based Quantitative Continuous Score (QCS) for B7-H4 IHC to understand AZD8205 pharmacodynamics","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Development and implementation of image analysis-based Quantitative Continuous Score (QCS) for B7-H4 IHC to understand AZD8205 pharmacodynamics","Topics":null,"cSlideId":""},{"Abstract":"<b>Introduction: <\/b>There is growing evidence that supports the role of the tumor microenvironment (TME) in the development and progression of hepatocellular carcinoma (HCC). However, the correlation between its composition and prognosis remain unclear. TME evaluation requires a combination of cell type and spatial information. These information can be obtained with the use of immunohistochemistry on patient derived slides. However, the IHC quantification remains a challenge. Computational methods such as artificial intelligence-based tool, may expedite the detection and classification thousands of different cells, expanding our understanding of the TME. Here, we aim to develop an AI based image analysis pipeline to define morphological and immunological characteristics of HCC-TME, as well as their relationship with clinicopathological features.<br \/><b>Materials and Methods: <\/b>We collected 98 HCC samples from liver resections available in the . TME composition of the tumors was evaluated and classified as inflamed, immune excluded and immune desert. Tumor slides were stained with a panel of TME markers (CD3, CD8, FOXP3, TIGIT, RORgt, ICOS, GranzymeB CD163, iNOS, PD-1, PD-L1) by IHC. The slides were digitalised and whole slide images were used for the quantification. The samples were split into training (80%) and test (20%) datasets and used to train convolutional neural network (CNN) models. For the quantification of immune cells, we trained two separate CNNs: cell detection and tumor-stroma segmentation. Cell nucleus instance segmentation was achieved using StarDist package (Schmidt et al 2018). We trained a model with our slides and tested the pretrained model (2D_versatile_he) which is for H&#38;E stained images. Immune cells were classified using random forest classifier in QuPath. Finally, we trained a CNN in UNET architecture with ResNet34 backbone for semantic segmentation of tumor tissue into parenchyma, stroma and debris classes, by fastai deep learning library.<br \/><b>Results: <\/b>The accuracy of pretrained StarDist model was limited to 72% on IHC slide images. Thus, we trained a new cell nucleus instance segmentation StarDist model with our dataset and it reached 84% accuracy, 91.3% F1-Score, 92% true positive, 90.6% true negative rates on IHC slide images. Random forest classifier annotated immune cells at 98% accuracy. The tissue segmentation model classified tumor regions into parenchyma, stroma and debris at 95,8% accuracy, 92.5% dice, 86.3% IuO.<br \/><b>Conclusions: <\/b>In this study we developed a pipeline implementing open-source solutions to quantify IHC slides. The use of this semi-automatized computational pathology workflow can provide robust information in regard of the TME composition augmenting the discovering tumour specific TME features and pave way for the discovery of novel prognostic and therapeutic targets.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/636ce538-2f31-4b55-be65-ab0d1c4a3001\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Hepatocellular carcinoma,Image analysis,Tumor microenvironment,Immunohistochemistry,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14709"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Caner Ercan<\/i><\/u><\/presenter>, <presenter><i>Mairene Coto-Llerena<\/i><\/presenter>, <presenter><i>Salvatore Piscuoglio<\/i><\/presenter>, <presenter><i>Luigi M. Terracciano<\/i><\/presenter>. University of Basel, University Hospital of Basel, Institute of Medical Genetics and Pathology, Basel, Switzerland","CSlideId":"","ControlKey":"f80160cb-c22e-41e4-bb93-46a66692e836","ControlNumber":"4494","DisclosureBlock":"&nbsp;<b>C. Ercan, <\/b> None..<br><b>M. Coto-Llerena, <\/b> None..<br><b>S. Piscuoglio, <\/b> None..<br><b>L. M. Terracciano, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14709","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/636ce538-2f31-4b55-be65-ab0d1c4a3001\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"2","PosterboardNumber":"4","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"453","PresenterBiography":null,"PresenterDisplayName":"Caner Ercan, MD;PhD","PresenterKey":"e3f9f1eb-30f0-4281-8e6e-da2b63747f20","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"453. Establishing quantitative image analysis methods for tumor microenvironment evaluation","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Establishing quantitative image analysis methods for tumor microenvironment evaluation","Topics":null,"cSlideId":""},{"Abstract":"Background: The current computational analyses of multi to hyperplexed fluorescence and\/or mass spectrometry image datasets from patient pathology samples are not powerful enough to extract the maximum amount of information or to create the detailed knowledge that is required to advance precision medicine in pathology, including the development of personalized therapeutic strategies, identification of potential novel targets for drug discovery, selection of optimal patient cohorts for clinical trials, and improvement of the predictive power of prognostics\/diagnostics.<br \/>Methods: TumorMapr harnesses the computational power of proprietary, unbiased spatial analytics, spatial systems pathology, and explainable artificial intelligence (xAI) to extract information and to create knowledge from patient primary disease pathology samples imaged on any of the existing fluorescence and\/or mass spectrometry imaging platforms.<br \/>Results: To demonstrate the generalizability and utility of the TumorMapr platform, we apply it on two different datasets: hyperplexed immunofluorescence-based colorectal cancer data (51 biomarkers, 431 patients) and imaging mass cytometry-based breast cancer data (35 biomarkers, 281 patients). The TumorMapr platform (i) unlike the biased intensity thresholding approaches, the unbiased and automated functional cell phenotyping discovers a continuum of cell types and cell states, including transitional, multi-transitional cell states and fusion cell types that are critical for disease progression; (ii) derives microdomains with tumor promoting and tumor suppressing properties that are highly predictive of disease progression and response to therapy; (iii) spatial systems pathology analysis taps into the current network biology knowledge databases to derive pathway interactions and signaling networks, identify novel biomarkers and potential molecular targets and drugs, in the spatial context of each microdomain; (iv) xAI application guide, for example, in the case of predicting 5-year risk of recurrence in CRC patients, provides explanations in the form of microdomain-specific networks that are driving disease progression. Using the TumorMapr pipeline we created a prognostic test that shows a vastly superior performance over current approaches in predicting 5-yr risk of recurrence in CRC patients. Further, the TumorMapr platform enables building a rich outcome-specific library of microdomains to directly apply on prospective tissue samples for a companion diagnostic test that predicts disease outcomes.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/11ee61f1-3906-4f86-8a18-5a4baa316bf3\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Tumor microenvironment,,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14710"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Samantha Panakkal<\/i><\/presenter>, <presenter><i>Brian Falkenstein<\/i><\/presenter>, <presenter><i>Akif Burak Tosun<\/i><\/presenter>, <presenter><i>Bruce Campbell<\/i><\/presenter>, <presenter><i>Michael Becich<\/i><\/presenter>, <presenter><i>Jeffrey Fine<\/i><\/presenter>, <presenter><i>D. Lansing Taylor<\/i><\/presenter>, <presenter><i>S. Chakra Chennubhotla<\/i><\/presenter>, <presenter><u><i>Filippo Pullara<\/i><\/u><\/presenter>. SpIntellx, Inc., Pittsburgh, PA","CSlideId":"","ControlKey":"b4bed033-72c2-4382-b0b7-47ba159641fb","ControlNumber":"6048","DisclosureBlock":"<b>&nbsp;S. Panakkal, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment, Yes. <br><b>B. Falkenstein, <\/b> <br><b>SpIntellx, Inc.<\/b> Independent Contractor, Yes. <br><b>A. B. Tosun, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment, Yes. <br><b>B. Campbell, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment, Yes. <br><b>M. Becich, <\/b> <br><b>SpIntellx, Inc.<\/b> Other Business Ownership, Yes. <br><b>J. Fine, <\/b> <br><b>SpIntellx, Inc.<\/b> Other Business Ownership, Yes. <br><b>D. Taylor, <\/b> <br><b>SpIntellx, Inc.<\/b> Other Business Ownership, Yes. <br><b>S. Chennubhotla, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment, Yes. <br><b>F. Pullara, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment, Yes.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14710","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/11ee61f1-3906-4f86-8a18-5a4baa316bf3\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"3","PosterboardNumber":"5","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"454","PresenterBiography":null,"PresenterDisplayName":"Filippo Pullara, PhD","PresenterKey":"13fb68f9-18c6-429a-9a29-b5d422b0eadb","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"454. TumorMapr&#8482; analytical software platform: Unbiased spatial analytics and explainable AI (xAI) platform for generating data, extracting information, and creating knowledge from multi to hyperplexed fluorescence and\/or mass spectrometry image datasets","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"TumorMapr&#8482; analytical software platform: Unbiased spatial analytics and explainable AI (xAI) platform for generating data, extracting information, and creating knowledge from multi to hyperplexed fluorescence and\/or mass spectrometry image datasets","Topics":null,"cSlideId":""},{"Abstract":"<b>Background: <\/b>Modern diagnostic pathology workflows involve the integration of histomorphologic, immunohistochemical (IHC), and molecular data to reach a final diagnosis. Recently, advances in deep learning have revolutionized pathology by providing the prospect for expert-level autonomous image analysis tools. Despite recent innovations in deep learning, integrating histomorphologic and molecular information found on respective H&#38;E- and IHC-stained tissue sections still remains a challenge. Here, we aim to address this issue by incorporating computer vision tools, including deep learning and scale-invariant feature transform (SIFT), to align H&#38;E-stained sections with accompanying IHC studies for automated subclassification of gliomas.<br \/><b>Methods:<\/b> To test the workflow, we trained the publicly available VGG19 convolutional neural network (CNN) using patches of pathologist-annotated H&#38;E-stained WSIs to recognize histological patterns of 16 common tissue and brain tumor classes, including diffuse glioma, meningioma, metastatic carcinoma, and schwannoma. To complement the histomorphologic analysis, we optimized several deep learning classifiers, including Mask R-CNN, to recognize various IHC markers, such as Ki-67, IDH1-R132H and ATRX, relevant for molecular subclassification of gliomas. For the integrated analysis, we employed SIFT to align lesional regions of H&#38;E and IHC images.<br \/><b>Results: <\/b>The histomorphologic classifier excelled at classification with accuracies of 100% for glioma, meningioma and metastatic carcinoma, and 93% for schwannoma (n = 125). The Mask R-CNN was tested on 147 images generated from 34 brain tumor Ki-67 WSIs and showed a high concordance with aggregate pathologists&#8217; estimates (n = 3 assessors; y = 0.9712x -1.945, r = 0.9750). Using the deep learning classifiers and SIFT, we were able to identify tumor regions from the H&#38;E images and align them to their corresponding IHC images. This resulted in significant improvement of ATRX and IDH1-R132H quantification compared to unaligned WSIs. Finally, SIFT and partially sampling the lesional regions decreased computational time significantly without compromising accuracy.<br \/><b>Conclusion: <\/b>SIFT can work in concert with deep learning tools to help examine the histomorphologic and molecular patterns of various brain tumors and provide a framework for integrating deep learning tools to provide automated diagnoses.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/fa6afb56-a565-450e-86cd-90b84fb01ca8\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Deep learning,Immunohistochemistry,Diagnosis,Brain\/central nervous system cancers,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14711"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Michael K. Lee<\/i><\/u><\/presenter>, <presenter><i>Kevin Faust<\/i><\/presenter>, <presenter><i>Madhumitha Rabindranath<\/i><\/presenter>, <presenter><i>Phedias Diamandis<\/i><\/presenter>. University of Toronto, Toronto, ON, Canada, University of Toronto, Toronto, ON, Canada","CSlideId":"","ControlKey":"f518c14a-132d-4567-ad86-4b180e977137","ControlNumber":"2169","DisclosureBlock":"&nbsp;<b>M. K. Lee, <\/b> None..<br><b>K. Faust, <\/b> None..<br><b>M. Rabindranath, <\/b> None..<br><b>P. Diamandis, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14711","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/fa6afb56-a565-450e-86cd-90b84fb01ca8\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"4","PosterboardNumber":"6","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"455","PresenterBiography":null,"PresenterDisplayName":"Michael Lee, BS","PresenterKey":"21ef9da7-e650-4a30-b505-dc6721808ca7","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"455. Automating integration of histomorphologic and immunohistochemistry data using computer vision tools","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Automating integration of histomorphologic and immunohistochemistry data using computer vision tools","Topics":null,"cSlideId":""},{"Abstract":"For over 100 years, the traditional tools of pathology, such as tissue-marking dyes (e.g. the H&#38;E stain) have been used to study the disorganization and dysfunction of cells within tissues. This has represented a principal diagnostic and prognostic tool in cancer. However, in the last 5 years, new technologies have promised to revolutionize histopathology, with Spatial Transcriptomics technologies allowing us to measure gene expression directly in pathology-stained tissue sections. In parallel with these developments, Artificial Intelligence (AI) applied to histopathology tissue images now approaches pathologist level performance in cell type identification. However, these new technologies still have severe limitations, with Spatial Transcriptomics suffering difficulties distinguishing transcriptionally similar cell types, and AI-based pathology tools often performing poorly on real world out-of-batch test datasets. Thus, century-old techniques still represent standard-of-care in most areas of clinical cancer diagnostics and prognostics. Here, we present a new frontier in digital pathology: describing a conceptually novel computational methodology, based on Bayesian probabilistic modelling, that allows Spatial Transcriptomics data to be leveraged <i>together<\/i> with the output of deep learning-based AI used to computationally annotate H&#38;E-stained sections of the same tumor. By leveraging cell-type annotations from multiple independent pathologists, we show that this integrated methodology achieves better performance than any given pathologist&#8217;s manual tissue annotation<b><i> <\/i><\/b>in the task of identifying regions of immune cell infiltration in breast cancer, and easily outperforms either technology alone. We also show that on a subset of histopathology slides examined, the methodology can identify regions of clinically relevant immune cell infiltration that were missed entirely by an initial pathologist&#8217;s manual annotation. While this use case has clear diagnostic and prognostic value in cancer (e.g. predicting response to immunotherapy), our methodology is generalizable to any type of pathology images and also has broad applications in spatial transcriptomics data analytics, where most applications (such as identifying cell-cell interactions) rely on correct cell type annotations having been established <i>a priori<\/i>. We anticipate that this work will spur many follow-up studies, including new computational innovations building on the approach. The work sets the stage for better-than-pathologist performance in other cell-type annotation tasks, with relevant applications in diagnostics and prognostics across almost all cancers.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/47e48a03-c43f-4b07-98f9-8110f8d53cba\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Genomics,,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14712"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Asif Zubair<\/i><\/presenter>, <presenter><i>Rich Chapple<\/i><\/presenter>, <presenter><i>Sivaraman Natarajan<\/i><\/presenter>, <presenter><i>William C. Wright<\/i><\/presenter>, <presenter><i>Min Pan<\/i><\/presenter>, <presenter><i>Hyeong-Min Lee<\/i><\/presenter>, <presenter><i>Heather Tillman<\/i><\/presenter>, <presenter><i>John Easton<\/i><\/presenter>, <presenter><u><i>Paul Geeleher<\/i><\/u><\/presenter>. St. Jude Children's Research Hospital, Memphis, TN","CSlideId":"","ControlKey":"e7449280-2724-4064-8a80-4d6efd0799e9","ControlNumber":"628","DisclosureBlock":"&nbsp;<b>A. Zubair, <\/b> None..<br><b>R. Chapple, <\/b> None..<br><b>S. Natarajan, <\/b> None..<br><b>W. C. Wright, <\/b> None..<br><b>M. Pan, <\/b> None..<br><b>H. Lee, <\/b> None..<br><b>H. Tillman, <\/b> None..<br><b>J. Easton, <\/b> None..<br><b>P. Geeleher, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14712","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/47e48a03-c43f-4b07-98f9-8110f8d53cba\/@t03B8ZAz\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"5","PosterboardNumber":"7","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"456","PresenterBiography":null,"PresenterDisplayName":"Paul Geeleher, PhD","PresenterKey":"c0497291-ad9f-46a8-a17d-b30d899a36a5","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"456. Jointly leveraging spatial transcriptomics and deep learning models for image annotation achieves better-than-pathologist performance in cell type identification in tumors","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Jointly leveraging spatial transcriptomics and deep learning models for image annotation achieves better-than-pathologist performance in cell type identification in tumors","Topics":null,"cSlideId":""},{"Abstract":"<b>Background:<\/b> Automated cell-level characterization of the tumor microenvironment (TME) at scale is key to data-driven immuno-oncology. Artificial intelligence (AI)-powered analysis of hematoxylin and eosin (H&#38;E) images scales and has recently been translated into diagnostics. However, robust TME analysis solely based on H&#38;E data is bound by the stain's properties and by manual pathologist annotations, both in number and accuracy. In this study, we quantify the error introduced by pathologists' morphological assessment and mitigate this error by training AI-systems without manual pathologist annotations, using labels determined directly from IHC profiles.<br \/><b>Methods:<\/b> The work was carried out on 239 clinical NSCLC cases. CK-KL1, CD3+CD20, and Mum1 were used for defining carcinoma (CA), lymphocyte (LY), and plasma (PL) cells. For evaluation, representative regions were annotated by 3 trained pathologists. The workflow is based on co-registration of same-section H&#38;E and IHC stained images with single cell precision. Cells were detected in H&#38;E and labelled using rule-based algorithms that incorporated IHC information. This H&#38;E data was used to train neural networks (NN).<br \/><b>Results:<\/b> (A) The inter-rater agreement of pathologists annotating on H&#38;E is increased when information from registered IHC images is provided. (B) The concordance of pathologists on H&#38;E-only compared to on H&#38;E+IHC shows that pathologists miss or misclassify cells with a certain error. (C) NNs trained with IHC-based labels achieve similar performance for cell type classification on H&#38;E as pathologists on H&#38;E.<br \/><b>Conclusion: <\/b>This study demonstrates the value of combining histomorphological and IHC data for improved cell annotation. Our novel workflow provides a quantitative benchmark and facilitates training of accurate AI models for quantitative characterization of tumor and TME from H&#38;E sections. <table class=\"AbstractTable\" id=\"{50B9697C-2E32-4A10-AFD1-F5353E7FFE26}\"><caption class=\"AbstractTableCaption\"><\/caption><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>A) Inter-rater agreement by metric, stain, and cell type<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>By cell count<\/b>, Pearson correlation<\/td><td rowspan=\"1\" colspan=\"1\"><b>By cell count<\/b>, Pearson correlation<\/td><td rowspan=\"1\" colspan=\"1\"><b>By cell location<\/b>, Krippendorff&#8217;s alpha<\/td><td rowspan=\"1\" colspan=\"1\"><b>By cell location<\/b>, Krippendorff&#8217;s alpha<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Cell type<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>H&#38;E-only <\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>H&#38;E+IHC <\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>H&#38;E-only <\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>H&#38;E+IHC<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">CA<\/td><td rowspan=\"1\" colspan=\"1\">0.86<\/td><td rowspan=\"1\" colspan=\"1\">0.98<\/td><td rowspan=\"1\" colspan=\"1\">0.43<\/td><td rowspan=\"1\" colspan=\"1\">0.90<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">LY<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><td rowspan=\"1\" colspan=\"1\">0.99<\/td><td rowspan=\"1\" colspan=\"1\">0.21<\/td><td rowspan=\"1\" colspan=\"1\">0.76<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">PL<\/td><td rowspan=\"1\" colspan=\"1\">0.77<\/td><td rowspan=\"1\" colspan=\"1\">0.96<\/td><td rowspan=\"1\" colspan=\"1\">0.32<\/td><td rowspan=\"1\" colspan=\"1\">0.87<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>B) Performance of individual pathologists in H&#38;E<\/b><\/td><td rowspan=\"1\" colspan=\"2\"><b>Against consensus in H&#38;E+IHC<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Against own annotations in H&#38;E+IHC<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Against own annotations in H&#38;E+IHC<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Cell type<\/b><\/td><td rowspan=\"1\" colspan=\"2\"><b>By cell count<\/b>, Pearson correlation<\/td><td rowspan=\"1\" colspan=\"1\"><b>By cell location<\/b>, Precision<\/td><td rowspan=\"1\" colspan=\"1\"><b>By cell location<\/b>, Recall<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">CA<\/td><td rowspan=\"1\" colspan=\"2\">0.84<\/td><td rowspan=\"1\" colspan=\"1\">0.76<\/td><td rowspan=\"1\" colspan=\"1\">0.77<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">LY<\/td><td rowspan=\"1\" colspan=\"2\">0.78<\/td><td rowspan=\"1\" colspan=\"1\">0.70<\/td><td rowspan=\"1\" colspan=\"1\">0.60<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">PL<\/td><td rowspan=\"1\" colspan=\"2\">0.76<\/td><td rowspan=\"1\" colspan=\"1\">0.69<\/td><td rowspan=\"1\" colspan=\"1\">0.21<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"5\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"5\"><b>C) NN against annotator H&#38;E+IHC consensus<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Cell Type<\/b><\/td><td rowspan=\"1\" colspan=\"4\"><b>By cell count<\/b>, Pearson correlation<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">CA<\/td><td rowspan=\"1\" colspan=\"4\">0.84<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">LY<\/td><td rowspan=\"1\" colspan=\"4\">0.92<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">PL<\/td><td rowspan=\"1\" colspan=\"4\">0.75<\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/a4497178-671c-4b9e-a379-194e3fa2657a\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Tumor microenvironment,Deep learning,Image analysis,Immunohistochemistry,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14714"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Thomas Mrowiec<\/i><\/u><\/presenter>, <presenter><i>Sharon Ruane<\/i><\/presenter>, <presenter><i>Simon Schallenberg<\/i><\/presenter>, <presenter><i>Gabriel Dernbach<\/i><\/presenter>, <presenter><i>Rumyana Todorova<\/i><\/presenter>, <presenter><i>Cornelius Böhm<\/i><\/presenter>, <presenter><i>Walter De Back<\/i><\/presenter>, <presenter><i>Blanca Pablos<\/i><\/presenter>, <presenter><i>Roman Schulte-Sasse<\/i><\/presenter>, <presenter><i>Ivana Trajanovska<\/i><\/presenter>, <presenter><i>Adelaida Creosteanu<\/i><\/presenter>, <presenter><i>Emil Barbuta<\/i><\/presenter>, <presenter><i>Marcus Otte<\/i><\/presenter>, <presenter><i>Christian Ihling<\/i><\/presenter>, <presenter><i>Hans Juergen Grote<\/i><\/presenter>, <presenter><i>Juergen Scheuenpflug<\/i><\/presenter>, <presenter><i>Viktor Matyas<\/i><\/presenter>, <presenter><i>Maximilian Alber<\/i><\/presenter>, <presenter><i>Frederick Klauschen<\/i><\/presenter>. EMD Serono, Billerica, MA, Aignostics, Berlin, Germany, Charité, Berlin, Germany, LMU Munich, Munich, Germany","CSlideId":"","ControlKey":"0f9b90be-0a80-4222-9019-67833a19cfe6","ControlNumber":"2440","DisclosureBlock":"<b>&nbsp;T. Mrowiec, <\/b> <br><b>EMD Serono \/ Merck KGaA Healthcare, Darmstadt, Germany<\/b> Employment, Stock Option, Yes. <br><b>S. Ruane, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>S. Schallenberg, <\/b> <br><b>Institute of Pathology, Charité Berlin, Germany<\/b> Employment, Yes. <br><b>G. Dernbach, <\/b> <br><b>Institute of Pathology Charité, Berlin, Germany<\/b> Employment, Yes. <br><b>R. Todorova, <\/b> <br><b>Institute of Pathology, LMU Munich, Germany<\/b> Employment, Yes. <br><b>C. Böhm, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>W. de Back, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>B. Pablos, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>R. Schulte-Sasse, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>I. Trajanovska, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>A. Creosteanu, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>E. Barbuta, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>M. Otte, <\/b> <br><b>EMD Serono \/ Merck Heathcare KGaA, Darmstadt, Germany<\/b> Employment, Yes. <br><b>C. Ihling, <\/b> <br><b>EMD Serono \/ Merck Heathcare KGaA, Darmstadt, Germany<\/b> Employment, Yes. <br><b>H. Grote, <\/b> <br><b>EMD Serono \/ Merck Heathcare KGaA, Darmstadt, Germany<\/b> Employment, Yes. <br><b>J. Scheuenpflug, <\/b> <br><b>EMD Serono \/ Merck Heathcare KGaA, Darmstadt, Germany<\/b> Employment, Yes. <br><b>V. Matyas, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>M. Alber, <\/b> <br><b>Aignostics, Berlin, Germany<\/b> Employment, Yes. <br><b>F. Klauschen, <\/b> <br><b>Institute of Pathology, LMU Munich, Germany<\/b> Employment, No. <br><b>BIFOLD, Berlin, Germany<\/b> Other Business Ownership, No. <br><b>Institute of Pathology, Charité Berlin, Germany<\/b> Other Business Ownership, Yes. <br><b>German Cancer Consortium (DKTK), Partner Site Berlin, German Cancer Research Center (DKFZ)<\/b> Other Business Ownership. <br><b>Berlin Institute of Health, Berlin, Germany<\/b> Other Business Ownership, No.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14714","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/a4497178-671c-4b9e-a379-194e3fa2657a\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"6","PosterboardNumber":"8","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"457","PresenterBiography":null,"PresenterDisplayName":"Thomas Mrowiec, Dr Rer Nat,BS","PresenterKey":"6c3635f6-7a8c-4af8-aafb-ff790c861e43","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"457. Immunohistochemistry-informed AI systems for improved characterization of tumor-microenvironment in clinical non-small cell lung cancer H&#38;E samples","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Immunohistochemistry-informed AI systems for improved characterization of tumor-microenvironment in clinical non-small cell lung cancer H&#38;E samples","Topics":null,"cSlideId":""},{"Abstract":"Background\/Objective: Optical coherence tomography (OCT) is the optical analog of high-frequency ultrasound and produces real-time, high-resolution images up to 2 mm deep. Multi-reader studies of OCT have shown differentiation of normal parenchyma from neoplasms, including DCIS and cancers, with &#62;85% sensitivity and specificity. Intraoperative evaluation of breast lumpectomy margins (LMs) with OCT may help achieve negative margins at primary surgery and avoid re-excision. Artificial Intelligence can be trained to spot regions of interest (ROI) in OCT LM images suspicious for malignancy. The purpose of this study was to develop and validate an automated convolutional neural network (CNN) to screen OCT LM images for ROIs.<br \/>Methods: Following IRB approval, LMs from 126 patients with ductal malignancy were OCT imaged. Images were compared to corresponding permanent histology and annotated by breast pathologists to create a training set of 25,000 control ROIs. A CNN algorithm was developed with 3 convolutional layers, a 3x3 kernel, and 3 fully connected layers to perform binary classification of images as &#8220;suspicious&#8221; or &#8220;non-suspicious&#8221; for malignancy. A weighted loss function was used to balance the training data for non-suspicious vs. suspicious images and to tune sensitivity and specificity. Once trained and weighted, the CNN was tested in a prospective study using OCT images of 29 LMs from 29 patients with biopsy-proven ductal carcinoma in situ (DCIS), invasive ductal carcinoma (IDC), or both. CNN results were compared to permanent histology.<br \/>Results: The patient population was 61.5 &#177; 7.3 years old, 100% female, with Stage 0-1 disease. Disease included IDC (n=20), invasive lobular (n=2), DCIS (n=27), mixed (n=74), atypical ductal hyperplasia (n=24), as well as benign findings including atypical lobular hyperplasia (n=19), lymphatic invasion (n=13), lobular carcinoma in situ (n=12), usual ductal hyperplasia (n=35), and duct ectasia (n=17). Following primary surgery, LMs were scanned using OCT and images were CNN analyzed. Approximately 1.9 M OCT ROIs were assessed, identifying 101,099 suspicious ROIs. Three hundred and eighty-four (384) ROIs were correctly identified, yielding a 70% true positive and 5.2% false positive rate with 70% sensitivity and 96% specificity. The receiver operating curve is shown below.<br \/>Conclusions: Automated analysis of OCT images using a trained CNN to identify ROIs suspicious for DCIS or IDC in LMs is feasible, demonstrating high concordance with permanent pathology. These findings indicate the utility of AI for screening OCT images with potential utilization for intraoperative evaluation of LMs. A pivotal prospective clinical trial will be necessary to evaluate breast specimens in real time to determine if this application may improve re-excision rates in lumpectomy.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/44614374-ead5-4936-a5ee-d85fd3cb1511\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Breast cancer,Imaging,Cancer detection,Deep learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14718"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>David Rempel<\/i><\/u><\/presenter>, <presenter><i>Andrew Berkeley<\/i><\/presenter>, <presenter><i>Chandandeep Nagi<\/i><\/presenter>, <presenter><i>Vladimir Pekar<\/i><\/presenter>, <presenter><i>Margaret Burns<\/i><\/presenter>, <presenter><i>Beryl Augustine<\/i><\/presenter>, <presenter><i>Alia Nazarullah<\/i><\/presenter>, <presenter><i>Ismail Jatoi<\/i><\/presenter>, <presenter><i>Kelly K. Hunt<\/i><\/presenter>, <presenter><i>Alastair Thompson<\/i><\/presenter>, <presenter><i>Savitri Krishnamurthy<\/i><\/presenter>. Perimeter Medical Imaging AI, Inc., Toronto, ON, Canada, Baylor College of Medicine, Houston, TX, Illumisonics Inc., Toronto, ON, Canada, University of Texas Health Science Center at San Antonio, San Antonio, TX, The University of Texas MD Anderson Cancer Center, Houston, TX","CSlideId":"","ControlKey":"1814e0e8-d3fc-4ebb-92cd-80f35b73facf","ControlNumber":"5444","DisclosureBlock":"<b>&nbsp;D. Rempel, <\/b> <br><b>Employee of Perimeter Medical Imaging AI, Inc.<\/b> Employment, Stock, Stock Option, Yes. <br><b>A. Berkeley, <\/b> <br><b>Employee of Perimeter Medical Imaging AI, Inc.<\/b> Employment, Stock, Stock Option.<br><b>C. Nagi, <\/b> None.&nbsp;<br><b>V. Pekar, <\/b> <br><b>Previous employment at Perimeter Medical Imaging AI, Inc.<\/b> Employment. <br><b>M. Burns, <\/b> <br><b>Employee at Perimeter Medical Imaging AI, Inc.<\/b> Employment, Stock, Stock Option. <br><b>B. Augustine, <\/b> <br><b>Employee at Perimeter Medical Imaging AI, Inc.<\/b> Employment, Stock, Stock Option.<br><b>A. Nazarullah, <\/b> None..<br><b>I. Jatoi, <\/b> None..<br><b>K. K. Hunt, <\/b> None..<br><b>A. Thompson, <\/b> None..<br><b>S. Krishnamurthy, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14718","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/44614374-ead5-4936-a5ee-d85fd3cb1511\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"7","PosterboardNumber":"9","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"458","PresenterBiography":null,"PresenterDisplayName":"David Rempel","PresenterKey":"df06a7f3-8daa-45ad-9f0e-5b3312463039","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"458. Development and validation of convolutional neural network to identify regions of interest in lumpectomy margins using optical coherence tomography","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Development and validation of convolutional neural network to identify regions of interest in lumpectomy margins using optical coherence tomography","Topics":null,"cSlideId":""},{"Abstract":"<b>Background:<\/b> Pancreatic ductal adenocarcinoma (PDAC) has proven a difficult cancer to treat. To improve treatment strategies, molecular subtypes have been identified, one being immunogenic with significant immune infiltrate and better prognosis. These subtypes have been determined by RNA profiling, which often exhibits technical challenges in a clinical setting. Here we present a deep learning-based method to identify PDAC immunogenic patients using H&#38;E images. This method is robust to RNA quality issues and can elucidate unique morphological features not obtainable with RNA profiling to refine the selection of patients with this phenotype.<br \/><b>Methods: <\/b>Patients (n=265) were primarily stage II or IV, treated previously with gemcitabine+nab-paclitaxel or FOLFIRINOX. Ground truth for immunogenic subtype (n=105) was defined with RNASeq. Whole slide images were subdivided into non-overlapping, fixed-size tiles at 4 magnifications: 2.5x, 5x, 10x, 20x, followed by feature extraction using a ResNet50 convolutional neural network. Principal component (PC) analysis reduced dimensionality of extracted features in each tile. The dataset was split into 80% training, 20% testing. Posterior probabilities from a linear model were inputs to a support vector machine to predict outcome (2-step model). Progression- free survival (PFS) was evaluated using the Kaplan Meier method.<br \/><b>Results:<\/b> ImageNet-trained ResNet50 model extracted 2048 features from each tile and the first 75 PCs, explaining 87% variance, were input into the 2-step model; average AUC=0.77 (95% CI=0.70,0.83) across the 4 magnification datasets. A multi-scale ensemble approach combining these 4 magnifications improved the AUC to 0.80 (95% CI=0.66,0.93). Accuracy, sensitivity, and specificity were 0.79, 0.76, and 0.81, respectively. The predicted immunogenic subtype showed significantly improved PFS compared to the other 3 subtypes (HR 95%CI = 0.54 (0.36,0.81), p=0.003), while the RNASeq-derived immunogenic subtype had less differentiation (HR 95%CI = 0.64 (0.42,0.98), p=0.04).<br \/><b>Conclusions:<\/b> This study presents a deep learning 2-step model approach using tumor H&#38;E images to identify PDAC immunogenic subtype, with improved prognostic potential to that identified by RNA profiling, suggesting possible application in clinical settings for patient stratification. Future work will expand the model to larger independent cohorts.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2f5ea48c-6426-4776-b8ba-001091b88c87\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Deep learning,Pancreatic cancer,Image analysis,Tumor subtypes,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14719"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Han Si<\/i><\/u><\/presenter>, <presenter><i>Steven Xu<\/i><\/presenter>, <presenter><i>Anantharaman Muthuswamy<\/i><\/presenter>, <presenter><i>Ryan Liang<\/i><\/presenter>, <presenter><i>Kate Sasser<\/i><\/presenter>, <presenter><i>Hisham K. Hamadeh<\/i><\/presenter>, <presenter><i>Suzana Couto<\/i><\/presenter>, <presenter><i>Brandon Higgs<\/i><\/presenter>. Genmab, Plainsboro, NJ, Northeastern University, Boston, MA","CSlideId":"","ControlKey":"77937892-5d6b-4992-ac0e-86395003deeb","ControlNumber":"145","DisclosureBlock":"<b>&nbsp;H. Si, <\/b> <br><b>Genmab Inc<\/b> Employment, No. <br><b>S. Xu, <\/b> <br><b>Genmab<\/b> Employment. <br><b>A. Muthuswamy, <\/b> <br><b>Genmab<\/b> Employment. <br><b>R. Liang, <\/b> <br><b>Genmab<\/b> Grant\/Contract. <br><b>K. Sasser, <\/b> <br><b>Genmab<\/b> Employment. <br><b>H. K. Hamadeh, <\/b> <br><b>Genmab<\/b> Employment. <br><b>S. Couto, <\/b> <br><b>Genmab<\/b> Employment. <br><b>B. Higgs, <\/b> <br><b>Genmab<\/b> Employment.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14719","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/2f5ea48c-6426-4776-b8ba-001091b88c87\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"8","PosterboardNumber":"10","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"459","PresenterBiography":null,"PresenterDisplayName":"Han Si, PhD","PresenterKey":"2a595360-944d-4bf4-91c1-33c8964c46cd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"459. Identification of the PDAC immunogenic subtype using deep learning with multi-scaled digital H&#38;E images","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Identification of the PDAC immunogenic subtype using deep learning with multi-scaled digital H&#38;E images","Topics":null,"cSlideId":""},{"Abstract":"<b>Background:<\/b> The High Throughput Truthing (HTT) project is assessing pathologist agreement estimates of stromal tumor-infiltrating lymphocytes (sTILs) density in hematoxylin and eosin (H&#38;E) stained breast cancer biopsy slides. The HTT project will create a validation dataset for artificial intelligence and machine learning (AI\/ML) algorithms in digital pathology fit for a training, proficiency testing, and regulatory purpose.<br \/><b>Methods:<\/b> The pilot study crowdsourced pathologists to estimate sTIL density in 640 regions of interest (ROIs) across 64 slides via two modalities: an optical microscope (eeDAP) and two digital platforms (caMicroscope and PathPresenter). eeDAP is a hardware-software interface that presents the observer with pre-defined fields of view on H&#38;E slides that corresponds to the ROI on a whole slide image. The PathPresenter and caMicroscope web-applications replicate the eeDAP workflow on the whole slide image without microscope hardware. In the workflow, pathologists evaluated the eligibility of an ROI for sTILs content then estimated the densities of tumor-associated stroma and sTILs in the ROI. Inter-pathologist agreement within ROIs was characterized with the root mean-squared difference. Using 72 of the highest variability ROIs selected from the pilot study, seven practicing pathologists participated in a subsequent focus group to improve the clinical training and data-collection workflows.<br \/><b>Results:<\/b> The pilot study collected 7,373 sTIL density estimates from 35 pathologists between February 2020 and May 2021. The focus group provided an additional 411 evaluations on 72 ROIs and in-depth discussions to identify pitfalls, gaps in training, and workflow improvements. Installation of eeDAP for physical data collection guided improvements in documentation and operation capabilities. Updated training materials refine the definition of tumor-associated stroma, provide reference images to differentiate sTILs from other cell types, and provide feedback during training. Digital and microscope platforms benefitted from enforcing registration and training, standardizing workflows, and accelerating eeDAP slide-image registration.<br \/><b>Conclusions:<\/b> The slides, images, and annotations provided by volunteer collaborators and participants for our pilot study led to improvements in data collection tools and crowdsourcing workflows to ensure consistency and minimize annotation variability. Our pilot dataset and analysis methods are available on a public HTT Github repository to allow open access to our methodology and feedback from the digital pathology and statistics communities. These data-collection and analysis methods are applicable to other quantitative biomarkers for validation of AI\/ML algorithms. The lessons learned from this work will be applied to the HTT pivotal study and inform future quality data-collection methods of pathologist annotations.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/a9a5e3dc-2317-419b-9c0f-4c12814827f0\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Image analysis,Tumor infiltrating lymphocytes,Machine learning,Deep learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14721"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Katherine N. Elfer<\/i><\/u><\/presenter>, <presenter><i>Kim Blenman<\/i><\/presenter>, <presenter><i>Sarah N. Dudgeon<\/i><\/presenter>, <presenter><i>Victor Garcia<\/i><\/presenter>, <presenter><i>Anna Ehinger<\/i><\/presenter>, <presenter><i>Xiaoxian Li<\/i><\/presenter>, <presenter><i>Amy Ly<\/i><\/presenter>, <presenter><i>Dieter Peeters<\/i><\/presenter>, <presenter><i>Bruce Werness<\/i><\/presenter>, <presenter><i>Matthew Hanna<\/i><\/presenter>, <presenter><i>Roberto Salgado<\/i><\/presenter>. National Cancer Institute, Cancer Prevention Fellowship Program; United States Food and Drug Administration, Center for Devices and Radiologic Health, Office of Science and Engineering Laboratories, Division of Imaging Diagnostics & Software Reliability, Bethesda; White Oak, MD, Yale University: School of Medicine and Yale Cancer Center; School of Engineering and Applied Science, New Haven, CT, Yale University, New Haven, CT, United States Food and Drug Administration, Center for Devices and Radiologic Health, Office of Science and Engineering Laboratories, Division of Imaging Diagnostics & Software Reliability, Bethesda, MD, Lund University, Skåne University Hospital, Lund, Sweden, Emory University School of Medicine, Atlanta, GA, Massachusetts General Hospital, Boston, MA, Sint-Maarten Hospital; University of Antwerp, Mechelen; Antwerp, Belgium, Inova Health System; Arrive Bio, Falls Church, VA; San Francisco, CA, Memorial Sloan Kettering Cancer Center, New York, NY, Peter Mac Callum Cancer Centre, Division of Research, Melbourne, Australia; GZA-ZNA Hospitals, Antwerp, Belgium","CSlideId":"","ControlKey":"e1dcd19f-b42b-4aea-8acc-968a00c5cd21","ControlNumber":"1470","DisclosureBlock":"&nbsp;<b>K. N. Elfer, <\/b> None..<br><b>K. Blenman, <\/b> None..<br><b>S. N. Dudgeon, <\/b> None..<br><b>V. Garcia, <\/b> None..<br><b>A. Ehinger, <\/b> None..<br><b>X. Li, <\/b> None..<br><b>A. Ly, <\/b> None..<br><b>D. Peeters, <\/b> None.&nbsp;<br><b>B. Werness, <\/b> <br><b>Inova Health System<\/b> Employment, No. <br><b>Arrive Bio<\/b> No.<br><b>M. Hanna, <\/b> None..<br><b>R. Salgado, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14721","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/a9a5e3dc-2317-419b-9c0f-4c12814827f0\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"9","PosterboardNumber":"11","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"460","PresenterBiography":null,"PresenterDisplayName":"Katherine Elfer, MPH;PhD","PresenterKey":"99d6d58f-d092-43bb-b0c2-bc1c0414be16","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"460. Tools for collecting pathologist annotations and understanding interobserver variability","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Tools for collecting pathologist annotations and understanding interobserver variability","Topics":null,"cSlideId":""},{"Abstract":"With the growing standardization of Whole Slide Images (WSIs), deep learning algorithms have shown promising results for the automated classification and localization of tumors. Yet, it is often difficult to train such algorithms, as they usually require careful detailed annotations from expert pathologists, which are tedious to produce. This is why in general only slide-level labels are accessible while annotations of small regions (or tiles) are limited. With only slide-level information, it is difficult to obtain accurate predictions of the localization of pathological tissues inside a slide, despite reaching good slide-level classification. Besides, existing algorithms show limited consistency between slide- and tile-level predictions, leading to difficult interpretation in case of healthy tissue. Using the attention-based multiple instance learning framework, we propose to combine slide-level labels on all slides with tile-level labels on a small fraction (e.g. 20%) of slides within a histology dataset to improve both classification and localization performances. With this mixed supervision of slides, we aim to enforce a better consistency between slide- and tile-level labels. To this end, we introduce an attention-based loss function to further guide the model&#8217;s attention on discriminative regions inside tumorous slides, and display an equal attention among all tiles of normal slides. On the Camelyon16 dataset, we reached precision and recall scores as high as 0.99 and 0.85 respectively with an AUC of 0.93 on the competition test set, using only 50% of the slides with tile-level annotations in the training set. Experiments using various proportions of fully annotated slides in the training set show promising results for an improved localization of tumors and classification of slides. In this work, we showed that using a limited amount of fully annotated slides we can improve both the classification and localization performances of an attention-based deep learning model. This increased consistency and performances should help pathologists to better interpret the algorithm output and to focus on suspicious regions in probable tumorous slides.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/530f2fa2-b4c1-4615-bb16-cb5b5dd25c16\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Machine learning,,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14723"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Paul Tourniaire<\/i><\/presenter>, <presenter><i>Marius Ilie<\/i><\/presenter>, <presenter><u><i>Paul Hofman<\/i><\/u><\/presenter>, <presenter><i>Nicholas Ayache<\/i><\/presenter>, <presenter><i>Hervé Delingette<\/i><\/presenter>. Inria, Epione Team, Sophia Antipolis, Université Côte d’Azur, Nice, France, Laboratory of Clinical and Experimental Pathology, Hospital-Related Biobank (BB-0033-00025), Centre Hospitalier Universitaire de Nice, FHU OncoAge, Université Côte d’Azur, Nice, France","CSlideId":"","ControlKey":"f8e5497e-e6f7-4e97-b1d4-a1cf3655ceac","ControlNumber":"1938","DisclosureBlock":"&nbsp;<b>P. Tourniaire, <\/b> None..<br><b>M. Ilie, <\/b> None..<br><b>P. Hofman, <\/b> None..<br><b>N. Ayache, <\/b> None..<br><b>H. Delingette, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14723","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/530f2fa2-b4c1-4615-bb16-cb5b5dd25c16\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"10","PosterboardNumber":"12","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"461","PresenterBiography":null,"PresenterDisplayName":"Paul Hofman","PresenterKey":"17b3bb05-fe95-49f0-851c-971944390cde","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"461. Mixed supervision to improve the classification and localization: Coherence of tumors in histological slides","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Mixed supervision to improve the classification and localization: Coherence of tumors in histological slides","Topics":null,"cSlideId":""},{"Abstract":"Prostate cancer (PCa) is associated with several genetic alterations which play an important role in the disease heterogeneity and clinical outcome. These alterations involve gene fusion between TMPRSS2 and members of the ETS family of transcription factors like ERG, ETV1, and ETV4 together with mutations or deletions in tumor suppressors like TP53 and PTEN. The expanding wealth of digital whole slide images (WSIs) and the increasing adoption of deep learning approaches offer a unique opportunity for pathologists to streamline the detection of these alterations. Here, we used 736 haematoxylin and eosin-stained WSIs from 494 primary PCa patients to identify several key genetic alterations including ERG, ETV1, and ETV4 fusion, PTEN loss, and TP53 and SPOP mutations. Using a custom segmentation pipeline, we identified tissue regions and tiled them into high-resolution (10X magnification) patches (256X256 pixels) which were passed to our deep multiple instance learning framework. Using a pre-trained ResNet50 model, we extracted informative features which were subsequently used for training to predict slide-level labels and to detect slide regions with high diagnostic relevance. Using a 10-folds cross validation approach, we divided the data into training (80%), validation (10%) and testing (10%) sets. The training and validation data were used for training the model and hyperparameters tuning, respectively while the testing data was used to provide an unbiased evaluation of the models&#8217; performance using the mean Area Under the Receiver Operating Characteristic (AUROC) across the ten testing folds as evaluation metric. We managed to accurately detect key molecular alterations including ERG fusion, ETV1 fusion, ETV4 fusion, and PTEN loss. Additionally, we were able to detect mutations in TP53 and SPOP together with the presence of androgen-receptor splice variant 7 (ARv7). In addition to slide-level classification, we also identified subregions with high attention score which can help pathologists identify the distinct morphological features associated with each genetic alteration. Finally, in order to examine the cellular structure associated with each genetic alteration, we used Hover-Net model to segment and classify the nuclei in the high-attention tiles. Our work highlights the utility of using WSIs to accurately identify key molecular alteration in cancer and their associated morphological and cellular features on the slide which would streamline the diagnostic process. To the best of our knowledge, this is the first study that uses routine WSIs to predict and characterize key genetic alterations in PCa.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/94507efa-52d7-477c-8ad8-d59ec9c72cf9\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Deep learning,Imaging,Gene fusion,Mutation detection,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14724"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Mohamed Omar<\/i><\/u><\/presenter>, <presenter><i>Zhuoran Xu<\/i><\/presenter>, <presenter><i>Ryan Carelli<\/i><\/presenter>, <presenter><i>Jacob Rosenthal<\/i><\/presenter>, <presenter><i>David Brundage<\/i><\/presenter>, <presenter><i>Daniela C. Salles<\/i><\/presenter>, <presenter><i>Eddie L. Imada<\/i><\/presenter>, <presenter><i>Renato Umeton<\/i><\/presenter>, <presenter><i>Edward M. Schaeffer<\/i><\/presenter>, <presenter><i>Brian D. Robinson<\/i><\/presenter>, <presenter><i>Tamara L. Lotan<\/i><\/presenter>, <presenter><i>Massimo Loda<\/i><\/presenter>, <presenter><i>Luigi Marchionni<\/i><\/presenter>. Weill Cornell Medicine, New York, NY, Dana-Farber Cancer Institute, Boston, MA, Johns Hopkins University, Baltimore, MD, Feinberg School of Medicine, Northwestern University, Chicago, IL","CSlideId":"","ControlKey":"ec47d367-dc29-4fae-bdcb-abfbad020001","ControlNumber":"3115","DisclosureBlock":"&nbsp;<b>M. Omar, <\/b> None..<br><b>Z. Xu, <\/b> None..<br><b>R. Carelli, <\/b> None..<br><b>J. Rosenthal, <\/b> None..<br><b>D. Brundage, <\/b> None..<br><b>D. C. Salles, <\/b> None..<br><b>E. L. Imada, <\/b> None..<br><b>R. Umeton, <\/b> None..<br><b>E. M. Schaeffer, <\/b> None..<br><b>B. D. Robinson, <\/b> None..<br><b>T. L. Lotan, <\/b> None..<br><b>M. Loda, <\/b> None..<br><b>L. Marchionni, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14724","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/94507efa-52d7-477c-8ad8-d59ec9c72cf9\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"11","PosterboardNumber":"13","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"462","PresenterBiography":null,"PresenterDisplayName":"Mohamed Omar, MBBCh","PresenterKey":"a5a2aa79-5b2f-4949-8ce0-ce8d3b9f9511","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"462. Using attention-based deep multiple instance learning to identify key genetic alterations in prostate cancer from whole slide images","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Using attention-based deep multiple instance learning to identify key genetic alterations in prostate cancer from whole slide images","Topics":null,"cSlideId":""},{"Abstract":"Pathological complete response (no residual viable tumor, RVT) and\/or major pathologic response (&#8804;10% RVT) are now primary or secondary endpoints for a large proportion of clinical trials studying neoadjuvant immunotherapeutic regimens. We previously developed a scoring system for assessing pathologic respon&#173;&#173;se after immunotherapy, termed irPRC (Cottrell et al. Ann Oncol 2018). By these criteria, %RVT is assessed by dividing RVT by the sum of the surface area on the slide composed of RVT + necrosis + regression bed-- the latter feature is where the tumor used to be and is characterized by fibroinflammatory stroma that is distinct from tumoral stroma. We have previously reported high inter-observer reproducibility for pathologic response assessment following immunotherapy. However, these assessments involve performing evaluations that are currently outside the scope of routine surgical pathology training and may be time-consuming. To date, these assessments have primarily been performed by academic pathologists who have seen the largest number of these cases as a part of clinical trials. A machine learning (ML)-powered assessment of irPRC would allow for faster, standardized evaluation and expanded access to patients treated outside of large academic centers. We trained a supervised convolutional neural network to assess pathologic response using irPRC on n=92 H&#38;E-stained slides from patients with advanced, resectable NSCLC treated with neoadjuvant anti-PD-1 +\/- anti-CTLA-4 at a single institution. The ML algorithm was trained based on ground-truth manual annotations by pathologists on whole slide digital scans and tested using leave-one-out cross validation. Each of ~830,000 image tiles was classified into one of four classes: tumor, necrosis, immune-mediated regression, or background lung tissue. Receiver operating curves showed that the algorithm exhibited high accuracy for predicting the various tissue classes with an area under the curve of 0.95, 0.96, 0.90, and 0.90 for the four classes, respectively. %RVT was calculated by dividing the surface area of RVT by total tumor bed surface area (RVT + necrosis + regression). There was a strong positive correlation between the machine assessed RVT and the human assessed RVT at both the slide level and case level (aggregate %RVT based on surface area from all slides for a given patient), Pearson&#8217;s r=0.95 and r=0.99, respectively. Here, we demonstrate that a ML algorithm performs as well as an experienced pathologist assessment in scoring pathologic response. These findings will need to be validated in larger studies. Additionally, the association of pathologic response with longer term patient outcomes will be evaluated as survival data matures to determine whether pathologic response is a robust surrogate of survival.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/7761b476-af10-4e4b-b0db-64bdfd2043f3\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Machine learning,PD-1,pathologic response,irPRC,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14725"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Julie E. Stein<\/i><\/u><\/presenter>, <presenter><i>Vinay Pulim<\/i><\/presenter>, <presenter><i>Tricia R. Cottrell<\/i><\/presenter>, <presenter><i>Patrick M. Forde<\/i><\/presenter>, <presenter><i>Janis M. Taube<\/i><\/presenter>. Johns Hopkins University School of Medicine, Baltimore, MD, Independent Contributor, Brooklyn, NY, Queen's University School of Medicine, Kingston, ON, Canada","CSlideId":"","ControlKey":"841ce692-00be-413c-8512-b5da4bafab72","ControlNumber":"2646","DisclosureBlock":"&nbsp;<b>J. E. Stein, <\/b> None..<br><b>V. Pulim, <\/b> None..<br><b>T. R. Cottrell, <\/b> None.&nbsp;<br><b>P. M. Forde, <\/b> <br><b>AstraZeneca<\/b> Grant\/Contract, Other, Advisor\/consultant, Yes. <br><b>Bristol Myers Squibb<\/b> Grant\/Contract, Other, Advisor\/consultant, Yes. <br><b>Novartis<\/b> Grant\/Contract, Other, Advisor\/consultant, Yes. <br><b>Amgen<\/b> Other, Advisor\/consultant, Yes. <br><b>Genentech<\/b> Other, Advisor\/consultant, Yes. <br><b>Iteos<\/b> Other, Advisor\/consultant. <br><b>F-Star<\/b> Other, Advisor\/consultant. <br><b>G1 Therapeutics<\/b> Other, Advisor\/consultant. <br><b>Surface Oncology<\/b> Other, Advisor\/consultant. <br><b>Janssen<\/b> Other, Advisor\/consultant. <br><b>Merck<\/b> Other, Advisor\/consultant. <br><b>Sanofi<\/b> Other, Advisor\/consultant. <br><b>Kyowa<\/b> Grant\/Contract. <br><b>Flame<\/b> Other, DSMB. <br><b>Polaris<\/b> Other, DSMB. <br><b>J. M. Taube, <\/b> <br><b>Bristol Myers Squib<\/b> Grant\/Contract, Other, Advisor\/consultant. <br><b>Akoya Biosciences<\/b> Stock Option, Grant\/Contract, Other, Advisor\/consultant, equipment\/reagents, No. <br><b>AstraZeneca<\/b> Other, Advisor\/consultant. <br><b>Merck<\/b> Other, Advisor\/consultant. <br><b>Compugen<\/b> Other, Advisor\/consultant.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14725","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/7761b476-af10-4e4b-b0db-64bdfd2043f3\/@u03B8ZAA\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"12","PosterboardNumber":"14","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"463","PresenterBiography":null,"PresenterDisplayName":"Julie Stein, MD","PresenterKey":"edb5b95f-b2eb-4100-b538-d0507b8bb1f9","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"463. Highly accurate machine learning assessment of immune-related pathologic response criteria (irPRC) scoring in patients with non-small cell lung carcinoma (NSCLC) treated with neoadjuvant anti-PD-1-based therapies","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Highly accurate machine learning assessment of immune-related pathologic response criteria (irPRC) scoring in patients with non-small cell lung carcinoma (NSCLC) treated with neoadjuvant anti-PD-1-based therapies","Topics":null,"cSlideId":""},{"Abstract":"Morphological features of cancer cell nuclei are linked to gene expression signatures and genomic alterations. In addition, pathologists have leveraged nuclear morphology as diagnostic and prognostic markers. To enable the use of nuclear morphology in digital pathology, we developed a pan-tissue, deep-learning-based digital pathology pipeline for exhaustive nucleus detection, instance segmentation, and classification. We collected &#62; 29,000 manual nucleus annotations from hematoxylin and eosin (H&#38;E)-stained pathology images from 21 tumor types at 40x and 20x magnification from The Cancer Genome Atlas (TCGA) project, as well as a proprietary set of H&#38;E-stained tissue biopsies of skin, liver non-alcoholic steatohepatitis (NASH), colon inflammatory bowel disease (IBD), and kidney lupus. Annotations were used to train an object detection and segmentation model for identifying nuclei. Application of the model to held-out test data, including held-out tissue types, demonstrated performance comparable to state-of-the-art models described in the literature (mean Dice score = 0.80, aggregated Jaccard index = 0.60). We deployed our model to segment nuclei in H&#38;E slides from the breast cancer (BRCA, N = 941) and prostate adenocarcinoma (PRAD, N = 457) TCGA cohorts. We extracted interpretable features describing the shape (circularity, eccentricity), size, staining intensity (mean and standard deviation), and texture of each nucleus. Nuclei were assigned as cancer or other cell types using separately trained convolutional neural networks for BRCA and PRAD. We used the mean and standard deviation of each feature sampled from a random subset of cancer nuclei to summarize the nuclear morphology on each slide (mean (range) = 10,068 (5,981-10,452) cancer cells from each BRCA slide; mean (range) = 10,053 (5,029-10,495) cancer cells from each PRAD slide). We used nuclear features to construct random forest classification models for predicting markers of genomic instability and prognosis: whole-genome doubling (WGD) and homologous recombination deficiency (HRD) status separately in BRCA and PRAD, HER2 subtype in BRCA, and Gleason grade in PRAD. Nuclear features were predictive of WGD (area under the receiver operating characteristic curve (AUROC) = 0.78 BRCA, = 0.69 PRAD) and binarized HRD status (AUROC = 0.65 BRCA, = 0.68 PRAD) on held-out test sets. Nuclear features were predictive of HER2-enriched breast cancer vs. other molecular subtypes (AUROC = 0.72), and distinguished between low risk (6) and moderate\/high risk (7-10) Gleason grade in PRAD (AUROC = 0.72). In summary, we present a powerful pan-tissue approach for nucleus segmentation and featurization, which enables the construction of predictive models and the identification of features linking nuclear morphology with clinically-relevant prognostic biomarkers across multiple cancer types.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/7683c9a0-0d0d-4a77-ab1e-1b7128ece294\/@v03B8ZAB\/vod?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Predictive biomarkers,Prostate cancer,Breast cancer,HER2,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14726"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>John Abel<\/i><\/u><\/presenter>, <presenter><i>Suyog Jain<\/i><\/presenter>, <presenter><i>Deepta Rajan<\/i><\/presenter>, <presenter><i>Ken Leidal<\/i><\/presenter>, <presenter><i>Harshith Padigela<\/i><\/presenter>, <presenter><i>Aaditya Prakash<\/i><\/presenter>, <presenter><i>Jake Conway<\/i><\/presenter>, <presenter><i>Michael Nercessian<\/i><\/presenter>, <presenter><i>Christian Kirkup<\/i><\/presenter>, <presenter><i>Robert Egger<\/i><\/presenter>, <presenter><i>Ben Trotter<\/i><\/presenter>, <presenter><i>Andrew Beck<\/i><\/presenter>, <presenter><i>Ilan Wapinski<\/i><\/presenter>, <presenter><i>Michael G. Drage<\/i><\/presenter>, <presenter><i>Limin Yu<\/i><\/presenter>, <presenter><i>Amaro Taylor-Weiner<\/i><\/presenter>. PathAI, Boston, MA","CSlideId":"","ControlKey":"a456bde3-94ff-48a6-bf55-cd60bd325720","ControlNumber":"1432","DisclosureBlock":"<b>&nbsp;J. Abel, <\/b> <br><b>PathAI, Inc.<\/b> Employment, Stock Option, Yes. <br><b>S. Jain, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>D. Rajan, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>K. Leidal, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>H. Padigela, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>A. Prakash, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>J. Conway, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock, Stock Option, Yes. <br><b>M. Nercessian, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>C. Kirkup, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>R. Egger, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>B. Trotter, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>A. Beck, <\/b> <br><b>PathAI, Inc<\/b> Employment, Fiduciary Officer, Stock, Stock Option, Patent, Copyright, Yes. <br><b>I. Wapinski, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock, Stock Option, Patent, Yes. <br><b>M. G. Drage, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>L. Yu, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes. <br><b>A. Taylor-Weiner, <\/b> <br><b>PathAI, Inc<\/b> Employment, Stock Option, Yes.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14726","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/7683c9a0-0d0d-4a77-ab1e-1b7128ece294\/@v03B8ZAB\/vod?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"13","PosterboardNumber":"15","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"464","PresenterBiography":null,"PresenterDisplayName":"John Abel, PhD","PresenterKey":"1595128d-2ca8-4edb-872f-c8c74794ddf8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"464. AI-powered segmentation and analysis of nuclei morphology predicts genomic and clinical markers in multiple cancer types","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AI-powered segmentation and analysis of nuclei morphology predicts genomic and clinical markers in multiple cancer types","Topics":null,"cSlideId":""},{"Abstract":"<b>Background: <\/b>Rhabdomyosarcoma (RMS) is an aggressive soft tissue tumor in children and young adults, accounting for 350-400 new cases annually in the US. Diagnosis of RMS is defined by the expression of genes related to skeletal muscle differentiation and can be further subclassified based on histological patterns (embryonal, ERMS; alveolar, ARMS; spindle\/sclerosing, SSRMS). Genetic studies have found that the presence of a PAX fusion gene (FP-RMS), which is present in many ARMS tumors, correlates with poor outcome. Subsequent studies have identified additional genetic alterations (ex. <i>TP53<\/i> or <i>MYOD1<\/i> mutations) which also display distinct histological features and are associated with poor outcome. As a result, there is a growing need to identify these mutations to improve risk stratification. The goal of this study is to develop and test deep learning algorithms from diagnostic H&#38;E images of RMS tumors which can aid in the diagnosis, mutation prediction and risk stratification for RMS patients.<br \/><b>Methods: <\/b>De-identified RMS patient samples were collected from tissue banking studies from Children&#8217;s Oncology Group (n=275), University Hospital Zurich (n=250) and Memorial Sloan Kettering (n=10). H&#38;E stains on whole slides or TMAs were digitally scanned and used for analysis. Clinical information including clinical risk group, event-free survival, and genomic findings were used as available for training and testing. Convolutional neural networks (CNN) using EfficientNet were trained using K-fold cross validation to classify tumor histology, mutation probability, and risk stratification and tested against randomly selected samples or independent datasets when available.<br \/><b>Results: <\/b>The developed AI algorithm was able to classify tissue as ARMS (FP-RMS), ERMS (FN-RMS), stroma and necrosis with an average weighted intersect-over-union of 0.74 when compared to an expert pathologist annotation. A second deep learning algorithm developed specifically for distinguishing FP-RMS from FN-RMS displayed excellent sensitivity (FP-RMS=0.88) and specificity (FP-RMS=0.86) when tested against an independent RMS TMA dataset. Algorithms were also trained to predict mutations in <i>MYOD1<\/i>, <i>RAS<\/i> pathway genes, and <i>TP53<\/i> and displayed good performance with ROC values of 0.96, 0.68, and 0.64, respectively. Lastly, we developed an algorithm to provide a Cox proportional hazard prediction based on H&#38;E images. The resulting algorithm was capable of predicting EFS with similar accuracy as current clinical risk group assessment with improved ability to distinguish intermediate and high risk patients.<br \/><b>Conclusions:<\/b> Deep learning with convolutional neural networks provides pathologist-independent classification of RMS patients from simple H&#38;E images. These AI algorithms can provide probabilities of prognostically relevant genetic alterations and survival which will ultimately contribute to better risk stratification of RMS patients.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f1a7b896-ce1c-49a7-a408-dbcf57614043\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Rhabdomyosarcoma,Deep learning,Mutation detection,Survival,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14728"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>David Milewski<\/i><\/u><\/presenter>, <presenter><i>Hyun Jung<\/i><\/presenter>, <presenter><i>G. Thomas Brown<\/i><\/presenter>, <presenter><i>Yanling Liu<\/i><\/presenter>, <presenter><i>Jack Collins<\/i><\/presenter>, <presenter><i>Marc Ladanyi<\/i><\/presenter>, <presenter><i>Erin Rudzinski<\/i><\/presenter>, <presenter><i>Javed Khan<\/i><\/presenter>. National Cancer Institute, Bethesda, MD, Leidos Biomedical, Frederick, MD, National Cancer Institute, Frederick, MD, Memorial Sloan-Kettering Cancer Center, New York, NY, Seattle Children's Hospital, Seattle, WA","CSlideId":"","ControlKey":"dd8f403b-6a2d-4b8f-a6bf-e02735bccf6f","ControlNumber":"2623","DisclosureBlock":"&nbsp;<b>D. Milewski, <\/b> None..<br><b>H. Jung, <\/b> None..<br><b>G. Brown, <\/b> None..<br><b>Y. Liu, <\/b> None..<br><b>J. Collins, <\/b> None..<br><b>M. Ladanyi, <\/b> None..<br><b>E. Rudzinski, <\/b> None..<br><b>J. Khan, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14728","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/f1a7b896-ce1c-49a7-a408-dbcf57614043\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"14","PosterboardNumber":"17","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"466","PresenterBiography":null,"PresenterDisplayName":"David Milewski, BA;PhD","PresenterKey":"e651817c-46e0-489b-b0d2-37bd80628a2a","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"466. Predicting survival of rhabdomyosarcoma patients based on deep learning of H&#38;E images","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Predicting survival of rhabdomyosarcoma patients based on deep learning of H&#38;E images","Topics":null,"cSlideId":""},{"Abstract":"Colorectal cancer is one of the most common cancers in both men and women. Patient stratification in colorectal cancers is challenging and affects therapy decisions and patient care. In this study, we develop an integrative Inception V3-based deep learning approach to stratify TCGA-COAD patients from H&#38;E images, showing that combining deep learning extracted morphological features with clinical and mutational status improves patient stratification. Morphological features within tumor regions can distinguish patients by short or long overall survival (OS) (OS&#60;3 years v.s. OS&#62;5 years, AUC 0.81&#177;0.12), while they are less informative for intermediate OS (3&#60;OS&#60;5 years). Models that integrate morphological features with additional data modalities yield superior stratification to those that use only a single datatype or that use only clinical information and genomic markers. Remarkably, combining deep learning morphological features with clinical information and genomic markers also boosts stratification of patients with 3&#60;OS&#60;5 years, both at the 3-year time point (p &#60;0.001) and 5-year time point (p &#60;0.001). We validated our model on an external dataset (OS&#60;3 years v.s. OS&#62;5 years, AUC 0.78&#177;0.20), and again found that combining morphological features and clinical data is superior to only using a single datatype. Our deep learning models were also able to perform reliable tumor segmentation (AUC&#62;0.92). However, survival predictions based on deep learning tumor segmentation were inferior to those based on pathologist tumor annotations (OS&#60;3 years v.s. OS&#62;5 years, AUC 0.79&#177;0.14). Furthermore, we show that the cross-talk between different data modalities is informative of patient risk. More precisely, models that directly combine image and clinical features performed superior to a na&#239;ve Bayes classifier combining predictions of models trained on each data type (integrative model AUC=0.81&#177;0.06 and na&#239;ve Bayes AUC=0.76&#177;0.11, p&#60;0.01). Our results show integrative analysis utilizes the cross-talk between data modalities to boost patient risk stratification, and that deep learning is an efficient methodology for taking advantage of cross-talk between various data modalities.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/af191cd9-a228-4070-ad27-a3672de184aa\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Survival,Deep learning,Cancer diagnostics,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14729"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Jie Zhou<\/i><\/u><\/presenter>, <presenter><i>Ali Foroughi pour<\/i><\/presenter>, <presenter><i>Rafic Beydoun<\/i><\/presenter>, <presenter><i>Hany Deirawan<\/i><\/presenter>, <presenter><i>Fayez Daaboul<\/i><\/presenter>, <presenter><i>Fahad Shabbir Ahmed<\/i><\/presenter>, <presenter><i>Jeffrey H. Chuang<\/i><\/presenter>. The Jackson Laboratory for Genomic Medicine, Farmington, CT, Wayne State University, Detroit, MI","CSlideId":"","ControlKey":"904acad9-50eb-4e12-8e83-e24df79852e7","ControlNumber":"3711","DisclosureBlock":"&nbsp;<b>J. Zhou, <\/b> None..<br><b>A. Foroughi pour, <\/b> None..<br><b>R. Beydoun, <\/b> None..<br><b>H. Deirawan, <\/b> None..<br><b>F. Daaboul, <\/b> None..<br><b>F. S. Ahmed, <\/b> None..<br><b>J. H. Chuang, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14729","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/af191cd9-a228-4070-ad27-a3672de184aa\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"15","PosterboardNumber":"18","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"467","PresenterBiography":null,"PresenterDisplayName":"Jie Zhou, MS","PresenterKey":"0b348fdf-b669-44ff-aec8-bddd94cfbf5e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"467. Integrative deep learning analysis identifies cross-talk between morphology, mutation, and clinical variables for colon adenocarcinoma patient outcomes","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Integrative deep learning analysis identifies cross-talk between morphology, mutation, and clinical variables for colon adenocarcinoma patient outcomes","Topics":null,"cSlideId":""},{"Abstract":"Many targeted cancer therapies rely on biomarkers, which are assessed by standard pathologist scoring of immunohistochemically stained tissue. However, this process is subjective, semi-quantitative and does not assess expression heterogeneity. A quantitative method to measure IHC markers might therefore significantly improve patient selection particularly of proteins expressed at low levels. To address these challenges, we have developed the Quantitative Continuous Scoring (QCS) that deploys the power of fully supervised Deep Learning (DL) algorithms to provide objective and continuous data of biomarkers in digitized IHC whole slide images (WSI). The two DL-based algorithms, developed using pathologist input as the ground truth, identify areas of invasive tumor and segment each individual tumor cell across the WSI into pixels that represent cell nuclei, cytoplasm and\/or membrane. This allows to compute biomarker expression as mean Optical Density (OD) in each of these subcellular compartments based on the Hue-Saturation-Density (HSD) model. Of note, this also allows computation of the spatial distribution of tumor cells across the WSI. The measured OD for each cell is aggregated as a histogram to quantitative continuous readouts for each patient sample. The method&#8217;s ability to accurately detect low expression range facilitates selection of antibody clones for IHC assays, has been successfully used to delineate mode of action and PK\/PD mechanisms, has provided surrogate markers of spatial expression heterogeneity to predict potential bystander activity and has facilitated marker co-expression analysis to inform rational combination therapies. In retrospective clinical trials analysis, QCS showed superior performance in identifying a patient population gaining maximum treatment benefit. QCS-based quantification of PD-L1 membrane expression was able to stratify anti-PD-L1 treated late-stage non-small cell lung cancer (NSCLC) patients [NCT01693562] with a higher prevalence and more significant log rank p-value (64%, p=0.0001) for OS compared to pathologist TPS (59%, p=0.01). In summary, we describe a computational pathology-based approach for precise biomarker quantification and superior patient selection with broad applicability and the potential to transform pathology, thus addressing one of the key challenges of precision oncology.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/b1a7a8ca-8e28-45e0-99ca-10a0dc78e258\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Deep learning,PD-L1,Antibody-drug conjugate (ADC),Heterogeneity,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14730"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Hadassah Sade<\/i><\/u><\/presenter>, <presenter><i>Ansh Kapil<\/i><\/presenter>, <presenter><i>Philipp Wortmann<\/i><\/presenter>, <presenter><i>Andreas Spitzmueller<\/i><\/presenter>, <presenter><i>Nicolas Triltsch<\/i><\/presenter>, <presenter><i>Lina Meinecke<\/i><\/presenter>, <presenter><i>Susanne Haneder<\/i><\/presenter>, <presenter><i>Anatoliy Shumilov<\/i><\/presenter>, <presenter><i>Jan Lesniak<\/i><\/presenter>, <presenter><i>Valeria Bertani<\/i><\/presenter>, <presenter><i>Tze-Heng Tan<\/i><\/presenter>, <presenter><i>Ana Hidalgo-Sastre<\/i><\/presenter>, <presenter><i>Simon Christ<\/i><\/presenter>, <presenter><i>Andrea Storti<\/i><\/presenter>, <presenter><i>Regina Alleze<\/i><\/presenter>, <presenter><i>Dasa Medrikova<\/i><\/presenter>, <presenter><i>Jessica Chan<\/i><\/presenter>, <presenter><i>Simon Lanzmich<\/i><\/presenter>, <presenter><i>Markus Schick<\/i><\/presenter>, <presenter><i>Guenter Schmidt<\/i><\/presenter>, <presenter><i>J. Carl Barrett<\/i><\/presenter>. AstraZeneca Computational Pathology GmbH, Munich, Germany, AstraZeneca, Gaithersburg, MD","CSlideId":"","ControlKey":"9c7606fc-e81a-4ec5-adfd-f57c08c9801a","ControlNumber":"5024","DisclosureBlock":"<b>&nbsp;H. Sade, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Yes. <br><b>A. Kapil, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>P. Wortmann, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>A. Spitzmueller, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>N. Triltsch, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>L. Meinecke, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>S. Haneder, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>A. Shumilov, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>J. Lesniak, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>V. Bertani, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>T. Tan, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>A. Hidalgo-Sastre, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>S. Christ, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>A. Storti, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>R. Alleze, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>D. Medrikova, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>J. Chan, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>S. Lanzmich, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>M. Schick, <\/b> <br><b>AstraZeneca<\/b> Employment, Yes. <br><b>G. Schmidt, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Yes. <br><b>J. Barrett, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Yes.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14730","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/b1a7a8ca-8e28-45e0-99ca-10a0dc78e258\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"16","PosterboardNumber":"19","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"468","PresenterBiography":null,"PresenterDisplayName":"Hadassah Sade, PhD","PresenterKey":"bbfe2015-080c-43f1-9283-654bb339ebb0","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"468. Quantitative assessment of IHC using computational pathology allows superior patient selection for biomarker-informed patients","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Quantitative assessment of IHC using computational pathology allows superior patient selection for biomarker-informed patients","Topics":null,"cSlideId":""},{"Abstract":"Heterogeneity is a hallmark of cancer and perhaps one of the most important features associated with resistance to therapies and likelihood of recurrence and\/or metastasis. Genomic instability contributes to genetic diversity, which leads to high levels of intratumoural heterogeneity. While genetic diversity is one contributor to phenotypic heterogeneity in tumors, the spatial variation in the tumor microenvironment (TME) also drives emergent phenotypic heterogeneity and intrinsic variation in resistance to drugs and the immune system. Ultimately, heterogeneity leads to higher likelihood of metastasis. Traditionally, pathology allowed for the assessment of heterogeneity.<br \/>However, this was limited to gross assessment of the TME, through measurement of mitotic levels and severity of cancer invasion. We present SimBioSys PhenoScope, a multi-scale analysis and visualization platform that integrates cancer data across scales to extract cross modality trends that drive cancer invasion. As a demonstrated use case for the platform, we present a vignette of using the platform to analyze pathology slides at three scales. Three convolutional neural networks (CNN) are developed and validated. The outputs of these networks were combined with 2D simulations of the metabolic behavior and growth of cells within the TME. Two CNNs were developed and one implemented: one that identifies cells undergoing mitosis, one that segments individual cells and classifies their type, and one that segments five tissues from pathology slides. Additionally, transcriptional data was used to generate patient specific metabolic models. Each CNN was developed using training images and validated on the test images. The mitosis detection CNN was found to have an accuracy of 76.2% (precision=83%, recall=76%) in the test set. The classification CNN was found to have a Dice Similarity Coefficient (DSC) of 0.821 for segmenting cells and an F1 score for classifying cells ranging from 0.559 (F1i) to 0.756 (F1d). The segmentation CNN was found to have an accuracy of 78.1% with DSC ranging from 0.66 and 0.86 depending on tissue. The segmentations were input into a proprietary simulation framework along with patient-specific metabolic models to predict the spatial gradients of nutrients, and spatial organization of growth and metabolism. Simulations show multiple behaviors such as regions of high lactate production or consumption by cancer, and regions that differ by lactate production and alanine uptake in cancers. These behaviors were correlated with local cell mitoses and invasion of Tumor Infiltrating Lymphocytes.<br \/>Tools to examine cancers across scales and within the TME are currently lacking. We demonstrate a proof-of-principle approach of combining data across scales in a fashion that allows for novel predictions of TME behavior.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/119e2d90-efb5-446c-80a3-14a621a262dd\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Machine learning,Tumor heterogeneity,Modeling,Metabolism,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14841"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Joseph R. Peterson<\/i><\/u><\/presenter>, <presenter><i>Matthew Shin<\/i><\/presenter>, <presenter><i>Patricia Carrigan<\/i><\/presenter>, <presenter><i>Michael J. Hallock<\/i><\/presenter>, <presenter><i>Snehal Patel<\/i><\/presenter>, <presenter><i>The SimBioSys Team<\/i><\/presenter>. SimBioSys, Inc, Chicago, IL","CSlideId":"","ControlKey":"001aa724-c98b-476d-a517-37fe2453471e","ControlNumber":"6147","DisclosureBlock":"&nbsp;<b>J. R. Peterson, <\/b> None..<br><b>M. Shin, <\/b> None..<br><b>P. Carrigan, <\/b> None..<br><b>M. J. Hallock, <\/b> None..<br><b>S. Patel, <\/b> None..<br><b>T. SimBioSys Team, <\/b> None.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14841","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/119e2d90-efb5-446c-80a3-14a621a262dd\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"17","PosterboardNumber":"20","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"469","PresenterBiography":null,"PresenterDisplayName":"Joseph Peterson, PhD","PresenterKey":"a80e03de-a58f-46dd-a3ef-03c2feba7b19","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"469. A multi-scale analysis and visualization platform for cancer data - deriving tumor microenvironment behavior from pathology and transcriptomics","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A multi-scale analysis and visualization platform for cancer data - deriving tumor microenvironment behavior from pathology and transcriptomics","Topics":null,"cSlideId":""},{"Abstract":"Introduction: Important immunotherapy drugs targeting PD-L1 are approved for first and second line treatment for various stages of NSCLC. Reproducible and precise evaluation of PD-L1 expression is essential to accurately evaluate patients&#8217; eligibility for treatment and for enrollment in clinical trials. Current guidelines rely on pathologists to interpret tumor samples, which is challenging in part because different PD-L1 assays have distinct scoring criteria. As a result, determining eligibility by manual assessment can be inconsistent and inaccurate, leading to untreated patients. To support pathologist quantification of PD-L1 in clinical trials, PathAI has developed scanner-and antibody-agnostic machine learning (ML) models, AI-based histologist measurement of PD-L1 in NSCLC (AIM-PD-L1-NSCLC), for the quantification of PD-L1 expression in NSCLC using four PD-L1 immunohistochemistry (IHC) clones.<br \/>Methods: AIM-PD-L1-NSCLC was trained using convolutional neural networks to identify and quantify PD-L1-positive cells in digitized whole slide images (WSI) of tissue samples. Models were developed using over 5,000 diverse clinical biopsies and resections, including primary and metastatic adenocarcinoma and squamous cell carcinoma samples collected from 10 clinical trials and from two clinical laboratories, each stained for PD-L1 with one of four IHC clones: SP263 (N=1,320), SP142 (N=1,829) (both Ventana Medical Systems Inc., Tucson, AZ), 28-8 (N=1,331), or 22C3 (N=843) (both Agilent Technologies, Santa Clara, USA). Slides were digitized using Aperio, Philips, and Ventana scanners, and WSI were split into training (N=3,818) and test (N=1,505) datasets. The training dataset was annotated by board certified pathologists (313,770 annotations) to label tissue regions and cells. Human Interpretable features representing the number of tumor cells were automatically extracted from the model and a slide level Tumor Proportion Score (TPS) calculated as the proportion of PD-L1+ cancer cells divided by total cancer cells in tumor regions. Model predicted slide level TPS were compared with the median TPS of five pathologists&#8217; scores using intraclass correlation coefficient (ICC) statistics.<br \/>Results: There was high concordance between ML model-predicted and median pathologists&#8217; slide level TPS for all PD-L1 clones (ICC 0.93 (95% CI 0.90-0.94), and for each individual clone: 22C3 ICC 0.93 (95% CI 0.89-0.96); SP142 ICC 0.88 (95% CI 0.79-0.93); SP263 ICC 0.96 (95% CI 0.93-0.97; 28-8 ICC 0.90 (95% CI 0.85-0.93).<br \/>Conclusions: AIM PD-L1 NSCLC is highly concordant with the gold standard pathologist consensus score across four PD-L1 clones in a large diverse dataset. This model could support patient enrollment and stratification in prospective clinical trials, as well as quality control of staining and pathology drift.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/34691c26-18aa-422a-b78f-f943ac5971a3\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"PD-L1,Machine learning,Clinical dataset,Multi-IHC clone,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/14846"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><i>Michael Griffin<\/i><\/presenter>, <presenter><i>Mevlana Gemici<\/i><\/presenter>, <presenter><i>Ashar Javed<\/i><\/presenter>, <presenter><i>Nishant Agrawal<\/i><\/presenter>, <presenter><i>Murray Resnick<\/i><\/presenter>, <presenter><i>Limin Yu<\/i><\/presenter>, <presenter><i>Sara Hoffman<\/i><\/presenter>, <presenter><i>Victoria Mountain<\/i><\/presenter>, <presenter><i>Jamie Harisiades<\/i><\/presenter>, <presenter><i>Megan Rothney<\/i><\/presenter>, <presenter><i>Benjamin Glass<\/i><\/presenter>, <presenter><i>Ilan Wapinski<\/i><\/presenter>, <presenter><i>Andrew Beck<\/i><\/presenter>, <presenter><u><i>Eric Walk<\/i><\/u><\/presenter>. PathAI, Boston, MA","CSlideId":"","ControlKey":"dab2a532-d373-488a-a568-af0afdafebd9","ControlNumber":"5191","DisclosureBlock":"<b>&nbsp;M. Griffin, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>M. Gemici, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>A. Javed, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>N. Agrawal, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>M. Resnick, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>L. Yu, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>S. Hoffman, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>V. Mountain, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>J. Harisiades, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>M. Rothney, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>B. Glass, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>I. Wapinski, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>A. Beck, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>E. Walk, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"14846","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/34691c26-18aa-422a-b78f-f943ac5971a3\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"18","PosterboardNumber":"22","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"471","PresenterBiography":null,"PresenterDisplayName":"Eric Walk, MD","PresenterKey":"1676b9b8-3422-40d7-8eea-9a8e165d017d","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"471. AIM PD-L1-NSCLC: Artificial intelligence-powered PD-L1 quantification for accurate prediction of tumor proportion score in diverse, multi-stain clinical tissue samples","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AIM PD-L1-NSCLC: Artificial intelligence-powered PD-L1 quantification for accurate prediction of tumor proportion score in diverse, multi-stain clinical tissue samples","Topics":null,"cSlideId":""},{"Abstract":"<b>Introduction: <\/b>Pancreatic adenocarcinoma (PAC) is highly heterogeneous, resulting in overall ineffectiveness of most anti-tumor treatments. Two tumor subtypes (Classical and Basal) and two stromal subtypes (&#8220;active&#8221; and &#8220;inactive&#8221;) have been described. The Basal and the active stroma have worse prognosis. These subtypes could also be predictive of the response to different chemotherapies. To date, molecular subtype classification or phenotype quantification can only be defined by RNAseq, a complex technique sensitive to the quantity and quality of samples, requiring a timescale limiting its routine application. We propose a deep learning approach (PACpAInt) to predict molecular subtypes in PAC on routine histological slides.<br \/><b>Patients and <\/b><b>Methods: <\/b>424 digitalized HES slides of 202 resected PAC from 3 centers with clinical and transcriptomic data were used as training cohort. 3 validation cohorts were used (i) 250 resected PAC from a 4th center including 97 cases with an exact HES\/RNAseq spatial match and all tumor slides digitalized (n = 891); (ii) 126 resected PAC from the TCGA (HES + RNAseq); (iii) 25 liver biopsies from metastatic PAC (HES + RNAseq). A multi-step deep learning model was developed to recognize tumor tissue, tumor from stroma cells, and then predicts their transcriptomic molecular subtypes, either at the level of an entire slide, or at the tile level (squares of 112 &#956;m) allowing to study intratumor heterogeneity.<br \/><b>Results: <\/b>PACpAInt correctly predicted the tumor subtype at the whole slide level (AUC = 0.86 and 0.81 in 2 validation cohorts) and improved for samples with unambiguous molecular subtype (AUC = 0.91 and 0.88) confirming the limit of a binary approach. Similar results were obtained on liver biopsies (AUC = 0.85 and 0.92 on unambiguous cases). PACpAInt independently predicted progression-free and overall survival (PFS HR=1.37 [1.16 - 1.62] and OS HR=1.27 [1.08 - 1.49]). Analysis of all tumor slides from 77 Classical cases showed that 39% were heterogeneous with a Basal contingent. These cases had shorter PFS (15 vs. 47 months, p= 0.001) and OS (31 vs. 64 months, p= 5e-5).The analysis of intratumoral heterogeneity using PACpAInt predicted the molecular subtype of tumor and stroma cells of each tile within a slide (&#62; 6 million tiles analyzed). 61% of cases had a main subtype either Classical (42%) or Basal (19%). 39% of the cases were ambiguous could be considered either hybrid (10%) with coexistence of Basal and Classical cells, or intermediate (29%) corresponding to homogeneous tumors but of intermediate differentiation. This classification had a strong prognostic impact (OS: 45.1 vs 33.0 vs 23.4 vs 13.6 months, resp. Classical, intermediate, hybrid, Basal; p &#60;e-12).<br \/><b>Conclusion: <\/b>This study provides the first PAC subtyping tool widely usable in clinical practice, opening the possibility of molecular classification useful for routine care and clinical trials.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/518156c9-449f-4f5b-a0e3-f5d83f0b319e\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Pancreatic cancer,Deep learning,Transcription,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/19146"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Charlie Saillard<\/i><\/u><\/presenter>, <presenter><i>Flore Delecourt<\/i><\/presenter>, <presenter><i>Benoit Schmauch<\/i><\/presenter>, <presenter><i>Olivier Moindrot<\/i><\/presenter>, <presenter><i>Magali Svrcek<\/i><\/presenter>, <presenter><i>Armelle Bardier-Dupas<\/i><\/presenter>, <presenter><i>Jean Francois Emile<\/i><\/presenter>, <presenter><i>Mira Ayadi<\/i><\/presenter>, <presenter><i>Vinciane Rebours<\/i><\/presenter>, <presenter><i>Louis De Mestier<\/i><\/presenter>, <presenter><i>Pascal Hammel<\/i><\/presenter>, <presenter><i>Cindy Neuzillet<\/i><\/presenter>, <presenter><i>Jean Baptiste Bachet<\/i><\/presenter>, <presenter><i>Juan Iovanna<\/i><\/presenter>, <presenter><i>Nelson Dusetti<\/i><\/presenter>, <presenter><i>Yuna Blum<\/i><\/presenter>, <presenter><i>Magali Richard<\/i><\/presenter>, <presenter><i>Yasmina Kermezli<\/i><\/presenter>, <presenter><i>Valerie Paradis<\/i><\/presenter>, <presenter><i>Mikhail Zaslavskiy<\/i><\/presenter>, <presenter><i>Pierre Courtiol<\/i><\/presenter>, <presenter><i>Aurelie Kamoun<\/i><\/presenter>, <presenter><i>Remy Nicolle<\/i><\/presenter>, <presenter><i>Jerome Cros<\/i><\/presenter>. Owkin, Paris, France, Beaujon Hospital-INSERMU1149, Clichy, France, OWKIN, Paris, France, MATI, Paris, France, Saint-Antoine Hospital - Sorbonne Universités, Paris, France, Pitié-Salpêtrière Hospital - Sorbonne Universités, Paris, France, Ambroise Paré Hospital – Université Saint Quentin en Yvelines, Clichy, France, INTEGRAGEN, Paris, France, Université de Paris-Beaujon Hospital-INSERMU1149, Clichy, France, Paul Brousse Hospital, Villejuif, France, Institut Curie, Paris, France, Pitié-Salpêtrière Hospital - Sorbonne Universités, Paris, France, Institut Paoli-Calmettes, Aix Marseille Université, Marseille, France, Université de Rennes 1, Rennes, France, Université Grenoble-Alpes, Grenoble, France, Université de Paris-Beaujon Hospital-INSERMU1149, Clichy, France, Beaujon Hospital-INSERMU1149, Clichy, France","CSlideId":"","ControlKey":"60405b64-2a92-4d03-b8b1-74e84e6b927f","ControlNumber":"3692","DisclosureBlock":"<b>&nbsp;C. Saillard, <\/b> <br><b>OWKIN<\/b> Employment, Stock Option.<br><b>F. Delecourt, <\/b> None.&nbsp;<br><b>B. Schmauch, <\/b> <br><b>OWKIN<\/b> Employment, Stock Option, Yes.<br><b>O. Moindrot, <\/b> None.&nbsp;<br><b>M. Svrcek, <\/b> <br><b>Bristol-Myers Squibb<\/b> Travel, Other, Advisory Role, No. <br><b>Astellas<\/b> Other, Advisory Role, No. <br><b>MSD Oncology<\/b> Other, Advisory Role, No. <br><b>Sanofi<\/b> Other, Advisory Role, No. <br><b>Bayer<\/b> Other, Advisory Role, No. <br><b>Ventana\/Roche<\/b> Grant\/Contract, No.<br><b>A. Bardier-Dupas, <\/b> None..<br><b>J. Emile, <\/b> None..<br><b>M. Ayadi, <\/b> None..<br><b>V. Rebours, <\/b> None.&nbsp;<br><b>L. De Mestier, <\/b> <br><b>AAA<\/b> Other, Personnal fees, No. <br><b>IPSEN<\/b> Other, Personnal fees, No. <br><b>KEOCYT<\/b> Other, Personnal fees, No. <br><b>SIRTEX<\/b> Other, Personnal fees, No. <br><b>P. Hammel, <\/b> <br><b>Amgen<\/b> Other, Boards, No. <br><b>AstreaZeneca<\/b> Other, Boards, No. <br><b>Erythec<\/b> Other, Boards, No. <br><b>Halozyme<\/b> Other, Boards, No. <br><b>Vect-Horus<\/b> Other, Boards, No. <br><b>Viatris<\/b> Other, Boards, No. <br><b>Ipsen<\/b> Grant\/Contract, No. <br><b>Pfizer<\/b> Grant\/Contract, No. <br><b>C. Neuzillet, <\/b> <br><b>Amgen<\/b> Grant\/Contract, No. <br><b>AstraZeneca<\/b> Grant\/Contract, No. <br><b>Baxter<\/b> Grant\/Contract, No. <br><b>Bristol-Myers Squibb<\/b> Grant\/Contract, No. <br><b>Fresenius Kabi<\/b> Grant\/Contract, No. <br><b>Incyte Biosciences<\/b> Grant\/Contract, No. <br><b>Merck<\/b> Grant\/Contract, No. <br><b>MSD<\/b> Grant\/Contract, No. <br><b>Mylan\/Viatris<\/b> Grant\/Contract, No. <br><b>Novartis<\/b> Grant\/Contract, No. <br><b>Nutricia<\/b> Grant\/Contract, No. <br><b>Pierre Fabre<\/b> Grant\/Contract, No. <br><b>Roche<\/b> Grant\/Contract, No. <br><b>Sanofi<\/b> Grant\/Contract, No. <br><b>Servier<\/b> Grant\/Contract, No. <br><b>J. Bachet, <\/b> <br><b>AstraZeneca<\/b> Grant\/Contract, No. <br><b>Bayer<\/b> Grant\/Contract, No. <br><b>Pierre Fabre<\/b> Grant\/Contract, No. <br><b>Sanofi<\/b> Grant\/Contract, No. <br><b>Servier<\/b> Grant\/Contract, No. <br><b>Shire<\/b> Grant\/Contract, No.<br><b>J. Iovanna, <\/b> None..<br><b>N. Dusetti, <\/b> None..<br><b>Y. Blum, <\/b> None..<br><b>M. Richard, <\/b> None..<br><b>Y. Kermezli, <\/b> None..<br><b>V. Paradis, <\/b> None.&nbsp;<br><b>M. Zaslavskiy, <\/b> <br><b>OWKIN<\/b> Employment, Stock Option. <br><b>P. Courtiol, <\/b> <br><b>OWKIN<\/b> Stock Option, Yes. <br><b>A. Kamoun, <\/b> <br><b>OWKIN<\/b> Employment, Stock Option, Yes.<br><b>R. Nicolle, <\/b> None.&nbsp;<br><b>J. Cros, <\/b> <br><b>Owkin<\/b> Patent, Yes. <br><b>IPSEN<\/b> Travel, No.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"19146","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/518156c9-449f-4f5b-a0e3-f5d83f0b319e\/@v03B8ZAB\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"19","PosterboardNumber":"23","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"472","PresenterBiography":null,"PresenterDisplayName":"Charlie Saillard","PresenterKey":"fbfc1c45-8607-4929-9001-1c5efee84ba8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"472. PACpAInt: A deep learning approach to identify molecular subtypes of pancreatic adenocarcinoma on histology slides","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"PACpAInt: A deep learning approach to identify molecular subtypes of pancreatic adenocarcinoma on histology slides","Topics":null,"cSlideId":""},{"Abstract":"<b>Introduction: <\/b>Genomic events in cancer driver genes such as mutations and copy number alterations play critical roles in cancer onset and progression. Here we apply a novel biologically inspired deep learning classification method called GeneMasking to perform prostate cancer (PC) classification high accuracy. The important key novelty of GeneMasking is that it marks the genomic events that determine the classification of a given sample in a <i>sample-specific <\/i>manner. This provides us with an exciting opportunity to investigate two fundamental cancer research questions: 1.For a specific tumor sample, which cancer driver genes are functionally important, playing a detrimental role in its classification? 2.For a specific tumor sample, does an established cancer driver gene act as oncogene or tumor suppressor gene (TSG) in that sample?<br \/><b>Methods: <\/b>We applied GeneMasking to study these questions by analyzing the somatic mutation and copy number alteration (CNA) data of 1011 PC patient samples recently published by Elmarakeby et al. [Nature 598, 348-352 (2021)] and classify as primary or metastatic tumors. GeneMasking achieves an overall AUC (area under the receiver operating characteristic curve)&#8201;of&#8201;0.958 in this classification task. Additionally and importantly, for each sample, GeneMasking provides a list of genes with mutation and\/or CNA events that are important in classifying it. We focus on 61 known COSMIC cancer driver genes marked as important in &#8805; 20 samples. A driver gene that is marked as <i>important<\/i> is inferred as <i>oncogenic-acting<\/i> in that given sample if it is amplified or mutated by an activating mutation, and vice versa for inferring it as a <i>TSG-acting<\/i> in that sample. For each gene, we compute the <i>oncogene\/TSG ratio<\/i> of its inferred function across all samples where it was marked &#8216;important&#8217;. We then investigate whether this ratio is higher than 1 as expected for drivers traditionally labeled oncogenes, or lower, as expected for those known as TSGs.<br \/><b>Results: <\/b>Our key findings are: 1) For 44 drivers (including 5 PC-specific genes), the overall inferred oncogene\/TSG ratios reassuringly match their conventional annotations as oncogenes or TSGs in COSMIC.<br \/>2) For 8 drivers, however, their inferred oncogene\/TSG ratios are <i>opposite<\/i> from those listed in COSMIC. Those include MUC4, XPO1, FANCD2 etc.<br \/>3) 5 drivers are annotated as both oncogenes and TSGs in COSMIC and here we infer their specific roles in PC.<br \/><b>Conclusions: <\/b>We provide a first-of-its-kind computational approach to annotate cancer driver genes as oncogenes or TSGs in a patient cohort. This lays the basis for two future exciting applications: (a) Identifying the contexts in which a driver acts as oncogene or TSG, and (b) Help advance precision oncology, targeting actionable mutations of drivers only when they are truly oncogenic.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/a6ec934f-203b-45f2-a75a-d2e829bed127\/@w03B8ZAC\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Cancer genomics,Tumor suppressor gene,Oncogene,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/19151"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[{"FileType":"mp3","Icon":"far fa-file-audio","Label":"Audio","Reference":"4dcbb158-e142-4048-b485-2a6a33fb1ebf","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/4dcbb158-e142-4048-b485-2a6a33fb1ebf\/@w03B8ZAC\/mp3"}],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Saugato Rahman Dhruba<\/i><\/u><\/presenter>, <presenter><i>Niv Amitay<\/i><\/presenter>, <presenter><i>Lior Wolf<\/i><\/presenter>, <presenter><i>Eytan Ruppin<\/i><\/presenter>. National Cancer Institute, National Institutes of Health, Bethesda, MD, Tel Aviv University, Tel Aviv, Israel","CSlideId":"","ControlKey":"45cc38be-c8cb-4082-a2b6-b2b01b7f0985","ControlNumber":"2633","DisclosureBlock":"&nbsp;<b>S. Dhruba, <\/b> None..<br><b>N. Amitay, <\/b> None..<br><b>L. Wolf, <\/b> None.&nbsp;<br><b>E. Ruppin, <\/b> <br><b>Pangea Therapeutics<\/b> Other, Eytan Ruppin is a co-founder and scientific consultant of Pangea Therapeutics (https:\/\/pangeamedicine.com\/), however he has divested all his shares and receives no salary or financial benefit from this company., No. <br><b>MedAware Ltd.<\/b> Other, Eytan Ruppin is a co-founder of Medaware Ltd (https:\/\/www.medaware.com\/)., Yes. <br><b>Metabomed<\/b> Other, Eytan Ruppin is a co-founder of Metabomed (https:\/\/www.metabomed.com\/)., No.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"19151","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/a6ec934f-203b-45f2-a75a-d2e829bed127\/@w03B8ZAC\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"20","PosterboardNumber":"24","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"473","PresenterBiography":null,"PresenterDisplayName":"Saugato Rahman Dhruba, PhD","PresenterKey":"53d64d93-9d36-4464-b988-0f0f27132bfb","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"473. GeneMasking: A new approach for inferring the functional role of cancer driver genes and its application in prostate cancer","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"GeneMasking: A new approach for inferring the functional role of cancer driver genes and its application in prostate cancer","Topics":null,"cSlideId":""},{"Abstract":"Background: In lung cancer, the KEAP1\/NRF2 pathway modulates an anti-tumor response by regulating cellular metabolism and inflammatory processes. Approximately 19% of lung adenocarcinoma (LUAD) tumors have a mutation in KEAP1. Clinically, KEAP1-mutated LUAD has poor prognosis, and there is need for rapid and accurate patient genotyping to inform treatment decisions. Here, we describe machine learning (ML) models that can predict KEAP1 mutation status from tissue histology.<br \/>Methods: ML models, pre-trained to identify and quantify areas of tissue (cancer epithelium, cancer stroma, and necrosis), counts of cancer, fibroblast, and immune cells (lymphocytes, macrophages, plasma cells) in non-small cell lung cancer (NSCLC), were applied to 208 hematoxylin and eosin (H&#38;E)-stained whole slide images (WSI) of LUAD from The Cancer Genome Atlas (TCGA) without further training. Genomic analyses indicated that 17% (N=35) of these cases are KEAP1MUT. Human Interpretable Features (HIFs), based on histology predictions, are automatically extracted from the model and provide a quantitative description of the tumor microenvironment of each WSI. Associations between HIFs and KEAP1MUT were determined by univariate analysis followed by false discovery rate (FDR) correction. Hierarchical clustering using cross correlation and combining p-values for HIF groups using an Empirical Brown&#8217;s method identified correlations between HIFs. Confounding factor influence was accounted for after positive associations were identified. Independent validation of associations between KEAP1MUT and HIFs was performed using TCGA transcriptomic data to correlate specific mutations with mRNA expression of relevant markers.<br \/>Results: ML-models generated 4,443 HIFs from the TCGA LUAD WSI, which were reduced to 2,684 HIFs after removal of outlier HIFs, exclusion of HIFs that are degenerate, have missing features, or are of an absolute value.<br \/>KEAP1MUT was significantly associated with 193 HIFs in univariate analyses (p&#60;0.05 after FDR correction), and four groups of HIFs after taking correlations into account (p&#60;0.05 after group-wise FDR correction; 211-264 HIFs per group). 161 HIFs were identified by both methods. Further assessment of the KEAP1MUT -associated HIFs showed that these mutations were correlated with a reduction in macrophages in the tumor microenvironment (TME). This was supported by analysis of transcriptomic data from KEAP1MUT (N=35) and KEAP1WT (N=164) samples, which showed significantly reduced expression of the macrophage marker CD14 (p&#60;0.001) in KEAP1MUT tissue samples.<br \/>Conclusions: ML model quantification of TME histological features can generate HIFs that correlate with the KEAP1MUT status of a LUAD biopsy. These results exemplify how ML-powered digital pathology could predict molecular markers directly from standard H&#38;E biopsy slides.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":"https:\/\/cslide-us.ctimeetingtech.com\/play\/6577084e-49c3-49fa-8c32-835e05005e59\/@w03B8ZAC\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png"},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology and artificial intelligence,,"},{"Key":"Keywords","Value":"Predictive biomarkers,Pathology,KEAP1,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":"https:\/\/cattendee.abstractsonline.com\/meeting\/10517\/Presentation\/21613"},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<presenter><u><i>Robert Egger<\/i><\/u><\/presenter>, <presenter><i>Martin Ieong<\/i><\/presenter>, <presenter><i>Murray Resnick<\/i><\/presenter>, <presenter><i>Amaro Taylor-Weiner<\/i><\/presenter>, <presenter><i>Victoria Mountain<\/i><\/presenter>, <presenter><i>Ilan Wapinski<\/i><\/presenter>, <presenter><i>Michael Montalto<\/i><\/presenter>, <presenter><i>Andrew Beck<\/i><\/presenter>, <presenter><i>Josie Hayes<\/i><\/presenter>, <presenter><i>Benjamin Glass<\/i><\/presenter>. PathAI, Boston, MA, Revolution Medicines, Redwood City, CA","CSlideId":"","ControlKey":"95585ccf-1d34-4fc0-b783-964392864671","ControlNumber":"5077","DisclosureBlock":"<b>&nbsp;R. Egger, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>M. Ieong, <\/b> <br><b>Revolution Medicines<\/b> Employment, Yes. <br><b>M. Resnick, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>A. Taylor-Weiner, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>V. Mountain, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>I. Wapinski, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes. <br><b>M. Montalto, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>A. Beck, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>J. Hayes, <\/b> <br><b>Revolution Medicines<\/b> Employment, Yes. <br><b>B. Glass, <\/b> <br><b>PathAI<\/b> Employment, Stock Option, Yes.","End":"4\/10\/2022 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"21613","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"MediaItem","OtherContent":null,"PlayerUrl":"https:\/\/cslide-us.ctimeetingtech.com\/play\/6577084e-49c3-49fa-8c32-835e05005e59\/@w03B8ZAC\/pdf?cover=https:\/\/files.abstractsonline.com\/SUPT\/101\/10517\/cfg-cattendee-cslide-player-cover.png","PlayerUrlReason":null,"PositionInSession":"21","PosterboardNumber":"25","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"449","PresenterBiography":null,"PresenterDisplayName":"Robert Egger","PresenterKey":"18c61f5e-753d-450b-b0d8-cb4d976abacc","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"449. Machine learning models identify histological features that can predict KEAP1 mutations in lung adenocarcinoma","SearchResultFooter":"","SearchResultHeader":"Apr 10 2022  1:30PM","SessionId":"299","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Digital Pathology","ShowChatLink":"false","Start":"4\/10\/2022 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Machine learning models identify histological features that can predict KEAP1 mutations in lung adenocarcinoma","Topics":null,"cSlideId":""}]