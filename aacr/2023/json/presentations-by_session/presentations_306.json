[{"Abstract":"The increasing use of precious, patient-derived cells has driven the need for non-perturbing and label-free cell measurements, particularly in the oncology field. To address this we developed the Incucyte<sup>&#174;<\/sup> AI Cell Health Analysis Software Module, which uses two pre-trained deep neural networks to perform automated, unbiased analysis of Phase contrast images to segment individual cells and perform label-free Live\/Dead cell classification. The neural networks which perform cell instance segmentation and infer cell viability were trained on a wide diversity of cell types with varied morphologies, ensuring that the analysis is applicable across a variety of adherent and suspension tumor cell types. Here, we demonstrate the application of this analysis across diverse and commonly used biological models of breast cancer, glioblastoma, and B-cell lymphoma. In each case, cells were treated with chemotherapeutic compounds or biosimilar antibodies and Phase contrast images were acquired at regular intervals over 3 - 4 days using the Incucyte<sup>&#174;<\/sup> Live-Cell Analysis System. Using the Incucyte<sup>&#174;<\/sup> AI Cell Health Analysis cells were accurately segmented and the percentage of dead cells were quantified over time without the requirement for a fluorescent reporter or other exogenous label, and with limited user input. Four breast cancer cell lines were treated with a panel of chemotherapeutics designed to target specific expression patterns. AI Cell Health analysis showed that Estrogen receptor (ER) inhibitor Tamoxifen selectively induced &#62;60% cell death only in ER positive cell lines BT474 and MCF7; dual epidermal growth factor receptor (EGFR\/ HER2) inhibitor Lapatinib induced cell death in AU565, BT474 and MCF7 which express these surface markers. In contrast, Lapatinib and Tamoxifen induced morphological change - but minimal cell death - in triple negative MDA-MB-231 cells. Three glioblastoma cell lines A172, U87 and T98G were treated with a larger panel of chemotherapeutic compounds and for four of the active compounds, efficacy was also determined. Cisplatin, doxorubicin, vinblastine and taxol induced concentration-dependent cell death in A172 and T98G cells; U87 cells displayed resistance to each of these compounds with a maximal 46.5% cell death induced by doxorubicin. Ramos B-cell lymphoma cells were exposed to increasing concentrations of monoclonal antibody Rituximab and the biosimilar Truxima<sup>&#174;<\/sup>. The antibodies induced specific cell death via the surface marker CD20 in a time and concentration-dependent manner with similar efficacy (IC<sub>50<\/sub> Rituximab 94.7 ng\/mL; Truxima<sup>&#174;<\/sup> 110.3 ng\/mL), while antibody control IgG1 remained non-perturbing to cells. These results demonstrate that the Incucyte<sup>&#174;<\/sup> AI Cell Health Analysis is applicable to a broad range of cancer types cultured in 2D monolayer. This unbiased method enables accurate, label-free quantification of cytotoxic effects induced by clinically relevant therapeutics.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Image analysis,Cell death,Breast cancer,Glioma cell lines,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Gillian Lovell<\/b><sup>1<\/sup>, Daniel  A.  Porto<sup>2<\/sup>, Jasmine Trigg<sup>1<\/sup>, Nevine Holtz<sup>2<\/sup>, Nicola Bevan<sup>1<\/sup>, Timothy Dale<sup>1<\/sup>, Daniel Appledorn<sup>2<\/sup><br><br\/><sup>1<\/sup>Sartorius, Royston, United Kingdom,<sup>2<\/sup>Sartorius, Ann Arbor, MI","CSlideId":"","ControlKey":"c5926c5f-a378-41aa-b5f3-04aadd3cf787","ControlNumber":"1612","DisclosureBlock":"<b>&nbsp;G. Lovell, <\/b> <br><b>Sartorius<\/b> Employment. <br><b>D. A. Porto, <\/b> <br><b>Sartorius<\/b> Employment. <br><b>J. Trigg, <\/b> <br><b>Sartorius<\/b> Employment. <br><b>N. Holtz, <\/b> <br><b>Sartorius<\/b> Employment. <br><b>N. Bevan, <\/b> <br><b>Sartorius<\/b> Employment. <br><b>T. Dale, <\/b> <br><b>Sartorius<\/b> Employment. <br><b>D. Appledorn, <\/b> <br><b>Sartorius<\/b> Employment.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8092","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"1","PosterboardNumber":"1","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5418","PresenterBiography":null,"PresenterDisplayName":"Gillian Lovell, MS;PhD","PresenterKey":"dc052a0b-e526-464b-9cb1-a2bcc07d4d17","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5418. AI-driven image analysis enables simplified, label-free cytotoxicity screening","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AI-driven image analysis enables simplified, label-free cytotoxicity screening","Topics":null,"cSlideId":""},{"Abstract":"Purpose Tertiary lymphoid structures are organized aggregates of immune cells present in the tumor microenvironment (TME) in which novel targets as well as beneficial biomarkers for immunotherapy in cancer were found. Here, we have developed and validated a deep learning model by integrating H&#38;E images of renal cell carcinoma and spatial transcriptomics data to infer spatial mapping of tertiary lymphoid structure scores in TME only using hematoxylin and eosin (H&#38;E) images.<br \/>Methods A total of 20 H&#38;E images combined with spatial transcriptomics data of renal cell carcinoma were used to develop a model. Tertiary lymphoid structure scores can be acquired for each spot in spatial transcriptomics by geometric mean of the specific gene expression relevant to B cell, T cell, immunoglobulin, fibroblast, complement, and others. A convolutional neural network using H&#38;E image patches as inputs was developed to predict the tertiary lymphoid structure scores from H&#38;E-stained tissue image patches of renal cell carcinoma acquired by different patients. For the external validation, the model estimated the tertiary lymphoid structure scores from H&#38;E-stained tissue image patches of renal cell carcinoma of The Cancer Genome Atlas (TCGA-RCC).<br \/>Results The tertiary lymphoid structure scores inferred by the model using H&#38;E image patches were significantly correlated with those derived by spatial transcriptomics data as an internal validation (r = 0.68, p &#60; 1e-10) . The mean value of the deep learning-based tertiary lymphoid structure scores estimated by the TCGA-RCC tissue images was significantly correlated with the tertiary lymphoid structure scores, T cell enrichment scores and immune cell enrichment scores estimated by bulk RNA-seq data from the corresponding TCGA data.<br \/>Conclusions A deep learning model to infer spatial tertiary lymphoid structure in the tumor microenvironment using H&#38;E images was developed. As the tertiary lymphoid structure is a key to predict responsiveness of immune checkpoint inhibitors, mapping the score only using H&#38;E images could be clinically translated into image-based biomarkers. This approach can provide objective and flexible deep learning-based models for characterizing tumor microenvironment related to spatial immune distribution.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Renal cell carcinoma,Tumor microenvironment,Tumor immunity,The Cancer Genome Atlas (TCGA),"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Seungho Cook<\/b><sup>1<\/sup>, Haenara Shin<sup>2<\/sup>, Mi-Kyoung Seo<sup>1<\/sup>, Dae Seung Lee<sup>1<\/sup>, Hongyoon Choi<sup>3<\/sup><br><br\/><sup>1<\/sup>Portrai, Inc, Seoul, Korea, Republic of,<sup>2<\/sup>Kim Jaechul Graduate School of AI, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea, Republic of,<sup>3<\/sup>Department of Nuclear Medicine, Seoul National University Hospital, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"dfa7a01e-19bd-4cdc-aac5-1b02331f5dea","ControlNumber":"2177","DisclosureBlock":"<b>&nbsp;S. Cook, <\/b> <br><b>Portrai<\/b> Employment. <br><b>H. Shin, <\/b> <br><b>Portrai<\/b> Employment. <br><b>M. Seo, <\/b> <br><b>Portrai<\/b> Employment. <br><b>D. Lee, <\/b> <br><b>Portrai<\/b> Stock. <br><b>H. Choi, <\/b> <br><b>Portrai<\/b> Stock.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8094","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"2","PosterboardNumber":"3","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5420","PresenterBiography":null,"PresenterDisplayName":"Seungho Cook, MS","PresenterKey":"52e3d582-1271-4b2d-b822-a2b92fd8f7cd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5420. Deep learning-based mapping of tertiary lymphoid structure scores from H&#38;E images of renal cell carcinoma trained by spatial transcriptomics data","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Deep learning-based mapping of tertiary lymphoid structure scores from H&#38;E images of renal cell carcinoma trained by spatial transcriptomics data","Topics":null,"cSlideId":""},{"Abstract":"Most of the biomedical knowledge the research community has acquired during the past few decades has been deposited in scientific literature as unstructured text. Converting the unstructured text into the structured form will enable novel methodologies and applications for scientific discovery that can fully harness the power of the existing knowledge. To this end, two fundamental questions need to be addressed: named entity recognition (NER) and relation extraction (RE). NER deals with identifying the concepts or entities in texts, such as diseases, genes\/proteins, chemical compounds, etc. while RE aims to extract the relations among these entities. Together, the extracted information forms a knowledge graph (KG) where the nodes are entities in the texts and the edges represent their relationships. KGs can link concepts within existing research to allow researchers to find connections that may have been difficult to discover without them. The LitCoin Natural Language Processing (NLP) Challenge was recently organized by NCATS of NIH and NASA to spur innovation by rewarding the most creative and high-impact uses of biomedical text to create KGs. Our team participated in the challenge and ranked first place. We have applied the methods we developed for the LitCoin NLP challenge to all PubMed abstracts and constructed the largest-scale biomedical KG to date. We show that powerful and versatile query functions can be implemented on top of the KG to enable highly specific and accurate knowledge retrieval and inference of causal and indirect relationships.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Bioinformatics,Knowledge graph,Natural language processing,Information retrieval,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Xin Sui<sup>1<\/sup>, Yuan Zhang<sup>2<\/sup>, Feng Pan<sup>2<\/sup>, Donghu Sun<sup>1<\/sup>, Menghan Chung<sup>1<\/sup>, <b>Jinfeng Zhang<\/b><sup>2<\/sup><br><br\/><sup>1<\/sup>Insilicom LLC, Tallahassee, FL,<sup>2<\/sup>Florida State University, Tallahassee, FL","CSlideId":"","ControlKey":"ce0c625c-3a81-47d3-89af-1fd98bd3f711","ControlNumber":"5698","DisclosureBlock":"<b>&nbsp;X. Sui, <\/b> <br><b>Insilicom LLC<\/b> Employment.<br><b>Y. Zhang, <\/b> None..<br><b>F. Pan, <\/b> None..<br><b>D. Sun, <\/b> None..<br><b>M. Chung, <\/b> None.&nbsp;<br><b>J. Zhang, <\/b> <br><b>Insilicom LLC<\/b> Other Business Ownership.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8095","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"3","PosterboardNumber":"4","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5421","PresenterBiography":null,"PresenterDisplayName":"Jinfeng Zhang, PhD","PresenterKey":"c4ab062c-3048-4266-860a-344e32408ba8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5421. Constructing the largest-scale knowledge graph using all PubMed abstracts and its application for highly specific and accurate knowledge retrieval","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Constructing the largest-scale knowledge graph using all PubMed abstracts and its application for highly specific and accurate knowledge retrieval","Topics":null,"cSlideId":""},{"Abstract":"Renal cell carcinoma (RCC) is a heterogeneous disease with 16 different subtypes identified and diagnosed by assessment of tumor histology, and specific molecular and genetic markers. Three major subtypes - clear cell, papillary, and chromophobe carcinoma - have different prognoses and treatment regimens. Treatment response has been associated with mutations that may affect the tumor microenvironment (TME). Here, machine learning (ML) models quantified histologic features of the TME directly from RCC hematoxylin and eosin (H&#38;E)-stained whole slide images (WSI). The potential for model outputs to predict clinically-relevant biomarkers was investigated.<br \/>Machine learning models based on convolutional neural networks were trained using RCC and non-RCC kidney WSI of biopsies and resections from the cancer genome atlas (TCGA), proprietary, and commercial sources (tissue model N=3208; cell model N=789; vessel model N=839) to classify and quantify histologic features of the TME including cells, tissues, and blood vessels. Thousands of human interpretable features (HIFs) were extracted from model predictions that precisely describe the TME across each WSI (e.g., cell density within a tissue region). Associations between HIFs and PBRM1 loss of function (LOF) mutations and VEGFA mRNAseq expression in clear cell RCC were determined using univariate logistic regressions and Spearman correlations, respectively. False discovery rate in multiple hypothesis testing was controlled using an Empirical Brown&#8217;s Method and the Benjamini-Hochberg procedure.<br \/>ML-models generated 3390 HIFs from 692 TCGA RCC WSI. After quality control to remove features with missing values, outlier slides and de-duplication, 237 HIFs (657 WSI) remained. Major RCC subtypes could be extracted directly from these HIFs using hierarchical clustering (p&#60;10-6, chi-squared test). Individual RCC subtypes were distinguished by features describing immune cells and vascularization. A mixed subcluster enriched for higher stage (p&#60;10-6, chi-squared test) papillary and clear cell RCC tumors was associated with increased prevalence of sarcomatoid regions and immune cells. In clear cell RCC, significant associations were found between HIFs describing a spatially specific increase in lymphocytes in the cancer epithelium (FDR-corrected p=0.004) and decrease in macrophages (FDR-corrected p=0.004) in the entire tumor area and PBRM1MUT, a mutation associated with response to immunotherapy; VEGFA expression, predictive of angiogenesis, positively associated with an increased abundance of lymphocytes near erythrocytes (Spearman r=0.37).<br \/>ML model quantified RCC TME histology allowed identification of spatially specific differences that correlate with histological subtypes, mutations, and vascularization. Complementary ML-based TME assessment and genomic analyses may be used, after further validation, to explore novel biomarkers.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Renal cell carcinoma,Machine learning,Histopathology,Biomarkers,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Samuel Vilchez<\/b><sup><\/sup>, Isaac Finberg<sup><\/sup>, Miles Markey<sup><\/sup>, Shima Nofallah<sup><\/sup>, Kathleen Sucpito<sup><\/sup>, Fedaa Najdawi<sup><\/sup>, Geetika Singh<sup><\/sup>, Ben Trotter<sup><\/sup>, Victoria Mountain<sup><\/sup>, Jake Conway<sup><\/sup>, Robert Egger<sup><\/sup>, Chintan Parmar<sup><\/sup>, Ilan Wapinski<sup><\/sup>, Stephanie Hennek<sup><\/sup>, Jonathan Glickman<sup><\/sup><br><br\/>PathAI, Inc., Boston, MA","CSlideId":"","ControlKey":"61f700f3-caaf-4066-8c70-21bb85ce4635","ControlNumber":"5128","DisclosureBlock":"<b>&nbsp;S. Vilchez, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>I. Finberg, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>M. Markey, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>S. Nofallah, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>K. Sucpito, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>F. Najdawi, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>G. Singh, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>B. Trotter, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>V. Mountain, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>J. Conway, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>R. Egger, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>C. Parmar, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>Novartis<\/b> Employment. <br><b>I. Wapinski, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>S. Hennek, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>J. Glickman, <\/b> <br><b>PathAI<\/b> Employment, Stock Option.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8096","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"4","PosterboardNumber":"5","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5422","PresenterBiography":null,"PresenterDisplayName":"Samuel Vilchez, PhD","PresenterKey":"2540fbfb-a465-441c-ab6b-4921c384c91c","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5422. Machine learning models identify key histological features of renal cell carcinoma subtypes","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Machine learning models identify key histological features of renal cell carcinoma subtypes","Topics":null,"cSlideId":""},{"Abstract":"Background: Mitotic rate is a readout routinely used for characterization of tumor samples. Standard methods to quantify cell division include manual pathologist counts based on hematoxylin and eosin (H&#38;E) staining and either manual or automated assessment of immunohistochemistry (IHC) staining using phospho-histone H3 (pHH3). These suffer the drawbacks of high inter-pathologist variability in the case of H&#38;E assessment and time inefficiency and false positive calls in case of pHH3 staining. Aiming to overcome these issues, we developed a mitosis detection model based on H&#38;E-stained tissue sections alone.<br \/>Methods: To develop and evaluate the model, we used 1032 H&#38;E-stained tissue sections (156 used for model training) of pre-clinical pancreas cancer xenografts originating from mice that have undergone a series of experiments conducted to examine the pharmacodynamic effect of several anti-cancer protocols. We trained (i) a tissue segmentation model (segmenting tissue regions into &#8216;carcinoma&#8217;, &#8216;stroma&#8217;, &#8216;necrosis&#8217;, and &#8216;other&#8217;) and (ii) a segmentation model for pixel-level mitosis detection (segmenting &#8216;mitosis&#8217; vs. &#8216;non-mitosis&#8217;). Regions predicted as mitosis were post-processed to represent individual dividing cells. The tissue segmentation model served as a filter to predict mitotic rate for carcinoma tissue areas only, which has not been accounted for in previous AI-based methods for mitotic rate prediction on H&#38;E tissue. To evaluate the model on detecting mitotic events, the model was compared against a 5-pathologist consensus of mitotic count. The mitotic rates predicted by the model were used to infer differences between treatment groups (various treatments and dosages vs. control).<br \/>Results: The mitosis detection model for quantifying rates of cell division in carcinoma regions of H&#38;E-stained tissue sections showed a notable agreement with the 5-pathologist mitotic count consensus (Pearson correlation 0.92). Furthermore, the model correlated well with mitosis counts based on pHH3 IHC staining (Pearson correlation 0.78), which were available for 63 cases. Finally, when used to characterize the entire CDX cohort, the case level mitotic rate predicted by the model showed significant differences between treatment groups in line with or better than using a pHH3 IHC stain.<br \/>Conclusion: This study demonstrates the efficacy and scalability of AI-based models for the quantification of mitotic rate based on H&#38;E-stained tissue alone, presenting a time- and cost-efficient approach that also mitigates inter-annotator variability.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Mitosis,Deep learning,Preclinical,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Sharon Ruane<\/b><sup>1<\/sup>, Lukas Ruff<sup>1<\/sup>, Brian Reichholf<sup>2<\/sup>, Christina Aigner<sup>1<\/sup>, Emil Barbuta<sup>1<\/sup>, Stephan Tietz<sup>1<\/sup>, Olivér Atanaszov<sup>1<\/sup>, Rosemarie Krupar<sup>1<\/sup>, Simon Schallenberg<sup>3<\/sup>, Maximilian Alber<sup>1<\/sup>, Francesca Trapani<sup>2<\/sup>, Frederick Klauschen<sup>4<\/sup><br><br\/><sup>1<\/sup>Aignostics GmbH, Berlin, Germany,<sup>2<\/sup>Boehringer Ingelheim RCV GmbH & Co KG, Vienna, Austria,<sup>3<\/sup>Institute of Pathology, Charité Universitätsmedizin Berlin, Berlin, Germany,<sup>4<\/sup>Institute of Pathology, Ludwig Maximilian University, Munich, Germany","CSlideId":"","ControlKey":"67b08076-eeb2-4ab7-a298-275073730f1d","ControlNumber":"4715","DisclosureBlock":"&nbsp;<b>S. Ruane, <\/b> None..<br><b>L. Ruff, <\/b> None..<br><b>B. Reichholf, <\/b> None..<br><b>C. Aigner, <\/b> None..<br><b>E. Barbuta, <\/b> None..<br><b>S. Tietz, <\/b> None..<br><b>O. Atanaszov, <\/b> None..<br><b>R. Krupar, <\/b> None..<br><b>S. Schallenberg, <\/b> None..<br><b>M. Alber, <\/b> None..<br><b>F. Trapani, <\/b> None.&nbsp;<br><b>F. Klauschen, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract. <br><b>Merck & Co.<\/b> Grant\/Contract. <br><b>Novartis AG<\/b> Grant\/Contract. <br><b>F. Hoffmann-La Roche AG<\/b> Grant\/Contract. <br><b>Eli Lilly and Company<\/b> Grant\/Contract. <br><b>Agilent Technologies, Inc.<\/b> Grant\/Contract. <br><b>Bayer AG<\/b> Grant\/Contract.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8097","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"5","PosterboardNumber":"6","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5423","PresenterBiography":null,"PresenterDisplayName":"Sharon Ruane, BA;D Phil;MS","PresenterKey":"4bb63ce2-b91b-4e10-b809-c5cb583f4b1e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5423. AI powered quantification of mitotic rate in H&#38;E stained tissue detects significant differences between treatment groups of preclinical pancreas cancer xenografts","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AI powered quantification of mitotic rate in H&#38;E stained tissue detects significant differences between treatment groups of preclinical pancreas cancer xenografts","Topics":null,"cSlideId":""},{"Abstract":"Background: Histopathology assessments of cancers require highly skilled pathologists, are labor intensive and prone to errors without proper training or fatigue. Machine learning can assist pathologists by increasing efficiency and minimizing individual variability. This study adapted a deep learning model to reliably identify 3 cell types from triple negative breast cancers fixed on H&#38;E slides and verified performance with an expert pathologist.<br \/>Methods: We apply the U-Net architecture to analyse pathology slides fixed with triple negative breast cancer (TNBC) tissue. The public dataset NuCLS was used for training. Semantic segmentation was used to identify single cells of 3 types: tumor cells, fibroblasts, and tumor infiltrating lymphocyte (TILs). For validation, the pathologist annotated 8 random H&#38;E tiles. The 3 cell types accuracy for NuCLS and the model was evaluated by our pathologist.<br \/>Results: Overall, there was a 73% agreement with the pathologists (Pathologist <i>vs<\/i>. NuCLS). A set of 1,555 (90%) TNBC slides were used for training and 173 for validation (10%; unseen data). Table 1 outlines the accuracy metrics for each cell type and for each comparison. Compared to our pathologist, the model accurately identified TILs (62%), followed by fibroblasts (42%) and lastly tumor cells (26%). A significant source of discrepancy was variation in labeled single cell boundaries. The model was better at identifying TILs. The pathologist took 1.5 hours to annotate 8 tiles for the 3 cells and our model 644ms.<i>Table 1 - Accuracy metrics.<\/i><table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{7C76B695-CB44-4ED7-A218-F9843847D805}\"><caption><\/caption><tr><td rowspan=\"1\" colspan=\"1\"><b> Quality assessment<\/b><b>8 H&#38;E tiles<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Pathologist <i>vs. <\/i>NuCLS<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>U-Net model <i>vs.<\/i> NuCLs<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>U-Net model <i>vs.<\/i> Pathologist<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>U-Net model <i>vs. <\/i>NuCLs (Full)<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Background<\/b><\/td><td rowspan=\"1\" colspan=\"1\">86%<\/td><td rowspan=\"1\" colspan=\"1\">71%<\/td><td rowspan=\"1\" colspan=\"1\">62%<\/td><td rowspan=\"1\" colspan=\"1\">73%<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Tumour<\/b><\/td><td rowspan=\"1\" colspan=\"1\">43%<\/td><td rowspan=\"1\" colspan=\"1\">35%<\/td><td rowspan=\"1\" colspan=\"1\">26%<\/td><td rowspan=\"1\" colspan=\"1\">71%<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Fibroblast<\/b><\/td><td rowspan=\"1\" colspan=\"1\">45%<\/td><td rowspan=\"1\" colspan=\"1\">39%<\/td><td rowspan=\"1\" colspan=\"1\">42%<\/td><td rowspan=\"1\" colspan=\"1\">31%<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>TILs<\/b><\/td><td rowspan=\"1\" colspan=\"1\">34%<\/td><td rowspan=\"1\" colspan=\"1\">96%<\/td><td rowspan=\"1\" colspan=\"1\">62%<\/td><td rowspan=\"1\" colspan=\"1\">87%<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Overall<\/b><\/td><td rowspan=\"1\" colspan=\"1\">73%<\/td><td rowspan=\"1\" colspan=\"1\">74%<\/td><td rowspan=\"1\" colspan=\"1\">61%<\/td><td rowspan=\"1\" colspan=\"1\">71%<\/td><\/tr><\/table><br \/>Conclusion: It is possible to develop a deep learning model to identify breast cancer cells, fibroblasts and TILs from H&#38;E stained slides, with similar accuracy levels as a trained pathologist. The model performed better than a pathologist in identifying TILs, but both struggled with fibroblasts. Accuracy of 71% overall and 87% for TILs, motivates expansion to further datasets and other cancer types.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Histopathology,Breast cancer,Deep learning,Tumor infiltrating lymphocytes,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Luiz Augusto Zillmann da Silva<sup>1<\/sup>, Alistair  R.   W.  Williams<sup>2<\/sup>, Aidan Kubeyev<sup>3<\/sup>, Andrea Giorni<sup>1<\/sup>, Jordan Laurie<sup>1<\/sup>, Prabu Sivasubramaniam<sup>3<\/sup>, Matthew Foster<sup>3<\/sup>, <b>Matthew Griffiths<\/b><sup>3<\/sup>, Uzma Asghar<sup>4<\/sup><br><br\/><sup>1<\/sup>Concr Pty Ltd, Brisbane, Australia,<sup>2<\/sup>Division of Pathology, The University of Edinburgh, Edinburgh, United Kingdom,<sup>3<\/sup>Concr Ltd, Cambridge, United Kingdom,<sup>4<\/sup>Technical, Concr Ltd, Cambridge, United Kingdom","CSlideId":"","ControlKey":"44c7be3c-b4a6-4bb3-b5ab-4a9cd2938d67","ControlNumber":"2690","DisclosureBlock":"&nbsp;<b>L. Zillmann da Silva, <\/b> None.&nbsp;<br><b>A. R. W. Williams, <\/b> <br><b>Mithra Women’s Healthcare (Liege, Belgium)<\/b> Independent Contractor. <br><b>Bayer AG (Berlin, Germany)<\/b> Independent Contractor.<br><b>A. Kubeyev, <\/b> None..<br><b>A. Giorni, <\/b> None..<br><b>J. Laurie, <\/b> None..<br><b>P. Sivasubramaniam, <\/b> None..<br><b>M. Foster, <\/b> None..<br><b>M. Griffiths, <\/b> None..<br><b>U. Asghar, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8098","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"6","PosterboardNumber":"7","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5424","PresenterBiography":null,"PresenterDisplayName":"Matthew Griffiths, PhD","PresenterKey":"95ff1723-ff78-4c3b-ae33-72097f8967dd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5424. A deep learning approach (AI) which accurately identifies breast tumor cells, tumor infiltrating lymphocytes (TILS) and fibroblasts from H&#38;E slides","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A deep learning approach (AI) which accurately identifies breast tumor cells, tumor infiltrating lymphocytes (TILS) and fibroblasts from H&#38;E slides","Topics":null,"cSlideId":""},{"Abstract":"Background: Development and clinical course of cancer is multifactorial with influences from the general health status of the patient, germline and neoplastic mutations, co-morbidities, and environment including lifestyle. For effective and individualized treatment of each patient, such multifactorial data must be easy-to-access and easy-to-analyze.<br \/>Purpose Statement: Cancers are characterized on a molecular level by the presence of complex gene mutations and other specific molecular markers. Moreover, special importance is placed on so-called cancer-critical genes, mutations of which are involved in the development and progression of various cancers. However, not all detected sequence alterations in these genes are known as cancer-causing mutations; thus, a more detailed and sensitive analysis is prudent. In addition, there is a limited number of established and reliable cancer biomarkers of sera. To that end, a complete analysis of molecular basis of cancer needs to include additional biomarkers such as galectins and glycans, since patients&#8217; galectin and glycomic profiles have promising cancer differentiating and diagnostic potential.<br \/>Methods: We utilized a Relational Database Management System populated by clinical data from the Prisma Health Cancer Institute Biorepository of ~6,000 cancer patients with at least 66 different cancer diagnoses. Molecular data is available for gene mutations, serum galectin proteins, and glycomic profiles of cancer patients. Mutation status of 50 cancer-critical genes in 1,500 patients, 320 individual patient profiles of 5 serum galectin proteins, and serum and tissue glycomic profiles of 60 patients have been included and will be expanded. In addition, healthy control values for galectin and glycomic profiles were obtained and added for reference. We performed statistical and AI models of Data Analytics using R, Python, and TensorFlow platforms. A comprehensive set of patient data was used to develop a predictive model of patient outcome using the clinical observations as the desired outcome.<br \/>Results: The use of typical statistical analyses (linear and logistic regression) revealed insignificant correlation between the predictors and the cancer type of patient outcome. However, the use of the Decision Tree revealed some interesting relationships that can be used for explainability and reliability of the Machine Learning approaches. Finally, Artificial Neural Network approaches provided the best performance in classification of cancer types from the given information.<br \/>Conclusion: Our studies provide predictive models that could potentially be used to improve the diagnostic and prognostic power of data collected from patients at presentation. However, the dichotomy of black box AI approaches that perform better than explainable approaches, complicate deployment of these techniques in the domain of medicine and healthcare.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Cancer,Machine learning,Mutations,Databases,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Ali Firooz<sup>1<\/sup>, Avery T. Funkhouser<sup>2<\/sup>, Julie C. Martin<sup>3<\/sup>, W. Jeffery Edenfield<sup>3<\/sup>, Homayoun Valafar<sup>1<\/sup>, <b>Anna  V.  Blenda<\/b><sup>2<\/sup><br><br\/><sup>1<\/sup>Computer Science & Engineering, University of South Carolina, Columbia, SC,<sup>2<\/sup>Biomedical Sciences, University of South Carolina School of Medicine Greenville, Greenville, SC,<sup>3<\/sup>Prisma Health Cancer Institute, Greenville, SC","CSlideId":"","ControlKey":"39461294-f749-4137-a94a-4aa8e0a11e40","ControlNumber":"4365","DisclosureBlock":"&nbsp;<b>A. Firooz, <\/b> None..<br><b>A. Funkhouser, <\/b> None..<br><b>J. C. Martin, <\/b> None.&nbsp;<br><b>W. Edenfield, <\/b> <br><b>Chimerix<\/b> Other, Consultant.<br><b>H. Valafar, <\/b> None..<br><b>A. V. Blenda, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8099","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"7","PosterboardNumber":"8","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5425","PresenterBiography":null,"PresenterDisplayName":"Anna Blenda, MS;PhD","PresenterKey":"35e54b5c-2d9d-4ec8-8e57-53d951c0ce57","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5425. Analysis of cancer patients&#8217; molecular and clinical data using artificial intelligence and machine learning approaches","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Analysis of cancer patients&#8217; molecular and clinical data using artificial intelligence and machine learning approaches","Topics":null,"cSlideId":""},{"Abstract":"<i><sub> <\/sub><\/i>Discovery and validation of biomarkers derived from multi-dimensional clinico-genomic datasets have become critical in precision medicine and oncology drug development. The integration of multi-dimensional genomic and imaging datasets from patients in late-stage oncology clinical trials can be difficult, in part due to limited patient enrollment and sample collection, especially tumor tissue biopsies. The objective of this project was to conduct predictive biomarker discovery on integrated clinico-genomics data spanning tumor genomics, germline genetics, tumor imaging, and circulating blood-based biomarkers for a cohort of 800+ advanced ovarian cancer patients enrolled in the phase III trial of the PARP-1 inhibitor Veliparib (VELIA). Genomic (DNA &#38; RNA) and imaging datasets were generated from 800+ patient-matched tumor biopsies, liquid biopsies and whole blood to enable various biomarker analyses for this study, notably in BRCA-deficient and HRD+ subgroups. Pairwise analysis of individual features with clinical outcomes shows that increased tumor-mutation burden (TMB), RNA-based estimates of immune activity (ICR and MIRACLE scores), CA-125 elimination constant (KELIM score), and image-based estimates tumor-infiltrating lymphocytes (TILs) were each significantly associated with longer PFS and less progressive disease (PD). Similarly, homologous recombination deficiency (HRD) and BRCA alteration were associated with better clinical outcomes, while high CA-125 was associated with worse outcomes. To understand the concerted impact of these features on clinical outcome, we developed multivariate classifiers of PD and regressors (Cox Proportional Hazards) of PFS using XGBoost; using a train-test split of 75\/25, we trained the models with 500 rounds of 10-fold cross validation hyperparameter tuning, which resulted in fit models. The PD classifier achieved a validation accuracy of 0.71 and F1-score of 0.78, with high immune activation, high TMB, high KELIM, and HRD and BRCA alteration predicting better outcomes. The PFS survival model achieved a validation C-index of 0.61, with a rank importance of features similar to that of PD classification models; for both models, patients receiving Veliparib had clear benefit relative to that of control arms. Collectively, this study illustrates the value of integrating multi-dimensional datasets with predictive machine learning to identify clinically-relevant biomarkers.<br \/>CR, DM, PA, BR, JD, TB, PN, JS, XH, and JFW are employees of AbbVie. RLC an employee at The University of Texas MD Anderson Cancer Center and has no funding to disclose. The design, study conduct, and financial support for this research were provided by AbbVie. AbbVie participated in the interpretation of data, review, and approval of the publication.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Multiomics,Predictive biomarkers,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Cyril Ramathal<\/b><sup>1<\/sup>, David Masica<sup>1<\/sup>, Peter Ansell<sup>1<\/sup>, Bridget Riley-Gillis<sup>1<\/sup>, Jacob Degner<sup>1<\/sup>, Thanh Bui<sup>1<\/sup>, Priya Narayanan<sup>1<\/sup>, Josue Samayoa<sup>1<\/sup>, Xin Huang<sup>1<\/sup>, Robert  F.  Coleman<sup>2<\/sup>, Jeffrey  F.  Waring<sup>1<\/sup><br><br\/><sup>1<\/sup>AbbVie Inc., North Chicago, IL,<sup>2<\/sup>US Oncology Research, The Woodlands, TX","CSlideId":"","ControlKey":"fd292325-cde8-4efc-bcca-60a1ab333028","ControlNumber":"1654","DisclosureBlock":"<b>&nbsp;C. Ramathal, <\/b> <br><b>AbbVie Inc<\/b> Employment, Stock, Travel. <br><b>D. Masica, <\/b> <br><b>AbbVie Inc<\/b> Employment. <br><b>P. Ansell, <\/b> <br><b>Abbvie Inc<\/b> Employment, Stock. <br><b>B. Riley-Gillis, <\/b> <br><b>Abbvie Inc<\/b> Employment, Stock. <br><b>J. Degner, <\/b> <br><b>Abbvie Inc<\/b> Employment, Stock. <br><b>T. Bui, <\/b> <br><b>AbbVie<\/b> Employment. <br><b>P. Narayanan, <\/b> <br><b>AbbVie<\/b> Employment. <br><b>J. Samayoa, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>X. Huang, <\/b> <br><b>Abbvie<\/b> Employment, Stock. <br><b>R. F. Coleman, <\/b> <br><b>AstraZeneca<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Abbvie<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Clovis<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Roche-Genentech<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Merck<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Toray<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Mersana<\/b> Grant\/Contract. <br><b>Genmab<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Immunogen<\/b> Grant\/Contract, Other, Scientific Steering Committee. <br><b>Glaxo Smith Kline<\/b> Other, Scientific Steering Committee. <br><b>Deciphera<\/b> Other, Scientific Steering Committee. <br><b>Novocure<\/b> Other, Scientific Steering Committee. <br><b>Epsilogen<\/b> Other, Scientific Steering Committee. <br><b>Agenus<\/b> Other, Scientific Steering Committee. <br><b>Aravive<\/b> Other, Scientific Steering Committee. <br><b>Karyopharm<\/b> Other, Scientific Steering Committee. <br><b>Mirati<\/b> Other, Scientific Steering Committee. <br><b>J. F. Waring, <\/b> <br><b>Abbvie<\/b> Employment, Stock.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8100","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"8","PosterboardNumber":"9","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5426","PresenterBiography":null,"PresenterDisplayName":"Cyril Ramathal, BA;PhD","PresenterKey":"e015db8c-b9a9-4592-8f91-34e9e0192d98","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5426. Multi-omic characterization and predictive features of advanced ovarian cancer patients in a large phase III cohort","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Multi-omic characterization and predictive features of advanced ovarian cancer patients in a large phase III cohort","Topics":null,"cSlideId":""},{"Abstract":"When applied to different datasets, performance of the same deep learning tumor segmentation model can greatly vary. In a non-small cell lung cancer CT scan segmentation study that consists of two datasets, we found that the SwinUNETR model achieves state-of-the-art DICE score on a public dataset NSCLC but performs badly on a private dataset of curated data collected clinically. This performance variation reduces the applicability of such models. To mitigate this gap, through experimentation, we identified a set of techniques and applied them in the following order: (1) normalize a dataset to reduce differences between images. (2) stratify a dataset according to tumor sizes to form a more diverse training set. (3) isolate the lung area before training to help the model focus on the right area. (4) before training, initialize models with self-supervised pre-training weights (5) use a new loss function to give more weights on the cancerous area (6) after a model is trained, perform 3-axis test time flipping augmentation and ensemble the final predictions. In our experiments, our set of techniques improved the test DICE score for both datasets we tested on, where the best improvement was a 53% improvement from 0.32 to 0.49 DICE score.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Transformer,SwinUNETR,Nodule segmentation ,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Yi Wei<\/b><sup>1<\/sup>, Balaji Selvaraj<sup>2<\/sup>, Mayank Patwari<sup>1<\/sup>, Qin Li<sup>3<\/sup>, Meng Xu<sup>4<\/sup>, Konstantinos Sidiropoulos<sup>1<\/sup>, Zhenning Zhang<sup>4<\/sup>, Leon Fedden<sup>1<\/sup>, Anant Madabhushi<sup>5<\/sup>, Mohammadhadi Khorrami<sup>6<\/sup>, Vidya Sankar Viswanathan<sup>6<\/sup>, Amit Gupta<sup>7<\/sup><br><br\/><sup>1<\/sup>AstraZeneca, Cambridge, United Kingdom,<sup>2<\/sup>AstraZeneca, Chennai, India,<sup>3<\/sup>Translational Medicine Oncology, AstraZeneca, Waltham, MA,<sup>4<\/sup>AstraZeneca, Gaithersburg, MD,<sup>5<\/sup>Georgia Institute of Technology and Emory University and Atlanta Veterans Administration Medical Center, Atlanta, GA,<sup>6<\/sup>Emory University School of Medicine, Atlanta, GA,<sup>7<\/sup>University Hospitals Cleveland Medical Center, Cleveland, OH","CSlideId":"","ControlKey":"a1be8103-cc2a-4ae9-a6b6-7af3794fb8c4","ControlNumber":"2895","DisclosureBlock":"<b>&nbsp;Y. Wei, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>B. Selvaraj, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>M. Patwari, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>Q. Li, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>K. Sidiropoulos, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>Z. Zhang, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>L. Fedden, <\/b> <br><b>AstraZeneca<\/b> Employment.<br><b>A. Madabhushi, <\/b> None..<br><b>M. Khorrami, <\/b> None..<br><b>V. Viswanathan, <\/b> None..<br><b>A. Gupta, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8101","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"9","PosterboardNumber":"10","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5427","PresenterBiography":null,"PresenterDisplayName":"Yi Wei, Unknown","PresenterKey":"d53897e2-beca-4bfd-88d9-ed79393a688f","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5427. Improving non-small cell lung cancer segmentation on a challenging dataset","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Improving non-small cell lung cancer segmentation on a challenging dataset","Topics":null,"cSlideId":""},{"Abstract":"Background: Skeletal muscle gauge (SMG) was recently introduced as an imaging indicator of sarcopenia for the prediction of clinical outcomes, including chemotherapy toxicity and prognosis, in patients with cancer. Computed tomography (CT) is essential for measuring SMG; thus, the use of SMG is limited to patients who undergo CT.<br \/>Objective: We aimed to develop a machine learning algorithm using clinical and inflammatory markers to predict SMG in patients with colorectal cancer (CRC)<br \/>Methods: The least absolute shrinkage and selection operator (LASSO) regression model was applied for variable selection and predictive signature building in the training set. The predictive accuracy of the LASSO model, defined as LP-SMG was compared using the area under the receiver operating characteristic (AUROC) and decision curve analysis (DCA) in the test set.<br \/>Results: A total of 1,094 patients with CRC were enrolled and randomly categorized into training (n=656) and test (n=438) sets. Low SMG was identified in 142 (21.6%) and 90 (20.5%) patients in the training and test sets, respectively. According to multivariable analysis of the test sets, LP-SMG was identified as an independent predictor of low SMG (OR: 1329.431, CI: 271.684-7667.996, <i>p<\/i>&#60;.001). Its predictive performance was similar in the training and test sets (AUROC: 0.846 vs. 0.869, <i>p<\/i>=.427). In the test set, LP-SMG showed better outcomes in predicting SMG than single clinical variables, such as sex, height, weight, and hemoglobin, as measured by AUROC and DCA.<br \/>Conclusions: LP-SMG, incorporating clinical variables and serum inflammatory indicators, showed superior performance compared to single variables in predicting low SMG. This machine learning model can be used as a screening tool to detect sarcopenic status without using CT during the treatment period. Applying a machine learning model might be beneficial in reducing the effort, cost, and radiation exposure from conventional CT-based diagnosis.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Colorectal cancer,Machine learning,Predictive biomarkers,Cachexia,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Jeonghyun Kang<\/b><sup><\/sup><br><br\/>Surgery, Yonsei University College of Medicine, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"12eefe49-f7d6-4404-a207-81a65b7c53f1","ControlNumber":"1596","DisclosureBlock":"&nbsp;<b>J. Kang, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8102","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"10","PosterboardNumber":"11","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5428","PresenterBiography":null,"PresenterDisplayName":"Jeonghyun Kang, MD;PhD","PresenterKey":"ec0fc7b9-2836-4ce6-8165-2d22df0d8ed4","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5428. Skeletal muscle gauge prediction by a machine learning model in patients with colorectal cancer","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Skeletal muscle gauge prediction by a machine learning model in patients with colorectal cancer","Topics":null,"cSlideId":""},{"Abstract":"Background: Predicting tissue of origin (ToO) using clinical and molecular data improves diagnostic accuracy up to 95% in patients with Cancer of Unknown Primary (CUP). It is hypothesized that better treatment stratification of CUP patients using omics and machine learning (ML) classifiers may improve prognosis.<br \/>Methods: We used publicly available whole exome somatic mutation data from 4733 primary solid tissue samples, across 11 tumor types from the TCGA database, and employed a ML classifier to predict their ToO. We used 5 sets of modeling features:<br \/>1) Non-silent somatic mutation burden of 230 cancer-related genes 2) Frequency of SNP substitution type 3) Trinucleotide mutation frequency 4) Copy number variation of the 230 cancer-related genes 5) Presence of hotspot mutations.<br \/>We trained a Support Vector Machine on a training subset (80% of samples) and tuned the hyperparameters maximizing a 5-fold cross-validation F1-score. We then tested the model performance on a validation subset (20% of samples) and on a limited (n=6) dataset of metastatic samples present in the TCGA database.<br \/>Results: On the primary tumor validation set, we achieved an average AUC of 0.98(std: 0.02) and top 1, top 2 and top 3 accuracies of 80%(std: 0.11), 90%(std: 0.08) and 95%(std: 0.04) respectively, across 11 tumor types. The classification accuracy plateaus after ~300 samples, suggesting further data collection may benefit low performing tumor types. The 2 worst performers: esophageal and stomach cancers were mostly misclassified with colorectal cancers, reflecting their relative similarity. On metastatic samples (n=6) the model achieved a 67% accuracy, this is work in progress.<br \/>Conclusion: Our study confirms the potential for a DNA-based machine learning approach to improve prognosis in CUP patients by aiding diagnosis of ToO. To this end, we plan to take this study further by applying this approach to large, independent datasets derived from metastatic samples and liquid biopsies from CUP patient cohorts.<table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{A96601C8-DA1F-495D-AD0C-18A9B9796304}\"><caption><\/caption><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><b>Top_1_acc<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Top_2_acc<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Top_3_acc<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Precision<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Recall<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>F1_score<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Training_size<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Breast<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><td rowspan=\"1\" colspan=\"1\">0.97<\/td><td rowspan=\"1\" colspan=\"1\">0.99<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><td rowspan=\"1\" colspan=\"1\">0.84<\/td><td rowspan=\"1\" colspan=\"1\">0.86<\/td><td rowspan=\"1\" colspan=\"1\">756<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Colorectal<\/td><td rowspan=\"1\" colspan=\"1\">0.85<\/td><td rowspan=\"1\" colspan=\"1\">0.97<\/td><td rowspan=\"1\" colspan=\"1\">0.98<\/td><td rowspan=\"1\" colspan=\"1\">0.83<\/td><td rowspan=\"1\" colspan=\"1\">0.83<\/td><td rowspan=\"1\" colspan=\"1\">0.83<\/td><td rowspan=\"1\" colspan=\"1\">460<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Oesophagus<\/td><td rowspan=\"1\" colspan=\"1\">0.5<\/td><td rowspan=\"1\" colspan=\"1\">0.75<\/td><td rowspan=\"1\" colspan=\"1\">0.89<\/td><td rowspan=\"1\" colspan=\"1\">0.51<\/td><td rowspan=\"1\" colspan=\"1\">0.5<\/td><td rowspan=\"1\" colspan=\"1\">0.51<\/td><td rowspan=\"1\" colspan=\"1\">144<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Liver<\/td><td rowspan=\"1\" colspan=\"1\">0.83<\/td><td rowspan=\"1\" colspan=\"1\">0.92<\/td><td rowspan=\"1\" colspan=\"1\">0.96<\/td><td rowspan=\"1\" colspan=\"1\">0.82<\/td><td rowspan=\"1\" colspan=\"1\">0.89<\/td><td rowspan=\"1\" colspan=\"1\">0.85<\/td><td rowspan=\"1\" colspan=\"1\">288<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Lung<\/td><td rowspan=\"1\" colspan=\"1\">0.86<\/td><td rowspan=\"1\" colspan=\"1\">0.91<\/td><td rowspan=\"1\" colspan=\"1\">0.94<\/td><td rowspan=\"1\" colspan=\"1\">0.98<\/td><td rowspan=\"1\" colspan=\"1\">0.81<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><td rowspan=\"1\" colspan=\"1\">396<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Ovary<\/td><td rowspan=\"1\" colspan=\"1\">0.87<\/td><td rowspan=\"1\" colspan=\"1\">0.94<\/td><td rowspan=\"1\" colspan=\"1\">0.97<\/td><td rowspan=\"1\" colspan=\"1\">0.77<\/td><td rowspan=\"1\" colspan=\"1\">0.9<\/td><td rowspan=\"1\" colspan=\"1\">0.83<\/td><td rowspan=\"1\" colspan=\"1\">312<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Pancreas<\/td><td rowspan=\"1\" colspan=\"1\">0.73<\/td><td rowspan=\"1\" colspan=\"1\">0.79<\/td><td rowspan=\"1\" colspan=\"1\">0.85<\/td><td rowspan=\"1\" colspan=\"1\">0.62<\/td><td rowspan=\"1\" colspan=\"1\">0.7<\/td><td rowspan=\"1\" colspan=\"1\">0.66<\/td><td rowspan=\"1\" colspan=\"1\">132<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Prostate<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><td rowspan=\"1\" colspan=\"1\">0.94<\/td><td rowspan=\"1\" colspan=\"1\">0.98<\/td><td rowspan=\"1\" colspan=\"1\">0.75<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><td rowspan=\"1\" colspan=\"1\">0.81<\/td><td rowspan=\"1\" colspan=\"1\">380<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Sarcoma<\/td><td rowspan=\"1\" colspan=\"1\">0.78<\/td><td rowspan=\"1\" colspan=\"1\">0.84<\/td><td rowspan=\"1\" colspan=\"1\">0.96<\/td><td rowspan=\"1\" colspan=\"1\">0.8<\/td><td rowspan=\"1\" colspan=\"1\">0.82<\/td><td rowspan=\"1\" colspan=\"1\">0.81<\/td><td rowspan=\"1\" colspan=\"1\">180<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Stomach<\/td><td rowspan=\"1\" colspan=\"1\">0.73<\/td><td rowspan=\"1\" colspan=\"1\">0.91<\/td><td rowspan=\"1\" colspan=\"1\">0.95<\/td><td rowspan=\"1\" colspan=\"1\">0.68<\/td><td rowspan=\"1\" colspan=\"1\">0.58<\/td><td rowspan=\"1\" colspan=\"1\">0.62<\/td><td rowspan=\"1\" colspan=\"1\">340<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Endometrial<\/td><td rowspan=\"1\" colspan=\"1\">0.9<\/td><td rowspan=\"1\" colspan=\"1\">0.97<\/td><td rowspan=\"1\" colspan=\"1\">0.99<\/td><td rowspan=\"1\" colspan=\"1\">0.86<\/td><td rowspan=\"1\" colspan=\"1\">0.87<\/td><td rowspan=\"1\" colspan=\"1\">0.87<\/td><td rowspan=\"1\" colspan=\"1\">400<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Mean<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>80.09%<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>90.09%<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>95.09%<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.77<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.78<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.78<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>344<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><b>Top_1_acc_n<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Top_2_acc_n<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Top_3_acc_n<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>n samples<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Metastatic breast<\/td><td rowspan=\"1\" colspan=\"1\">2<\/td><td rowspan=\"1\" colspan=\"1\">2<\/td><td rowspan=\"1\" colspan=\"1\">2<\/td><td rowspan=\"1\" colspan=\"1\">2<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Metastatic prostate<\/td><td rowspan=\"1\" colspan=\"1\">0<\/td><td rowspan=\"1\" colspan=\"1\">0<\/td><td rowspan=\"1\" colspan=\"1\">0<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Metastatic pancreas<\/td><td rowspan=\"1\" colspan=\"1\">0<\/td><td rowspan=\"1\" colspan=\"1\">0<\/td><td rowspan=\"1\" colspan=\"1\">0<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Metastatic sarcoma<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Metastatic oesophagus<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Mean accuracy<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>67%<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>67%<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>67%<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Cancer diagnostics,Somatic mutations,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Andrea Giorni<sup>1<\/sup>, Prabu Sivasubramiam<sup>2<\/sup>, Aidan Kubeyev<sup>2<\/sup>, Jordan Laurie<sup>1<\/sup>, Luiz Silva<sup>1<\/sup>, Matthew Foster<sup>1<\/sup>, Uzma Asghar<sup>2<\/sup>, <b>Matthew Griffiths<\/b><sup>2<\/sup><br><br\/><sup>1<\/sup>Concr Pty Ltd, Brisbane, Australia,<sup>2<\/sup>Concr Ltd, Cambridge, United Kingdom","CSlideId":"","ControlKey":"2755a263-1213-4be9-ad4d-8921c6c3d764","ControlNumber":"4065","DisclosureBlock":"&nbsp;<b>A. Giorni, <\/b> None..<br><b>P. Sivasubramiam, <\/b> None..<br><b>A. Kubeyev, <\/b> None..<br><b>J. Laurie, <\/b> None..<br><b>L. Silva, <\/b> None..<br><b>M. Foster, <\/b> None..<br><b>U. Asghar, <\/b> None..<br><b>M. Griffiths, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8103","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"11","PosterboardNumber":"12","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5429","PresenterBiography":null,"PresenterDisplayName":"Matthew Griffiths, PhD","PresenterKey":"95ff1723-ff78-4c3b-ae33-72097f8967dd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5429. Using machine learning to predict tissue of origin from somatic mutation features","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Using machine learning to predict tissue of origin from somatic mutation features","Topics":null,"cSlideId":""},{"Abstract":"Colorectal cancer (CRC) is the third most common cancer worldwide and represents the third leading cause of cancer deaths. Robust postoperative prediction of CRC patient prognosis may prove useful to better stratify patients, guide therapeutic choices and improve clinical trial designs. Deep learning-based analysis of whole slide images (WSI) has recently proved successful at various prediction tasks, including for example survival prediction for malignant pleural mesothelioma.<br \/>We developed a deep learning model that predicts overall survival (OS) of CRC patients, using WSI stained with haematoxylin\/eosin as input, and also evaluated the difference in prognostic power obtained when combining our model prediction with other clinical factors, namely tumor grade, sex and age. The model was trained on PETACC8 cohort, constituted of 1939 WSI from patients with stage III colon cancer. The PRODIGE13 cohort, constituted of 1155 WSI from patients with stage II and III colon and rectal cancers, was used for validation; only stage III colon cancers (N=428) were selected. Patients from both cohorts received standard chemotherapy treatment, with half of the PETACC8 population also receiving CETUXIMAB antibody treatment. Both cohorts were provided by the FFCD.<br \/>Our model first extracts information on small tiles of size 112&#181;m from the WSI, using a deep learning network trained in a self-supervised fashion, then aggregates the information of these tiles using a Multiple Instance Learning model (MIL) at the slide level to establish the final prediction. Our model was able to predict OS from WSI, reaching a c-index of 0.63 [0.61 - 0.66] in cross-validation over the PETACC8 cohort and a c-index of 0.59 [0.53 - 0.65] when transferring the PETACC8-trained model onto the PRODIGE13 cohort. The model was also able to significantly stratify patients into high and low risk groups [HR: 2.67; p&#60;0.0001]. We observed a significant c-index gain when combining our prediction and the pT classification in a linear Cox model as compared to pT alone, with c-index increasing from 0.61 to 0.66 (p=0.03).<br \/>Overall, we demonstrated that our model is able to robustly predict OS from WSI in stage III colon cancers and provides increased prognostic power, on top of more traditional clinical markers such as tumor grading. Further investigation of the WSI regions targeted by our model could provide valuable insights into postoperative histopathological features of prognostic significance.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Survival,Colorectal,Histopathology,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Jean-Eudes Le Douget<sup>1<\/sup>, Julien Taïeb<sup>2<\/sup>, <b>Paul Jacob<\/b><sup>1<\/sup>, Frédéric Bibeau<sup>3<\/sup>, Karine Le Malicot<sup>4<\/sup>, Jean-François Emile<sup>5<\/sup>, Aurélien de Reyniès<sup>5<\/sup>, Mehdi Morel<sup>1<\/sup>, Simon Jégou<sup>1<\/sup>, Côme Lepage<sup>6<\/sup>, Pierre Laurent-Puig<sup>7<\/sup><br><br\/><sup>1<\/sup>Owkin, Paris, France,<sup>2<\/sup>Georges Pompidou European Hospital, Paris, France,<sup>3<\/sup>Centre Hospitalier Universitaire de Besançon, Besançon, France,<sup>4<\/sup>FFCD, Dijon, France,<sup>5<\/sup>AP-HP, Paris, France,<sup>6<\/sup>INSERM, Dijon, France,<sup>7<\/sup>INSERM, Paris, France","CSlideId":"","ControlKey":"954d3808-02d7-49a2-8bcb-8c0f81a17e47","ControlNumber":"3136","DisclosureBlock":"<b>&nbsp;J. Le Douget, <\/b> <br><b>Owkin<\/b> Employment. <br><b>Bioserenity<\/b> Employment. <br><b>J. Taïeb, <\/b> <br><b>AMGEN<\/b> Independent Contractor. <br><b>Astellas<\/b> Independent Contractor. <br><b>Astra-Zeneca<\/b> Independent Contractor. <br><b>BMS<\/b> Independent Contractor. <br><b>Merck<\/b> Independent Contractor. <br><b>MSD<\/b> Independent Contractor. <br><b>Novartis<\/b> Independent Contractor. <br><b>Pierre Fabre<\/b> Independent Contractor. <br><b>Servier<\/b> Independent Contractor. <br><b>P. Jacob, <\/b> <br><b>Owkin<\/b> Employment.<br><b>F. Bibeau, <\/b> None..<br><b>K. Le Malicot, <\/b> None.&nbsp;<br><b>J. Emile, <\/b> <br><b>HalioDX<\/b> Independent Contractor.<br><b>A. de Reyniès, <\/b> None.&nbsp;<br><b>M. Morel, <\/b> <br><b>Owkin<\/b> Employment. <br><b>S. Jégou, <\/b> <br><b>Owkin<\/b> Employment. <br><b>C. Lepage, <\/b> <br><b>Amgen<\/b> Independent Contractor. <br><b>Pierre Fabre<\/b> Independent Contractor. <br><b>Novartis<\/b> Independent Contractor. <br><b>AAA<\/b> Independent Contractor. <br><b>P. Laurent-Puig, <\/b> <br><b>Merck Serono<\/b> Independent Contractor. <br><b>Amgen<\/b> Independent Contractor. <br><b>Boehringer Ingelheim<\/b> Independent Contractor. <br><b>Biocartis<\/b> Independent Contractor. <br><b>Roche<\/b> Independent Contractor. <br><b>Bristol-Myers Squibb<\/b> Independent Contractor. <br><b>MSD<\/b> Independent Contractor.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8104","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"12","PosterboardNumber":"13","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5430","PresenterBiography":null,"PresenterDisplayName":"Paul Jacob, MSc","PresenterKey":"71300478-bf84-4589-a358-721166d84d56","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5430. Improved colorectal cancer survival prediction with deep learning-based WSI analysis on PETACC8 and PRODIGE13 cohorts","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Improved colorectal cancer survival prediction with deep learning-based WSI analysis on PETACC8 and PRODIGE13 cohorts","Topics":null,"cSlideId":""},{"Abstract":"Tissue-based sampling and diagnosis is the extraction of information from specifically limited spaces and its diagnostic significance of a certain object. Pathologists deal with issues related to tumor heterogeneity since analyzing a single sample does not necessarily capture a representative depiction of cancer, and a tissue biopsy usually only presents a small fraction of the tumor. Many multiplex tissue imaging platforms (MTIs) make the assumption that tissue microarrays (TMAs) containing small core samples of 2-dimensional (2D) tissue sections are a good approximation of bulk tumors although tumors are not 2D. However, emerging whole slide imaging (WSI) or 3D tumor atlases that employ MTIs like cyclic immunofluorescence (CyCIF) strongly challenge this assumption.<br \/>In spite of the additional insight gathered by measuring the tumor microenvironment in WSI or 3D, it can be prohibitively expensive and time-consuming to process tens or hundreds of tissue sections with CyCIF. Even when resources are not limited, the criteria for region-of-interest (ROI) selection in tissues for downstream analysis remain largely qualitative and subjective as stratified sampling requires the knowledge of objects and evaluates their features. Although TMAs fail to adequately approximate whole tissue features, a theoretical subsampling of tissue exists that can best represent the tumor in the whole slide image. To address these challenges, we propose deep learning approaches to learn multi-modal image translation tasks from two aspects: 1) generative modeling approach to reconstruct 3D CyCIF representation and 2) co-embedding CyCIF image and Hematoxylin and Eosin (H&#38;E) section to learn multi-mappings by a cross-domain translation for minimum representative ROI selection. We demonstrate that generative modeling enables a 3D virtual CyCIF reconstruction of a colorectal cancer specimen given a small subset of the imaging data at training time. By co-embedding histology and MTI features, we propose a simple convex optimization for objective ROI selection. We demonstrate the potential application of ROI selection and the efficiency of its performance with respect to cellular heterogeneity. The key takeaway is that this pipeline allows for intelligent representation from H&#38;E images, which enables a plethora of subsequent analyses on this representation space with other multiplexed imaging platforms such as Multiplexed ion beam imaging (MIBI), Imaging Mass Cytometry (IMC) or NanoString GeoMX as only a few ROIs could be selected and analyzed using these platforms.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,3D multiplexed tissue imaging reconstruction,Region of Interest (ROIs) selection,optimization,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Erik Burlingame<sup><\/sup>, Luke Ternes<sup><\/sup>, Eun Na Kim<sup><\/sup>, Joe  W.  Gray<sup><\/sup>, <b>Young Hwan Chang<\/b><sup><\/sup><br><br\/>Biomedical Engineering, Oregon Health & Science University, Portland, OR","CSlideId":"","ControlKey":"ec11e041-c9f8-41e2-9816-9b980b260d97","ControlNumber":"919","DisclosureBlock":"&nbsp;<b>E. Burlingame, <\/b> None..<br><b>L. Ternes, <\/b> None..<br><b>E. Kim, <\/b> None.&nbsp;<br><b>J. W. Gray, <\/b> <br><b>Abbott Diagnostics<\/b> Patent, Other Intellectual Property. <br><b>Convergent Genomics<\/b> Other Business Ownership. <br><b>Health Technology Innovations<\/b> Other Business Ownership. <br><b>Zorro Bio<\/b> Other Business Ownership. <br><b>PDX Pharmaceuticals<\/b> Other Business Ownership. <br><b>New Leaf Ventures<\/b> Independent Contractor, Grant\/Contract. <br><b>Thermo Fisher Scientific<\/b> Grant\/Contract. <br><b>Zeiss<\/b> Grant\/Contract. <br><b>Miltenyi Biotech<\/b> Grant\/Contract. <br><b>Quantitative Imaging<\/b> Grant\/Contract. <br><b>Health Technology Innovations<\/b> Grant\/Contract. <br><b>Micron Technologies<\/b> Grant\/Contract.<br><b>Y. Chang, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8105","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"13","PosterboardNumber":"14","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5431","PresenterBiography":null,"PresenterDisplayName":"Young Hwan Chang","PresenterKey":"f3ed10c0-812b-408a-b5ac-b14ae0155412","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5431. 3D multiplexed tissue imaging reconstruction and optimized region-of-interest (ROI) selection through deep learning model of channels embedding","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"3D multiplexed tissue imaging reconstruction and optimized region-of-interest (ROI) selection through deep learning model of channels embedding","Topics":null,"cSlideId":""},{"Abstract":"Molecular profiling is central in cancer precision medicine but remains costly and is only based on tumor average profiles. Morphologic patterns observable in histopathology sections from tumors are determined by the underlying molecular phenotype and therefore have the potential to be exploited for the prediction of molecular phenotypes. Transcriptome-wide expression morphology (EMO) analysis with deep convolutional neural networks (CNN) enables the prediction of mRNA expression and proliferation markers from routine histopathology whole slide images in breast cancer. The NanoString GeoMx<sup>&#174;<\/sup> Digital Spatial Profiler (DSP) platform has capabilities of associating crucial spatial information with intratumor variabilities of gene expression, serving as an ideal tool to characterize and validate the prediction of intratumor heterogeneity. The GeoMx platform also provides functionalities of overlaying and aligning hematoxylin and eosin (H&#38;E) whole slide scans on serial tissue sections with morphology marker staining to facilitate region of interest (ROI) selection to match relevant image tiles from the model input, which is a key step to ensure accuracy for the evaluation of the model predictions. The GeoMx RNA Immune Pathways Panel contains 84 gene targets including key genes involved in immune pathways and tumorigenesis and was used to validate the prediction of mRNA expression output from deep CNN models.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Genomics,Histopathology,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Kathy Ton<sup>1<\/sup>, Yinxi Wang<sup>2<\/sup>, <b>Liuliu Pan<\/b><sup>1<\/sup>, Kimmo Kartasalo<sup>2<\/sup>, Balazs Acs<sup>3<\/sup>, Philippe Weitz<sup>2<\/sup>, Liang Zhang<sup>1<\/sup>, Yan Liang<sup>1<\/sup>, Johan Hartman<sup>4<\/sup>, Masi Volkonen<sup>5<\/sup>, Christer Larsson<sup>6<\/sup>, Pekka Ruusuvuori<sup>7<\/sup>, Joseph Beechem<sup>1<\/sup>, Mattias Rantalainen<sup>2<\/sup><br><br\/><sup>1<\/sup>NanoString Technologies, Inc., Seattle, WA,<sup>2<\/sup>Karolinska Institute, Stockholm, Sweden,<sup>3<\/sup>Karolinska Institute, Seattle, WA,<sup>4<\/sup>Karolinska Instutitute, stockholm, Sweden,<sup>5<\/sup>Turku University Hospital, Turku, Finland,<sup>6<\/sup>Lund University, Lund, Switzerland,<sup>7<\/sup>University of Turku, Turku, Finland","CSlideId":"","ControlKey":"2435694b-3c4f-4083-a952-b8a4b6e4f7b9","ControlNumber":"5672","DisclosureBlock":"<b>&nbsp;K. Ton, <\/b> <br><b>NanoString Technologies<\/b> Employment, Stock, Stock Option.<br><b>Y. Wang, <\/b> None..<br><b>K. Kartasalo, <\/b> None..<br><b>B. Acs, <\/b> None..<br><b>P. Weitz, <\/b> None.&nbsp;<br><b>L. Zhang, <\/b> <br><b>NanoString Technologies<\/b> Employment, Stock, Stock Option. <br><b>Y. Liang, <\/b> <br><b>NanoString Technologies<\/b> Employment, Stock, Stock Option.<br><b>J. Hartman, <\/b> None..<br><b>M. Volkonen, <\/b> None..<br><b>C. Larsson, <\/b> None..<br><b>P. Ruusuvuori, <\/b> None.&nbsp;<br><b>J. Beechem, <\/b> <br><b>NanoString Technologies<\/b> Employment, Stock, Stock Option.<br><b>M. Rantalainen, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8106","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"14","PosterboardNumber":"15","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5432","PresenterBiography":null,"PresenterDisplayName":"Liuliu Pan, Unknown","PresenterKey":"c7779060-dc91-43f7-910c-771422883cf8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5432. Validation of spatial gene expression patterns predicted by deep convolutional neural networks from breast cancer histopathology images","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Validation of spatial gene expression patterns predicted by deep convolutional neural networks from breast cancer histopathology images","Topics":null,"cSlideId":""},{"Abstract":"Lung squamous cell carcinoma (LSCC) is preceded by the development of bronchial premalignant lesions (PMLs). PMLs progress through a series of histologic grades characterized by molecular and morphologic alterations. To enhance our understanding of PML progression to lung cancer, we are developing deep learning methods to quantitate PML histologic features and localize PML severity along the histologic disease spectrum.<br \/>We leveraged whole slide images (WSIs) of lung tumors (lung adenocarcinoma, LUAD and LSCC) and non-involved adjacent (referred to as &#8216;normal&#8217;) tissue from the Clinical Proteomic Tumor Analysis Consortium (CPTAC), the National Lung Screening Trial (NLST) and the Cancer Genome Atlas (TCGA). The NLST WSIs were used for training a self-supervised contrastive learning (simCLR) model. A graph isomorphism network (GIN) trained on CPTAC WSIs was developed using the features from simCLR and perform WSI-level predictions on tissue subtype (LUAD, LSCC, normal). Model performance was assessed using area under the receiver operating curves (AUC). The model was used to learn WSI-level features of endobronchial biopsies of PMLs from two datasets (PCGA, n=365 samples spanning all histologic grades, and CIS, n=112, only high-grade samples). The features from the final layer of the GIN were used to compute principal components (PCs) and visualize the relationships between samples using t-SNE and UMAP. To interpret how the GIN processes WSI data, we performed gradient-based class activation mapping (Grad-CAMs) on the graphs.<br \/>High model performance was observed on the CPTAC test dataset (Accuracy = 87%, AUC &#62;= 0.89) but dropped slightly on the TCGA dataset (Accuracy = 72%, AUC &#62;= 0.75). The GIN-CAMs identified WSI regions that were highly associated with the output label based on expert pathologist annotation on TCGA cases. Clustering revealed distinct groupings of normal, LUAD and LSCC subtypes (PC1 &#38; PC2, p&#60;0.01). Most WSIs from the PCGA data clustered with normal tissues (PC1 &#38; PC2: p&#60;0.01 for PCGA v LUAD, PCGA v LSCC). However, a portion of the CIS samples were closely grouped with LSCC tumor cases (74% of CIS WSIs were classified as LSCC tumors. PC1 &#38; PC2: p&#60;0.01 for CIS v LUAD; PC1: p&#60;0.01 for CIS v LSCC). Additionally, the feature distribution of CIS samples that progressed towards LUSC tumors were significantly different than those that regressed (PC1 &#38; PC3: p &#60; 0.05 for Progressive v Regressive).<br \/>The GIN recognizes and generates robust features that are distinctly and consistently observed in the different histologic groups across multiple cohorts. These features are also able to stratify progressive and regressive high-grade lesions. The stratification of PMLs is an important step in designing novel interception strategies to prevent the development of lung cancer, and our results suggest that pathology data may be efficacious to include in future biomarkers.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Lung cancer,Premalignancy,Deep learning,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Rushin Gindra<sup>1<\/sup>, Yi Zheng<sup>2<\/sup>, Regan Conrad<sup>2<\/sup>, Emily Green<sup>2<\/sup>, Sarah Mazzilli<sup>2<\/sup>, Ehab Billatos<sup>2<\/sup>, Mary Reid<sup>3<\/sup>, Eric Burks<sup>4<\/sup>, Vijaya Kolachalama<sup>2<\/sup>, <b>Jennifer E. Beane<\/b><sup>2<\/sup><br><br\/><sup>1<\/sup>Helmholtz Munich and TranslaTUMedicine, Munich, Germany,<sup>2<\/sup>Boston Univ. School of Medicine, Boston, MA,<sup>3<\/sup>Roswell Park Comprehensive Cancer Institute, Buffalo, NY,<sup>4<\/sup>Boston Medical Center, Boston, MA","CSlideId":"","ControlKey":"1ed8a101-35d3-4c39-b315-c3839ec14bb8","ControlNumber":"7170","DisclosureBlock":"&nbsp;<b>R. Gindra, <\/b> None.&nbsp;<br><b>Y. Zheng, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract. <br><b>R. Conrad, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract. <br><b>E. Green, <\/b> <br><b>Janssen Pharamceuticals<\/b> Grant\/Contract. <br><b>S. Mazzilli, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract. <br><b>E. Billatos, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract. <br><b>M. Reid, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract.<br><b>E. Burks, <\/b> None.&nbsp;<br><b>V. Kolachalama, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract. <br><b>J. E. Beane, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8107","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"15","PosterboardNumber":"16","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5433","PresenterBiography":null,"PresenterDisplayName":"Jennifer Beane, BA;BE;PhD","PresenterKey":"2ddc78e6-1d2b-4512-aa4b-484c3a591610","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5433. Representation learning for histological profiling of lung squamous premalignant lesions and tumors","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Representation learning for histological profiling of lung squamous premalignant lesions and tumors","Topics":null,"cSlideId":""},{"Abstract":"Alterations in DNA methylation are one of the earliest, most common signatures of cancer development, making them ideal biomarkers for early detection. Methylation profiling of plasma cell-free DNA (cfDNA) has significant potential to expand the use of liquid biopsies to cancer screening. The EpiCheck platform combines methylation-sensitive restriction endonuclease (MSRE) digestion with whole genome sequencing to comprehensively map genome-wide DNA methylation changes with high fidelity. In this proof-of-concept study, MSRE-NGS was used to interrogate a liquid biopsy atlas focused on early-stage lung cancers to i) identify informative NGS methylation biomarkers in plasma, and ii) develop a machine learning method to discriminate between cancer and high-risk, non-cancer controls. The EpiCheck lung cancer atlas was constructed using biospecimens from academic (UBC, Vanderbilt, Cleveland Clinic) and commercial biobanks, and from a prospective multi-center study (NCT04968548). Plasma samples were collected from 93 high-risk primary lung cancer patients (62% stage I) and 90 high-risk individuals without cancer. Extracted DNA was digested with methylation-sensitive endonucleases and sequenced at an average depth of 600x. Methylation levels of ~6 million genomic loci were rank ordered using Student's t-test. Gene set enrichment analysis (GSEA) was performed on the top ranking 1000 differentially methylated loci. A logistic regression classifier with Lasso regularization was trained on 100,000 loci, and performance was examined by mean AUC using 5-fold cross-validation. A total of 23,130 loci exhibited significant differential methylation patterns between cancers and controls (p&#60;0.01, FDR corrected). Of these, 20,159 and 2,971 lung cancer loci were hypermethylated and hypomethylated, respectively. Biological characterization using GSEA identified enrichments in transcriptional regulation and developmental control. In particular, loci were enriched for Polycomb Repressive Complex regulated genes, suggesting a possible connection to abnormal epigenetic regulation via histone modification in lung cancer. Construction of a machine learning logistic regression model based on the five training folds utilized 224 loci on average, and achieved a mean cross-validation AUC of 0.93 when distinguishing plasma cancer cases vs controls. Our findings demonstrate that the MSRE-NGS EpiCheck platform identified putative biomarkers within the plasma methylome for detecting early-stage lung cancer. A machine learning model trained on methylation targets performed with high accuracy in discriminating lung cancer patients from high-risk healthy individuals. Additional studies are required for defining the strength of the approach and for validating its use in non-invasive lung cancer screening.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Lung cancer,Biomarkers,Screening,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Dvir Netanely<\/b><sup>1<\/sup>, Stephen Lam<sup>2<\/sup>, Anna McGuire<sup>3<\/sup>, Stephen Deppen<sup>4<\/sup>, Eric Grogan<sup>4<\/sup>, Fabien Maldonado<sup>4<\/sup>, Michael Gieske<sup>5<\/sup>, Joseph Seaman<sup>6<\/sup>, Kimberly Rieger-Christ<sup>7<\/sup>, Satish Kalanjeri<sup>8<\/sup>, Luis Herrera<sup>9<\/sup>, Nichole Tanner<sup>10<\/sup>, Garrett  B.  Sherwood<sup>11<\/sup>, Orna Savin<sup>1<\/sup>, Shacade Danan<sup>1<\/sup>, Sarah Zaouch<sup>1<\/sup>, Nimrod Axelrad<sup>1<\/sup>, Revital Knirsh<sup>1<\/sup>, Ofir Shliefer<sup>1<\/sup>, Keren Manor<sup>1<\/sup>, Radha Duttagupta<sup>12<\/sup>, Aharona Shuali<sup>1<\/sup>, Peter  J.  Mazzone<sup>13<\/sup>, Gerard  A.  Silvestri<sup>10<\/sup>, Catherine  A.  Schnabel<sup>12<\/sup>, Danny Frumkin<sup>1<\/sup>, Adam Wasserstrom<sup>1<\/sup><br><br\/><sup>1<\/sup>Nucleix, Rehovot, Israel,<sup>2<\/sup>Respiratory Medicine, University of British Columbia, Vancouver, BC, Canada,<sup>3<\/sup>Surgery, University of British Columbia, Vancouver, BC, Canada,<sup>4<\/sup>Thoracic Surgery, Vanderbilt University, Nashville, TN,<sup>5<\/sup>Family Medicine, St. Elizabeth Healthcare, Mitchell, KY,<sup>6<\/sup>Sarasota Memorial Hospital, Sarasota, FL,<sup>7<\/sup>Lahey Hospital & Medical Center, Burlington, MA,<sup>8<\/sup>Pulmonary and Critical Care Medicine, Harry S. Truman Memorial Veterans' Hospital, Columbia, MO,<sup>9<\/sup>Orlando Health, Orlando, FL,<sup>10<\/sup>Medical University of South Carolina, Charleston, SC,<sup>11<\/sup>Novant Health, Winston-Salem, NC,<sup>12<\/sup>Nucleix, San Diego, CA,<sup>13<\/sup>Pulmonary Medicine, Cleveland Clinic, Cleveland, OH","CSlideId":"","ControlKey":"aa1cec5a-219b-44e4-89c0-c56c1f3f02ef","ControlNumber":"4920","DisclosureBlock":"<b>&nbsp;D. Netanely, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option.<br><b>S. Lam, <\/b> None..<br><b>A. McGuire, <\/b> None..<br><b>S. Deppen, <\/b> None..<br><b>E. Grogan, <\/b> None..<br><b>F. Maldonado, <\/b> None..<br><b>M. Gieske, <\/b> None..<br><b>J. Seaman, <\/b> None..<br><b>K. Rieger-Christ, <\/b> None..<br><b>S. Kalanjeri, <\/b> None.&nbsp;<br><b>L. Herrera, <\/b> <br><b>Intuitive Surgical Inc<\/b> Other, Speaker Bureau.<br><b>N. Tanner, <\/b> None.&nbsp;<br><b>G. B. Sherwood, <\/b> <br><b>Astra Zeneca<\/b> Other, Consultant. <br><b>Bristol Myers Squibb<\/b> Other, Consultant. <br><b>O. Savin, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>S. Danan, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>S. Zaouch, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>N. Axelrad, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>R. Knirsh, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>O. Shliefer, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>K. Manor, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>R. Duttagupta, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>A. Shuali, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>P. J. Mazzone, <\/b> <br><b>Adela<\/b> Other, research funding. <br><b>Biodesix<\/b> Other, research funding. <br><b>Delfi Diagnostics<\/b> Other, research funding. <br><b>Exact Sciences<\/b> Other, research funding. <br><b>MagArray<\/b> Other, research funding. <br><b>Nucleix<\/b> Other, research funding. <br><b>Prognomix<\/b> Other, research funding. <br><b>Veracyte<\/b> Other, research funding. <br><b>G. A. Silvestri, <\/b> <br><b>Delfi Diagnostics<\/b> Other, research funding. <br><b>Biodesix<\/b> Other, research funding and consulting. <br><b>Prognomix<\/b> Other, research funding. <br><b>Olympus<\/b> Other, research funding and consulting. <br><b>Amgen<\/b> Other, research funding. <br><b>Nucleix<\/b> research funding. <br><b>C. A. Schnabel, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option. <br><b>D. Frumkin, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option, Patent. <br><b>A. Wasserstrom, <\/b> <br><b>Nucleix<\/b> Employment, Stock Option, Patent.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8108","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"16","PosterboardNumber":"17","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5434","PresenterBiography":null,"PresenterDisplayName":"Catherine Schnabel, PhD","PresenterKey":"3ffca030-e5d3-4e37-adf1-479a17d1d7ad","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5434. Machine-learning-based epigenetic detection of early-stage lung cancers using the EpiCheck liquid biopsy platform","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Machine-learning-based epigenetic detection of early-stage lung cancers using the EpiCheck liquid biopsy platform","Topics":null,"cSlideId":""},{"Abstract":"Introduction: STS are mostly prognosticated through nomograms relying on age, size, histotype and grade. Radiomics approaches, complemented with deep-learning, deep-radiomics and gene-expression profiling, could help understanding the bridge between STS radiophenotypes and molecular features and provide more efficient prognostic tools. Our goals were to investigate correlations between imaging and transcriptomics patterns, and to develop supervised prognostic models for STS patients.<br \/>Methods: We included all consecutive adult patients with newly-diagnosed locally-advanced STS managed at our sarcoma reference center between 2008 and 2020, with contrast-enhanced baseline MRI. After MRI dataset homogenization, we reduced the dimensions of the MRI data space by extracting 138 radiomics features (RFs) and 1024 deep-RFs with computational approach and autoencoder neural networks. Patient RNA was extracted from untreated samples. Following transcriptomic sequence analysis, gene expression levels for each patient were calculated. Complexity Index in Sarcoma (CINSARC) signature was extracted. Unsupervised classifications of patients based on radiomics, deep-radiomics and transcriptomics datasets were built using consensus hierarchical clustering. Differential Gene Expression and oncogenetic pathways analyses were performed. Associations between the 3 classifications, CINSARC, grade, histotypes and SARCULATOR were explored, as well as their prognostic value. The main outcome was the metastatic-relapse free survival (MFS). The SARCULATOR nomogram and prognostic semantic-radiological features were extracted for benchmarking and understanding models outputs.<br \/>Results: 220 patients were included (111 men, median age: 62 years); 60 patients developed metastases after completing curative treatments (data are being updated with 2 additional follow-up years). Transcriptomic analysis was achieved in 54 patients and is being updated with 56 additional samples.<br \/>So far, no significant associations were found between the radiomics-based classifications and the transcriptomics-based (including CINSARC).<br \/>Nevertheless, the computational radiomics, deep-radiomics, and transcriptomics classifications were associated with MFS, though transcriptomic significance was dampened by the small sample size (P=0.008 [N=220], 0.006 [N=220] and 0.070 [N=54], respectively), suggesting complementary prognostic information.<br \/>Supervised models using data-splitting, cross-validated algorithms training, and various combinations of input data are being elaborated to improve the MFS prediction.<br \/>Conclusion: Integrating complementary multiomics datasets with computational and deep radiomics should pave the way for better performing and personalized prognostications in STS patients.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Machine learning,Magnetic resonance imaging,Gene expression profiling,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Amandine Crombe<sup>1<\/sup>, Carlo Lucchesi<sup>2<\/sup>, Frédéric Bertolo<sup>2<\/sup>, Michèle Kind<sup>1<\/sup>, Raul Perret<sup>3<\/sup>, Francois Le Loarer<sup>3<\/sup>, Mariella Spalato-Ceruso<sup>4<\/sup>, Maud Toulmonde<sup>4<\/sup>, Audrey Laroche<sup>5<\/sup>, Vanessa Chaire<sup>3<\/sup>, Aurelien Bourdon<sup>2<\/sup>, <b>Antoine Italiano<\/b><sup>4<\/sup><br><br\/><sup>1<\/sup>Radiology, Institute Bergonié, Bordeaux, France,<sup>2<\/sup>Bioinformatics, Institute Bergonié, Bordeaux, France,<sup>3<\/sup>Biopathology, Institute Bergonié, Bordeaux, France,<sup>4<\/sup>Medical oncology, Institute Bergonié, Bordeaux, France,<sup>5<\/sup>Sarcoma unit, Institute Bergonié, Bordeaux, France","CSlideId":"","ControlKey":"a54001cc-f322-436e-81a5-c5b3cc4710dd","ControlNumber":"5140","DisclosureBlock":"&nbsp;<b>A. Crombe, <\/b> None..<br><b>C. Lucchesi, <\/b> None..<br><b>F. Bertolo, <\/b> None..<br><b>M. Kind, <\/b> None..<br><b>R. Perret, <\/b> None..<br><b>F. Le Loarer, <\/b> None..<br><b>M. Spalato-Ceruso, <\/b> None..<br><b>M. Toulmonde, <\/b> None..<br><b>A. Laroche, <\/b> None..<br><b>V. Chaire, <\/b> None..<br><b>A. Bourdon, <\/b> None..<br><b>A. Italiano, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8109","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"17","PosterboardNumber":"18","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5435","PresenterBiography":null,"PresenterDisplayName":"Antoine Italiano, MD;PhD","PresenterKey":"b2437d6d-3857-4a75-bae3-60a267fe9e51","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5435. Correlating and combining computational radiomics, deep radiomics and transcriptomics data in soft-tissue sarcomas (STS) patients highlight complementary prognostic information","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Correlating and combining computational radiomics, deep radiomics and transcriptomics data in soft-tissue sarcomas (STS) patients highlight complementary prognostic information","Topics":null,"cSlideId":""},{"Abstract":"Increasing implementation of whole slide image (WSI) and advances in computing capacity enable the use of artificial intelligence (AI) in pathology, such as quantification of biomarkers, aids in diagnosis and detection of lymph node metastasis. However, predicting therapy response in cancer patients from pre-treatment histopathologic images remains a challenging task, limited by poor understanding of tumor immune microenvironment. In this study, we aimed to develop AI models using multi-source histopathologic images to predict neoadjuvant chemotherapy (NAC) response in HER2-positive (HER2+) breast cancers. First, pretreatment tumor tissues were stained with Hematoxylin and Eosin (H&#38;E) and multiplex immunohistochemistry (IHC) including tumor immune microenvironment markers (PD-L1: immune checkpoint protein; CD8: marker for cytotoxic T-cells; and CD163: marker for type 2 macrophages). Next, we developed an AI-based pipeline to automatically extract histopathologic features from H&#38;E and multiplex IHC WSIs. The pipeline included: A) H&#38;E tissue segmentation based on DeepLabV3 model to generate stroma, tumor, and lymphocyte-rich regions. B) IHC marker segmentation to segment CD8, CD163, and PD-L1 stained cells. C) H&#38;E and IHC non-rigid registration to match H&#38;E and IHC images since they were stained from different levels of tissue. D) Image-based registration and segmentation histopathologic feature construction. A total of 36 histopathological features were constructed to represent tumor immune microenvironment characteristics such as ratios of PD-L1, CD8 and CD163 in tumoral, stromal or lymphocyte-rich regions. They were used to train machine learning (ML) models to predict NAC response in a training dataset with 62 HER2+ breast cancers (38 with complete and 24 with incomplete response). The ML model using logistic regression demonstrated the best performance with an area under curve (AUC) of 0.8975. We also tested ML models using pathologists-derived histopathologic features, but the best performed model showed an AUC of 0.7880. Finally, the developed logistic regression ML model was tested on an external validation dataset with 20 HER2+ breast cancers (10 with complete and 10 with incomplete response) and yielded an AUC of 0.9005. In summary, we described an automatic, accurate and interpretable AI-based pipeline to extract histopathologic features from H&#38;E and IHC WSIs and then used these features to develop machine learning model to accurately predict NAC response in HER2+ breast cancers. The ML model using AI-based extracted features outperformed the model using features manually generated by pathologists.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,Deep learning,Chemotherapy response,Immunohistochemistry,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Zhi Huang<sup>1<\/sup>, Anil V. Parwani<sup>2<\/sup>, Kun Huang<sup>3<\/sup>, <b>Zaibo Li<\/b><sup>2<\/sup><br><br\/><sup>1<\/sup>Purdue University, West Lafayette, IL,<sup>2<\/sup>The Ohio State University Wexner Medical Ctr., Columbus, OH,<sup>3<\/sup>Indiana University, Indianapolis, IN","CSlideId":"","ControlKey":"79a8bef7-17cd-45fc-a04c-ce42052816e3","ControlNumber":"186","DisclosureBlock":"&nbsp;<b>Z. Huang, <\/b> None..<br><b>A. V. Parwani, <\/b> None..<br><b>K. Huang, <\/b> None..<br><b>Z. Li, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8110","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"18","PosterboardNumber":"19","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5436","PresenterBiography":null,"PresenterDisplayName":"Zaibo Li, MBA;MD;PhD","PresenterKey":"fef9e313-3ed1-4bf0-b797-7f2589c67dbc","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5436. Developing artificial intelligence algorithms to predict response to neoadjuvant chemotherapy in HER2-positive breast cancer","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Developing artificial intelligence algorithms to predict response to neoadjuvant chemotherapy in HER2-positive breast cancer","Topics":null,"cSlideId":""},{"Abstract":"Purpose: Staging of human epidermal growth factor receptor 2 (HER2) expression is crucial for evaluating the effectiveness of breast cancer treatment. However, it involves an expensive and challenging immunohistochemical (IHC) staining in addition to hematoxylin and eosin (H&#38;E) staining. Here, we argue that customized vision transformers are effective in breast cancer HER2 expression staging using only H&#38;E-stained images.<br \/>Methods: Our algorithm has three modules: a localization module to weakly localize the necessary features of an image via spatial transformers, an attention module to learn global features from the image using vision transformers, and a loss module that determines the closest one to a HER2 expression level from input images by calculating the ordinal loss. We utilized a publicly available breast cancer HER2 expression dataset, the breast cancer immunohistochemical image (BCI) dataset, which contains paired H&#38;E and IHC stained images. Results were calculated with 95% confidence intervals and t-test was used to evaluate the significance of the proposed model against other models.<br \/>Results: Our approach achieved area under receiver operating characteristics curve (AUC), precision, sensitivity, and specificity of 0.9202&#177;0.01, 0.922&#177;0.01, 0.876&#177;0.01, and 0.959&#177;0.02, respectively, averaged over five-fold cross-validation, in staging HER2 expression. The proposed method showed better performance than the conventional vision transformer model and state-of-the-art convolutional neural network models with statistical significance of <i>p<\/i>&#60;0.01 in all cases.<br \/>Conclusion: Our findings are important in assisting HER2 expression staging in breast cancer treatment, while avoiding the need for an expensive and time-consuming IHC staining procedure.<br \/><table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{BDADAACF-36CC-4511-8AED-7E2E3218B4A7}\"><caption>Comparison of the proposed model with state-of-the-art models. CNN-convolutional neural network<\/caption><tr><td rowspan=\"1\" colspan=\"1\">Study<\/td><td rowspan=\"1\" colspan=\"1\">Neural network<\/td><td rowspan=\"1\" colspan=\"1\">Model<\/td><td rowspan=\"1\" colspan=\"1\">AUC<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Couture et al. (2018)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">VGG16<\/td><td rowspan=\"1\" colspan=\"1\">0.75<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Shamai et al. (2019)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">ResNet50<\/td><td rowspan=\"1\" colspan=\"1\">0.74<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Yang et al. (2021)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">ResNet50<\/td><td rowspan=\"1\" colspan=\"1\">0.76<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Naik et al. (2020)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">ResNet50<\/td><td rowspan=\"1\" colspan=\"1\">0.78<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Khater et al. (2021)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">ShuffleNet<\/td><td rowspan=\"1\" colspan=\"1\">0.75<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Conde-Sousa et al. (2022)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">EfficientNet<\/td><td rowspan=\"1\" colspan=\"1\">0.88<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Farahmand et al. (2022)<\/td><td rowspan=\"1\" colspan=\"1\">CNN<\/td><td rowspan=\"1\" colspan=\"1\">InceptionV3<\/td><td rowspan=\"1\" colspan=\"1\">0.90<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Proposed<\/td><td rowspan=\"1\" colspan=\"1\">Vision transformer<\/td><td rowspan=\"1\" colspan=\"1\">vitb_16<\/td><td rowspan=\"1\" colspan=\"1\">0.92<\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,HER2,Breast cancer,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Gelan Ayana<\/b><sup><\/sup>, Eonjin Lee<sup><\/sup>, Se-woon Choe<sup><\/sup><br><br\/>Kumoh National Institute of Technology Education Organization, Gumi, Korea, Republic of","CSlideId":"","ControlKey":"b60b4270-e7c7-48de-b8ba-d11862d29a17","ControlNumber":"1566","DisclosureBlock":"&nbsp;<b>G. Ayana, <\/b> None..<br><b>E. Lee, <\/b> None..<br><b>S. Choe, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8111","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"19","PosterboardNumber":"20","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5437","PresenterBiography":null,"PresenterDisplayName":"Gelan Ayana, MS","PresenterKey":"960d1b24-385d-417f-9fbf-77bc6a901a25","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5437. Vision transformers for breast cancer human epidermal growth factor receptor 2 (HER2) expression staging without immunohistochemical (IHC) staining","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Vision transformers for breast cancer human epidermal growth factor receptor 2 (HER2) expression staging without immunohistochemical (IHC) staining","Topics":null,"cSlideId":""},{"Abstract":"Background: Automated prognosis marker assessment in prostate and breast cancer using immunohistochemistry is currently hampered by the lack of a reliable differentiation between benign and malignant glands. To evaluate the patient&#8217;s risk in routine clinical practice in prostate cancer prognosis parameters such as the Gleason grading, that are accompanied by a high interobserver variability are used. In breast cancer multi-gene panels are used that are influenced by fluctuating tumor purity. A reproducible prognostic evaluation is lacking in both tumor entities.<br \/>Design: To enable automated prognosis marker quantification, we have developed and validated a framework for automated prostate and breast cancer detection that comprises three different artificial intelligence analysis steps and an algorithm for cell-distance analysis of multiplex fluorescence immunohistochemistry. Pan-cytokeratin (panCK) antibodies were used to detect epithelial cells and antibodies directed against Myosin and p63 were used to identify basal cells.<br \/>Results: The optimal distance between Myosin<sup>+<\/sup> and p63<sup>+<\/sup> basal cells and benign panCK<sup>+<\/sup> cells was identified as 25 &#181;m in breast and 23 &#181;m in prostate cancer and used to exclude benign glands from the analysis combined with several deep learning-based algorithms. Our framework discriminated normal glands from malignant glands with an AUC of 0.96 in breast and 0.98 % in prostate cancer. The approach for automated prostate and breast cancer detection, by excluding benign gland from the analysis, improved the predictive performance of prognosis markers significantly (p&#60;0.001). To compare the multiplex fluorescence immunohistochemistry-based (mfIHC) automated prognosis marker assessment with &#8220;classical&#8221; bright field-based automated prostate cancer detection for prognosis marker assessment in a cohort of 30 biopsies from routine clinical practice prognosis markers were manually assessed and set as gold standard. An excellent agreement between the mfIHC-based automated cancer detection and the reference manual cancer identification was found (intraclass correlation [ICC]: 0.94 [95% CI 0.87 - 0.97]).<br \/>Conclusion: Automated prostate and breast cancer identification enables fully automated prognosis marker assessment in routine clinical practice using deep learning and multiplex fluorescence immunohistochemistry. BLEACH&#38;STAIN as well as other multiplex fluorescence immunohistochemistry approaches that enable the simultaneous analysis of 20+ biomarkers can be used to established prognosis panels that can be now assessed in an automated manner.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,Deep learning,Prostate cancer,Immunohistochemistry,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Tim Mandelkow<sup>1<\/sup>, Gisa Mehring<sup>1<\/sup>, Elena Bady<sup>1<\/sup>, Maximilian Lennartz<sup>1<\/sup>, Christoph Fraune<sup>1<\/sup>, Frank Jacobsen<sup>1<\/sup>, Natalia Gorbokon<sup>1<\/sup>, Till Krech<sup>1<\/sup>, Eike Burandt<sup>1<\/sup>, Anne Menz<sup>1<\/sup>, Ria Uhlig<sup>1<\/sup>, Till S. Clauditz<sup>1<\/sup>, Guido Sauter<sup>1<\/sup>, Markus Graefen<sup>2<\/sup>, Sarah Minner<sup>1<\/sup>, <b>Niclas C. Blessin<\/b><sup>1<\/sup><br><br\/><sup>1<\/sup>University Medical Center Hamburg-Eppendorf, Hamburg, Germany,<sup>2<\/sup>Martini-Clinic Hamburg-Eppendorf, Hamburg, Germany","CSlideId":"","ControlKey":"b8173c15-d5c3-40ad-bbfd-d5aeb145e8d2","ControlNumber":"4135","DisclosureBlock":"&nbsp;<b>T. Mandelkow, <\/b> None..<br><b>G. Mehring, <\/b> None..<br><b>E. Bady, <\/b> None..<br><b>M. Lennartz, <\/b> None..<br><b>C. Fraune, <\/b> None..<br><b>F. Jacobsen, <\/b> None..<br><b>N. Gorbokon, <\/b> None..<br><b>T. Krech, <\/b> None..<br><b>E. Burandt, <\/b> None..<br><b>A. Menz, <\/b> None..<br><b>R. Uhlig, <\/b> None..<br><b>T. S. Clauditz, <\/b> None.&nbsp;<br><b>G. Sauter, <\/b> <br><b>MS Validated Antibodies GmbH<\/b> MS Validated Antibodies GmbH is owned by a family member of Guido Sauter, Director of Institute. GATA3 antibody, clone MSVA-450 and the Ki67 antibody, colne MSVA-267M; the monoclonal rabbit antibodies HER2, clone MSVA-340R; PD-L1, clone MSVA-711R; PR, clone MSVA-570R; AR, clone MSVA-367R; ER, clone MSVA-564R; TROP-2 (MSVA-733R); TOPO2A (MSVA-802R); Myosin (MSVA-375) and panCK(MSVA-000R).<br><b>M. Graefen, <\/b> None..<br><b>S. Minner, <\/b> None..<br><b>N. C. Blessin, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8112","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"20","PosterboardNumber":"21","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5438","PresenterBiography":null,"PresenterDisplayName":"Niclas Blessin, MD","PresenterKey":"78f26db6-1dfe-4280-8ee5-c965257228dd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5438. The combination of artificial intelligence and BLEACH&#38;STAIN multiplex fluorescence immunohistochemistry facilitates automated prostate and breast cancer detection","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"The combination of artificial intelligence and BLEACH&#38;STAIN multiplex fluorescence immunohistochemistry facilitates automated prostate and breast cancer detection","Topics":null,"cSlideId":""},{"Abstract":"MOTIVATION: One of the most complex aspects of providing care to cancer patients is building an accurate list of medications a patient is taking. Medication lists need to capture the necessary clinical context about how the patient uses the drug, such as if they can no longer afford a medication or decide to change the frequency at which they take it due to side effects. While hidden from the medication list, these changes are significant to medical decision making. Moreover, many studies focus on providing cancer medication safely. Still, providers are often not aware of other medications, which clinicians may administer in a different practice than the one providing cancer care. While many solutions attempt to improve the medication list, they frequently ignore one of the highest quality sources of medication information: clinical narratives. In this work, we propose utilizing Natural Language Processing (NLP) to extract medications and medication change events from clinical narratives.<br \/>METHODS &#38; DISCUSSION: In this work, we utilize NLP to extract medications and medication change events from clinical narratives. We use the medication event extraction schema from the N2C2 2022 Challenge to train and evaluate various models for two classification tasks. The first is Event Classification (EC), to identify if a medication was changed. The second is Event Context Classification (ECC) to understand the nature of any change.<br \/>Using this schema, we can parse a sentence from a clinical note such as &#8220;She was experiencing a bad episode of dry cough, so stopped taking lisinopril.&#8221; Parsing such a note helps us understand an actor (the patient) initiated an action (stopping the medication) with a temporality (in the past) and with a certainty (not hypothetical).<br \/>Our approach for both tasks involved using a pre-trained clinical language model while varying the context window around a medication, masking extraneous drugs, and using mark-up tokens around events. The most performant experiments utilized more extended context around a drug, with irrelevant drug masking. We also note that longer-range encoders had better F1 performance than the original BERT architectures.<br \/>We achieved a 92% performance (micro F1) for EC when detecting a medication change. For ECC, we achieved scores of 74%, 90%, 73%, and 88% (micro F1) over the categories of Action, Certainty, Temporality, and Actor.<br \/>CONCLUSION: Given the performance observed, this approach could allow clinicians to incorporate additional extracted medication context to improve patient care and provide high-quality treatment plans. Furthermore, we can aggregate this information across patients to give more insights to clinicians and researchers about the actual use of medications.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Deep learning,NLP,EMR,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Jacob Hoffman<sup><\/sup>, <b>Neehar Mukne<\/b><sup><\/sup>, Daniela Weiss<sup><\/sup>, Christine Swisher<sup><\/sup>, Max Kaufmann<sup><\/sup><br><br\/>The Ronin Project Inc, San Mateo, CA","CSlideId":"","ControlKey":"1596d1c4-427b-47dd-9508-d6c74b76ea9d","ControlNumber":"7853","DisclosureBlock":"<b>&nbsp;J. Hoffman, <\/b> <br><b>The Ronin Project Inc<\/b> Employment. <br><b>N. Mukne, <\/b> <br><b>The Ronin Project Inc<\/b> Employment. <br><b>D. Weiss, <\/b> <br><b>The Ronin Project Inc<\/b> Employment. <br><b>C. Swisher, <\/b> <br><b>The Ronin Project Inc<\/b> Employment. <br><b>M. Kaufmann, <\/b> <br><b>The Ronin Project Inc<\/b> Employment.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8113","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"21","PosterboardNumber":"22","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5439","PresenterBiography":null,"PresenterDisplayName":"Neehar Mukne, MS","PresenterKey":"76295cde-3c26-4a3a-8321-048099122597","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5439. Deep understanding of medication events from clinical narratives is essential to building a holistic picture of cancer patient medication history","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Deep understanding of medication events from clinical narratives is essential to building a holistic picture of cancer patient medication history","Topics":null,"cSlideId":""},{"Abstract":"Background: Knowledge of a patient&#8217;s tumor type is essential for guiding clinical treatment decisions in cancer, but histologically-based diagnosis remains challenging for a subset of cancers. Genomic alterations are highly indicative of tumor type and can be used to build classifiers that predict diagnoses, but most genomic-based classification methods use whole genome sequencing (WGS) data which is not feasible for widespread clinical implementation at present. Clinical sequencing is typically performed using cancer gene panels that target individual mutations, often drivers, but previous tumor type classifiers developed using driver-based features alone perform poorly. We hypothesize that a classifier developed using state-of-the-art deep-learning methods and a sufficiently large training cohort would be able to overcome previous accuracy limitations and support the development of a clinically-relevant tumor type prediction model.<br \/>Methods: We present Deep Genome-Derived Diagnosis (GDD-ENS), an ensemble-based deep-learning tumor type classification method trained using data from cancer gene panel sequencing. We specifically use data from MSK-IMPACT, an FDA-authorized clinical sequencing assay that reports genomic alterations including mutations, indels, copy number alterations, and gene fusions across 505 cancer-associated genes. We aggregated a discovery cohort of 35,372 patients with solid tumors profiled with MSK-IMPACT across 38 common cancer types and used this set to generate 4,487 somatic mutation features for development.<br \/>Results: GDD-ENS achieves 78.8% accuracy on a held out validation cohort of 6971 patients. For the 71.9% of predictions assigned a high confidence by the model, accuracy increases to 92.7%, rivaling WGS-based models. We use Shapley Values to report prediction-specific feature importance, and aggregate them across cancer types to show GDD-ENS identifies known cancer type-genomic alteration trends. GDD-ENS also, with high accuracy, identifies patients with cancer types not included in the 38 common types using metrics derived from ensemble statistics. For patients where non-genomic information could further guide predictions, we implement a customizable prediction-specific adaptive prior distribution and report improved accuracy after adjusting predictions to account for features such as metastatic sample biopsy site. Finally, we apply GDD-ENS to a set of 1,123 patients with Cancers of Unknown Primary (CUP) and return high confidence predictions for 49% of these patients, in some cases matching predictions on CUP samples with diagnoses that were later confirmed through additional sampling and disease progression.<br \/>Conclusions: Integrating GDD-ENS into prospective clinical sequencing workflows will enable clinically-relevant tumor type predictions that can guide treatment decisions in real-time.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Cancer diagnostics,Genomics,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Madison Darmofal<\/b><sup>1<\/sup>, Shalabh Suman<sup>2<\/sup>, Gurnit Atwal<sup>3<\/sup>, Jie-Fu Chen<sup>4<\/sup>, Anna Varghese<sup>5<\/sup>, Jason  C.  Chang<sup>4<\/sup>, Anoop Balakrishnan Rema<sup>4<\/sup>, Aijazuddin Syed<sup>4<\/sup>, Quaid Morris<sup>6<\/sup>, Michael Berger<sup>4<\/sup><br><br\/><sup>1<\/sup>Weill Cornell Medicine, Memorial Sloan Kettering Cancer Center, New York, NY,<sup>2<\/sup>Memorial Sloan Kettering Cancer Center, New York, NY,<sup>3<\/sup>Department of Molecular Genetics, University of Toronto, Toronto, ON, Canada,<sup>4<\/sup>Department of Pathology, Memorial Sloan Kettering Cancer Center, New York, NY,<sup>5<\/sup>Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, NY,<sup>6<\/sup>Computational and Systems Biology, Memorial Sloan Kettering, New York, NY","CSlideId":"","ControlKey":"d94c9e21-bbb2-4190-a2d8-e53921f89feb","ControlNumber":"4440","DisclosureBlock":"&nbsp;<b>M. Darmofal, <\/b> None..<br><b>S. Suman, <\/b> None..<br><b>G. Atwal, <\/b> None..<br><b>J. Chen, <\/b> None..<br><b>A. Varghese, <\/b> None..<br><b>J. C. Chang, <\/b> None..<br><b>A. Balakrishnan Rema, <\/b> None..<br><b>A. Syed, <\/b> None..<br><b>Q. Morris, <\/b> None..<br><b>M. Berger, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8114","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"22","PosterboardNumber":"23","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5440","PresenterBiography":null,"PresenterDisplayName":"Madison Darmofal","PresenterKey":"d87dff2c-a54d-454e-907b-f1219c30013e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5440. Deep-learning model for tumor type classification enables enhanced clinical decision support in cancer diagnosis","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Deep-learning model for tumor type classification enables enhanced clinical decision support in cancer diagnosis","Topics":null,"cSlideId":""},{"Abstract":"Background: Cyclin-dependent kinase inhibitor p21 is a regulator of cell cycle progression. Due to its capacity to induce cell cycle arrest (CCA) when expressed in the nucleus, it is also considered a tumor suppressor and its presence can be used to evaluate the efficacy of anti-cancer treatment. Since pathologists cannot assess nuclear p21 status of cells using hematoxylin &#38; eosin (H&#38;E) stained tissue alone, the current state-of-the-art approach requires evaluation using immunohistochemistry (IHC). This process is time-consuming, adds additional cost and usually requires a separate section of the sample tissue. Further, manual evaluation of IHC stainings typically shows high inter-pathologist variability. In this study, we developed a deep learning model that predicts cell-level nuclear p21 status on H&#38;E-stained tissue alone, aiming to bypass the IHC-staining step and all drawbacks associated with it.<br \/>Methods: 99 tissue sections of pancreas cancer xenografts were stained by H&#38;E, then restained for p21 (IHC). The samples originated from mice that had undergone experiments conducted to examine the pharmacodynamic effect of anti-cancer treatments. H&#38;E and IHC image pairs were coregistered to micrometer level precision. A tissue segmentation model was trained to detect regions of &#8216;carcinoma&#8217; in H&#38;E. This model was used as a filter and only cells within the tumor region were considered for analysis. Individual cells were detected in the H&#38;E image and these locations were transferred to the IHC image. A deep learning model was trained using IHC-informed labels to extract labels at scale from each IHC image. These labels were then transferred to the H&#38;E image and used to train a second deep learning model which predicted nuclear p21 status from H&#38;E alone.<br \/>Results: IHC-informed labels were extracted with a balanced accuracy (BA) of 0.93. The resulting &#8216;H&#38;E only&#8217; nuclear p21 model achieved a cell-level BA of 0.83. A case level comparison of the share of predicted p21+ nuclei showed a Pearson correlation of 0.72 with the share of p21+ nuclei determined by the IHC-informed extracted labels. Further, when used to characterize all samples, the model detected significant differences between treatment groups.<br \/>Conclusion: Nuclear p21 status can be detected at a cellular level in H&#38;E images alone, using a deep learning model. This provides an opportunity to assess samples for cell cycle arrest status at scale in a standardized manner, without the need for IHC staining.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-01 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"p21,Deep learning,Immunohistochemistry,Preclinical,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Christina Aigner<\/b><sup>1<\/sup>, Brian Reichholf<sup>2<\/sup>, Maxime Emschwiller<sup>1<\/sup>, Marija Pezer<sup>1<\/sup>, Tobias Winterhoff<sup>1<\/sup>, Simon Schallenberg<sup>3<\/sup>, Rosemarie Krupar<sup>1<\/sup>, Lukas Ruff<sup>1<\/sup>, Sharon Ruane<sup>1<\/sup>, Maximilian Alber<sup>1<\/sup>, Frederick Klauschen<sup>4<\/sup>, Francesca Trapani<sup>2<\/sup><br><br\/><sup>1<\/sup>Aignostics GmbH, Berlin, Germany,<sup>2<\/sup>Boehringer Ingelheim RCV GmbH & Co KG, Vienna, Austria,<sup>3<\/sup>Institute of Pathology, Charité – Universitätsmedizin Berlin, Berlin, Germany,<sup>4<\/sup>Institute of Pathology, Ludwig Maximilian University, Munich, Germany","CSlideId":"","ControlKey":"02b0bc13-3b2d-4ffc-a24c-fa20be7ff403","ControlNumber":"4714","DisclosureBlock":"&nbsp;<b>C. Aigner, <\/b> None..<br><b>B. Reichholf, <\/b> None..<br><b>M. Emschwiller, <\/b> None..<br><b>M. Pezer, <\/b> None..<br><b>T. Winterhoff, <\/b> None..<br><b>S. Schallenberg, <\/b> None..<br><b>R. Krupar, <\/b> None..<br><b>L. Ruff, <\/b> None..<br><b>S. Ruane, <\/b> None..<br><b>M. Alber, <\/b> None.&nbsp;<br><b>F. Klauschen, <\/b> <br><b>Bristol Myers Squibb<\/b> Grant\/Contract. <br><b>Merck & Co.<\/b> Grant\/Contract. <br><b>Novartis AG<\/b> Grant\/Contract. <br><b>F. Hoffmann-La Roche AG<\/b> Grant\/Contract. <br><b>Eli Lilly and Company<\/b> Grant\/Contract. <br><b>Agilent Technologies, Inc.<\/b> Grant\/Contract. <br><b>Bayer AG<\/b> Grant\/Contract.<br><b>F. Trapani, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8115","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"23","PosterboardNumber":"24","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5441","PresenterBiography":null,"PresenterDisplayName":"Christina Aigner, MS","PresenterKey":"32ab1248-83d0-445f-ba3e-9f7901bc5d96","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5441. Cell cycle arrest status predicted from H&#38;E stained images using deep learning","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Cell cycle arrest status predicted from H&#38;E stained images using deep learning","Topics":null,"cSlideId":""},{"Abstract":"Introduction: Artifacts are often introduced during tissue collection and processing, slide preparation, and\/or when generating whole slide images (WSI). The presence of artifacts has a negative impact on the digital pathology workflow as artifacts may hinder diagnostic reporting and can lead to false positive and false negative results when using image analysis algorithms or computer-aided diagnosis systems. Manual quality control of WSI is a time-consuming procedure and therefore automated quality control tools, which report and exclude artifacts, are highly desirable to streamline digital pathology workflows. To automate the quality control step, we developed SlideQC, an AI-based quality control tool that automatically detects, reports, and outlines artifacts such as air bubbles, dust\/debris, folds, out-of-focus,and pen marks, in both research and clinical workflows. Methods: SlideQC was trained with a DenseNet-based network using 1984 annotations for artifacts including air bubbles, dust\/debris, folds, out-of-focus, and pen markers, across 254 Haematoxylin and Eosin (H&#38;E) stained WSI from more than 9 tissue types. A set of 2048 annotations from synthetically generated out-of-focus images was added to supplement the training data. The performance of the SlideQC was evaluated on an external test cohort of 49 WSI H&#38;E images sourced from the open-source database &#8216;HistoQCRepo&#8217;, across 375 annotations (tissue and artifact), and compared with the performance of HistoQC, an open-source quality control tool for digital pathology slides. Results: On the external test cohort, SlideQC showed high sensitivity, specificity, and F1-score with average values of 0.93, 0.99, and 0.93, across the five artifact types. In the same cohort, HistoQC attained an average sensitivity, specificity, and F1-score of 0.65, 0.79, and 0.54, respectively. Conclusions: SlideQC achieved high sensitivity, specificity, and F1-score on an external test cohort. SlideQC can add efficiency gains to a workflow by performing quality control on 100% of slides rather than the currently manually performed on only a subset of the slides in clinical pathology departments. SlideQC can allowthe triaging and alerting of slides containing a high level of artifact within a digital pathology workflow. The tool can also be used to exclude the artifact region from downstream analysis by subsequent image analysis algorithms.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology ,,"},{"Key":"Keywords","Value":"Machine learning,Deep learning,Formalin-fixed paraffin-embedded (FFPE),Image analysis,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Daniela Rodrigues<\/b><sup>1<\/sup>, Stefan Reinhard<sup>2<\/sup>, Therese Waldburger<sup>2<\/sup>, Daniel Martin<sup>3<\/sup>, Suzana Couto<sup>4<\/sup>, Inti Zlobec<sup>2<\/sup>, Peter Caie<sup>1<\/sup>, Erik Burlingame<sup>1<\/sup><br><br\/><sup>1<\/sup>Indica Labs, Albuquerque, NM,<sup>2<\/sup>Institute of Pathology, University of Bern, Bern, Switzerland,<sup>3<\/sup>Genmab, New York, NY,<sup>4<\/sup>Pathology, Genmab, Princeton, NJ","CSlideId":"","ControlKey":"fa8c74e0-7296-4a31-9482-79e44881dc2b","ControlNumber":"6490","DisclosureBlock":"<b>&nbsp;D. Rodrigues, <\/b> <br><b>Indica Labs<\/b> Employment. <br><b>S. Reinhard, <\/b> <br><b>Indica Labs<\/b> Indica Labs provided free software. <br><b>T. Waldburger, <\/b> <br><b>Indica Labs<\/b> Other, Indica Labs provided free software. <br><b>D. Martin, <\/b> <br><b>Genmab<\/b> Employment. <br><b>S. Couto, <\/b> <br><b>Genmab<\/b> Employment. <br><b>I. Zlobec, <\/b> <br><b>Indica Labs<\/b> Indica Labs provided free software. <br><b>P. Caie, <\/b> <br><b>Indica Labs<\/b> Employment. <br><b>E. Burlingame, <\/b> <br><b>Indica Labs<\/b> Employment.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8118","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"24","PosterboardNumber":"25","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5442","PresenterBiography":null,"PresenterDisplayName":"Kim Collins","PresenterKey":"955b6084-2f27-499f-85d7-ae0becfffafc","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5442. SlideQC: An AI-based tool for automated quality control of whole-slide digital pathology images","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"SlideQC: An AI-based tool for automated quality control of whole-slide digital pathology images","Topics":null,"cSlideId":""},{"Abstract":"Introduction: Atypical adenomatous hyperplasia (AAH) is the only recognized preneoplasia of lung adenocarcinoma, which can progress to adenocarcinoma in situ (AIS), minimally invasive adenocarcinoma (MIA) and eventually to invasive adenocarcinoma (ADC). A more complete understanding of the early carcinogenesis of lung cancer is critical for lung cancer early detection and interception. However, studying these lung cancer precursors is challenging because these lesions are often insufficient for molecular and immune profiling. Artificial intelligence (AI)-based studies on H&#38;E histopathology images, termed pathomics, have achieved substantial progress in revealing heterogeneous phenotypic characteristics of various cancers. However, pathomics on lung precancerous progression and their correlation with genomic features remain underexplored.<br \/>Methods: We curated FFPE H&#38;E slides from two ethnic groups, including the Caucasian cohort containing 46 lesions with 170 regions of interest (ROI) (74 AAH, 10 AIS, 21 MIA, and 65 ADC) and the Asian cohort containing 128 lesions with 369 ROIs (59 AAH, 84 AIS, 77 MIA, and 149 ADC). We adopted the expert-in-the-loop strategy to develop a deep learning pipeline to segment and annotate the cells within ROI into three categories: epithelial, lymphocyte, and other. Next, we measured the ratio and density of epithelial cells and lymphocytes inside each ROI as pathomics features. Finally, we interrogated ROI-level features and examined their correlation with molecular and immune features in the Asian cohort.<br \/>Results: We observed a progressive increase in the ratio and density of epithelial cells and a progressive decrease in the ratio and density of lymphocytes defined by the AI model from AAH to AIS, MIA, and ADC, consistent with the same trends defined by T cell receptor (TCR) sequencing and multiplex immunofluorescence (mIF). When correlating pathomics features with molecular\/immune features, the epithelial cell ratio exhibited prominent positive correlations with the frequency of allelic imbalance (rho=0.588, p=4.71e-13) and nonsynonymous mutation burden (rho=0.453, p=1.03e-7). In contrast, the lymphocyte ratio showed a notable negative correlation with copy number variation burden (rho=-0.412, p=1.61e-6).<br \/>Conclusion: Employing AI tools to analyze HE images of lung precancerous lesions, we revealed that molecular and immune evolution during early lung carcinogenesis is consistent with the results from complicated, time-consuming, and expensive molecular\/immune profiling, which requires a large number of tissue specimens, highlighting the potential of pathomics in the study of cancer biology, particularly in diseases having limited tissue specimens.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology ,,"},{"Key":"Keywords","Value":"Lung cancer: non-small cell,Histopathology,Genomics,Cancer progression,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Pingjun Chen<\/b><sup>1<\/sup>, Frank Rojas<sup>2<\/sup>, Xin Hu<sup>3<\/sup>, Junya Fujimoto<sup>2<\/sup>, Alejandra Serrano<sup>2<\/sup>, Bo Zhu<sup>4<\/sup>, Lingzhi Hong<sup>1<\/sup>, Rukhmini Bandyopadhyay<sup>1<\/sup>, Muhammad Aminu<sup>1<\/sup>, Maliazurina  B.  Saad<sup>1<\/sup>, Morteza Salehjahromi<sup>1<\/sup>, Sheeba  J.  Sujit<sup>1<\/sup>, Neda Kalhor<sup>5<\/sup>, Harvey  I.  Pass<sup>6<\/sup>, Andre  L.  Moreira<sup>7<\/sup>, Ignacio  I.  Wistuba<sup>2<\/sup>, Don  L.  Gibbons<sup>4<\/sup>, John  V.  Heymach<sup>4<\/sup>, Luisa  M.  Solis Soto<sup>2<\/sup>, Jianjun Zhang<sup>4<\/sup>, Jia Wu<sup>1<\/sup><br><br\/><sup>1<\/sup>Imaging Physics, The University of Texas MD Anderson Cancer Center, Houston, TX,<sup>2<\/sup>Translational Molecular Pathology, The University of Texas MD Anderson Cancer Center, Houston, TX,<sup>3<\/sup>Genomic Medicine, The University of Texas MD Anderson Cancer Center, Houston, TX,<sup>4<\/sup>Thoracic\/Head and Neck Medical Oncology, The University of Texas MD Anderson Cancer Center, Houston, TX,<sup>5<\/sup>Pathology, The University of Texas MD Anderson Cancer Center, Houston, TX,<sup>6<\/sup>Surgery, NYU Langone Health, New York, NY,<sup>7<\/sup>Pathology, NYU Langone Health, New York, NY","CSlideId":"","ControlKey":"f544c958-67ff-46ad-bba7-a5cde013dceb","ControlNumber":"1584","DisclosureBlock":"&nbsp;<b>P. Chen, <\/b> None..<br><b>F. Rojas, <\/b> None..<br><b>X. Hu, <\/b> None..<br><b>J. Fujimoto, <\/b> None..<br><b>A. Serrano, <\/b> None..<br><b>B. Zhu, <\/b> None..<br><b>L. Hong, <\/b> None..<br><b>R. Bandyopadhyay, <\/b> None..<br><b>M. Aminu, <\/b> None..<br><b>M. B. Saad, <\/b> None..<br><b>M. Salehjahromi, <\/b> None..<br><b>S. J. Sujit, <\/b> None..<br><b>N. Kalhor, <\/b> None..<br><b>H. I. Pass, <\/b> None..<br><b>A. L. Moreira, <\/b> None.&nbsp;<br><b>I. I. Wistuba, <\/b> <br><b>AstraZeneca\/MedImmune<\/b> Grant\/Contract, consulting or advisory roles, personal fees. <br><b>Bayer<\/b> Other, consulting or advisory roles, personal fees. <br><b>Bristol-Myers Squibb<\/b> Grant\/Contract, consulting or advisory roles, personal fees. <br><b>Genentech\/Roche<\/b> Grant\/Contract, consulting or advisory roles, personal fees. <br><b>GlaxoSmithKline<\/b> Other, consulting or advisory roles, personal fees. <br><b>Guardant Health<\/b> Grant\/Contract, consulting or advisory roles, personal fees. <br><b>HTG Molecular Diagnostics<\/b> Grant\/Contract, consulting or advisory roles, personal fees. <br><b>Merck<\/b> Other, consulting or advisory roles. <br><b>MSD Oncology<\/b> Other, consulting or advisory roles. <br><b>OncoCyte<\/b> Other, consulting or advisory roles, personal fees. <br><b>Jansen<\/b> Other, consulting or advisory roles. <br><b>Novartis<\/b> Other, consulting or advisory roles. <br><b>Flame Inc<\/b> Other, consulting or advisory roles. <br><b>Regeneron<\/b> Other, consulting or advisory roles, personal fees. <br><b>Pfizer<\/b> Other, consulting or advisory roles, personal fees. <br><b>Daiichi-Sankyo<\/b> Other, personal fees. <br><b>Roche<\/b> Other, personal fees. <br><b>Astra Zeneca<\/b> Other, personal fees. <br><b>Sanofi<\/b> Other, personal fees. <br><b>D. L. Gibbons, <\/b> <br><b>AstraZeneca<\/b> Other, honoraria for scientific advisory boards, research support. <br><b>Sanofi<\/b> Other, honoraria for scientific advisory boards. <br><b>Alethia Biotherapeutics<\/b> Other, honoraria for scientific advisory boards. <br><b>Menarini<\/b> honoraria for scientific advisory boards. <br><b>Eli Lilly<\/b> honoraria for scientific advisory boards. <br><b>4D Pharma<\/b> honoraria for scientific advisory boards. <br><b>Onconova<\/b> Other, honoraria for scientific advisory boards. <br><b>Janssen<\/b> Other, research support. <br><b>Takeda<\/b> Other, research support. <br><b>Astellas<\/b> Other, research support. <br><b>Ribon Therapeutics<\/b> Other, research support. <br><b>NGM Biopharmaceuticals<\/b> Other, research support. <br><b>Boehringer Ingelheim<\/b> Other, research support. <br><b>Mirati Therapeutics<\/b> Other, research support.<br><b>J. V. Heymach, <\/b> None..<br><b>L. M. Solis Soto, <\/b> None.&nbsp;<br><b>J. Zhang, <\/b> <br><b>Merck<\/b> Grant\/Contract. <br><b>Johnson and Johnson<\/b> Patent, Other, personal fees. <br><b>Novartis<\/b> Grant\/Contract, Other, personal fees. <br><b>Bristol Myers Squibb<\/b> Other, personal fees. <br><b>AstraZeneca<\/b> Other, personal fees. <br><b>GenePlus<\/b> Other, personal fees. <br><b>Innovent<\/b> Other, personal fees. <br><b>Hengrui<\/b> Other, personal fees.<br><b>J. Wu, <\/b> None.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8119","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"25","PosterboardNumber":"26","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5443","PresenterBiography":"","PresenterDisplayName":"Pingjun Chen, PhD","PresenterKey":"b678b1b1-8973-443c-b902-2113ba2dc4b3","PresenterPhoto":"https:\/\/files.abstractsonline.com\/assocphotos\/101\/b678b1b1-8973-443c-b902-2113ba2dc4b3.profile.png","SearchResultActions":null,"SearchResultBody":"5443. Pathomics reveals the molecular and immune evolution from lung preneoplasia to invasive adenocarcinoma","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Pathomics reveals the molecular and immune evolution from lung preneoplasia to invasive adenocarcinoma","Topics":null,"cSlideId":""},{"Abstract":"Background: Transcriptomic and morphological features of the tumor microenvironment (TME) are associated with favorable prognosis and can serve as surrogate markers for immune checkpoint inhibitor response in certain breast cancer subtypes. Tertiary lymphoid structures (TLS) and stromal tumor-infiltrating lymphocytes (sTILs) are integral components of the TME. New techniques for TLS characterization could improve reproducibility and automate the current workflow. Here, we correlated AI-based imaging platform predictions of TLS and sTILs on breast cancer H&#38;E whole slide images (WSIs) with expression data.<br \/>Design: WSIs from 390 TCGA breast cancer samples were used to detect normalized tumoral TLS and tumor stroma infiltration areas by a convolutional neural network (CNN). High and low groups were defined by IQR1 and IQR3. Gene counts were compared using differential expression analysis followed by gene set enrichment analysis (GSEA) with hallmark gene sets. Kassandra's cell type percentage predictions, functional gene signature (Fges) single-sample GSEA, and PROGENy pathway activity median-scaled scores were compared with the Mann-Whitney U test. The Fges consisted of 4 TLS and 29 TME signatures and were clustered into 4 groups: fibrotic, myeloid, T cell, and TLS. Group medians were analyzed. Somatic deep amplifications, deletions, and missense mutations of cancer pathways were compared with Fisher&#8217;s exact test. The FDR method was used to adjust p-values.<br \/>Results: <i>FDCSP,<\/i> <i>CXCL13,<\/i> <i>CD79A, CCL19, <\/i>and <i>IGLL5 <\/i>were upregulated in the TLS-high group (logFC &#62; 1.5, p &#60; 0.003), and <i>CXCL13,<\/i> <i>CXCL9,<\/i> <i>CCL19,<\/i> <i>CD3E, <\/i>and <i>CD79A <\/i>were upregulated in the sTIL-high group (logFC &#62; 2, p &#60; 4e-9). GSEA identified interferon &#947; and &#945; response and allograft rejection signatures in TLS- and sTIL-high groups (p = 0.006, NES &#62; |2.5|). sTIL-high samples expressed high levels of E2F targets, while the sTIL-low group was enriched with myogenesis and epithelial-mesenchymal transition gene sets.<br \/>The TLS-high group was enriched in the TLS Fges cluster (p = 1e-5) and contained high B, CD4<sup>+<\/sup> T, and CD8<sup>+<\/sup> T cell content (p &#60; 2e-4). sTIL samples expressed high levels of B, CD4<sup>+ <\/sup>T, CD8<sup>+<\/sup> T, and myeloid cells (p &#60; 0.001) and TLS and myeloid clusters (p &#60; 1e-5). TGF&#946; and VEGF pathways were more active in sTIL-low samples (p &#60; 0.001), while JAK-STAT was most active in the sTIL-high group (p = 0.0006). In the basal subtype (p &#60; 0.001), the TLS-high group was associated with <i>NOTCH2<\/i> amplification; the sTIL-low group had increased <i>NRG1<\/i> deletions; and the sTIL-high group contained <i>BRCA2<\/i> mutations.<br \/>Conclusions: RNA-based methods used were concordant with AI-based methods of TLS and sTIL detection. Our CNN-based method of identifying immune structures in the TME with morphological features on H&#38;E WSIs may automate traditional pathology workflows with additional validation.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-05 Integrative cancer science,,"},{"Key":"Keywords","Value":"Breast cancer,RNA sequencing,Tumor microenvironment,Tumor infiltrating lymphocytes,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Nadezhda Lukashevich<sup><\/sup>, Vladimir Kushnarev<sup><\/sup>, Daniil Dymov<sup><\/sup>, Anastasia Zotova<sup><\/sup>, Anna Belozerova<sup><\/sup>, Ivan Valiev<sup><\/sup>, Lev Popyvanov<sup><\/sup>, Anna M. Love<sup><\/sup>, Nathan Fowler<sup><\/sup>, Alexander Bagaev<sup><\/sup>, <b>Ekaterina Postovalova<\/b><sup><\/sup><br><br\/>BostonGene, Corp., Waltham, MA","CSlideId":"","ControlKey":"c72a3788-7b54-44a6-9b4d-a75bd1bb2250","ControlNumber":"2253","DisclosureBlock":"<b>&nbsp;N. Lukashevich, <\/b> <br><b>BostonGene, Corp.<\/b> Employment. <br><b>V. Kushnarev, <\/b> <br><b>BostonGene, Corp.<\/b> Employment, Stock Option. <br><b>D. Dymov, <\/b> <br><b>BostonGene, Corp.<\/b> Employment. <br><b>A. Zotova, <\/b> <br><b>BostonGene, Corp.<\/b> Employment, Patent. <br><b>A. Belozerova, <\/b> <br><b>BostonGene, Corp.<\/b> Employment. <br><b>I. Valiev, <\/b> <br><b>BostonGene, Corp.<\/b> Employment, Stock Option, Patent. <br><b>L. Popyvanov, <\/b> <br><b>BostonGene, Corp.<\/b> Employment. <br><b>A. M. Love, <\/b> <br><b>BostonGene, Corp.<\/b> Employment. <br><b>N. Fowler, <\/b> <br><b>BostonGene, Corp.<\/b> Employment, Stock Option. <br><b>Roche<\/b> Grant\/Contract, Other, Consulting. <br><b>Gilead<\/b> Grant\/Contract, Other, Consulting. <br><b>CelGene<\/b> Grant\/Contract, Other, Consulting. <br><b>A. Bagaev, <\/b> <br><b>BostonGene, Corp.<\/b> Employment, Stock Option, Patent. <br><b>E. Postovalova, <\/b> <br><b>BostonGene, Corp.<\/b> Employment, Stock Option, Patent.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8120","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"26","PosterboardNumber":"27","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5444","PresenterBiography":null,"PresenterDisplayName":"Ekaterina Postovalova, PhD","PresenterKey":"8df38f0f-cdac-42d3-884c-ffd3e1e03977","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5444. Integrated analysis of gene expression signatures and AI-based detection of tertiary lymphoid structures and stromal tumor-infiltrating lymphocytes in breast cancer H&#38;E samples","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Integrated analysis of gene expression signatures and AI-based detection of tertiary lymphoid structures and stromal tumor-infiltrating lymphocytes in breast cancer H&#38;E samples","Topics":null,"cSlideId":""},{"Abstract":"Background: The spatial intratumor heterogeneity (ITH) is widely acknowledged as driving therapeutic response and providing fuel for drug resistance. Currently, patient selection for immunotherapy is driven mostly by PD-1\/PD-L1 based IHC tests and mutational analysis. These oversimplified approaches fail to predict the risk of recurrence, therapeutic response and drug resistance with high accuracy. We hypothesize that functional responses of heterogeneous non-random spatial arrangements of tumor, stromal and immune cells in the tumor microenvironment are determined by distinct combinations of their internal states and spatial interactions within neighborhoods. The interactions generate distinct cell-cell communication networks forming functional spatial configurations of cells, termed microdomains, as organizational units of spatial ITH. Deriving the spatial networks within each microdomain with unbiased spatial analytics and the underlying network biology through explainable AI, is key to understanding tumor initiation, tumor progression, and response to therapy.<br \/>Problem: There has been an explosion of spatial imaging technologies using immunofluorescence and\/or mass spectrometry for intact tissues measuring protein expressions, DNA and RNA probes. To extract high-value knowledge from these multiplexed datasets, a key first step is to segment cells accurately. Despite decades of research, this step remains elusive due to imaging artifacts arising from issues with tile stitching, incorrect registration, signal oversaturation, non-uniform illumination, poor or high-background nuclei signal, defocus, varying cell and nuclear shapes, fluorescence emission efficiency variation, overlapping and\/or superimposed nuclei and low resolution (e.g., mass cytometry). Those artifacts may lead to incorrect cell phenotypes, incomplete cell phenotype atlases, and missing rare cell, fusion cell or transition cell types.<br \/>Solution: We present TumorMapr&#8482;, a segmentation-free, unbiased spatial analytics and explainable AI platform that extracts information and creates knowledge from patient disease pathology samples imaged with any technology including fluorescence, mass spectrometry etc.<br \/>Results: We apply TumorMapr on hyperplexed immunofluorescence dataset of colorectal cancer and hyperplexed imaging mass cytometry dataset of triple negative breast cancer to discover functional cell prototypes involving spatial collections of neighboring pixels highly predictive of disease progression and response to therapy, tumor promoting and tumor restraining microdomains and microdomain-specific network biology predictive of disease outcomes. We further compare these results with segmentation-based approaches to showcase the discovery of novel cell prototypes.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology ,,"},{"Key":"Keywords","Value":"Breast cancer,,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Filippo Pullara<\/b><sup><\/sup>, Brian Falkenstein<sup><\/sup>, Bruce Campbell<sup><\/sup>, Samantha Panakkal<sup><\/sup>, Akif Burak Tosun<sup><\/sup>, Jeffrey Fine<sup><\/sup>, S. Chakra Chennubhotla<sup><\/sup><br><br\/>SpIntellx, Inc., Pittsburgh, PA","CSlideId":"","ControlKey":"31d41512-e13d-439d-8d32-a2ab00ecaa2f","ControlNumber":"7752","DisclosureBlock":"<b>&nbsp;F. Pullara, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment. <br><b>B. Falkenstein, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment. <br><b>B. Campbell, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment. <br><b>S. Panakkal, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment. <br><b>A. B. Tosun, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment. <br><b>J. Fine, <\/b> <br><b>SpIntellx, Inc.<\/b> Stock Option, co-founder. <br><b>S. Chennubhotla, <\/b> <br><b>SpIntellx, Inc.<\/b> Employment.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8121","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"27","PosterboardNumber":"28","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5445","PresenterBiography":null,"PresenterDisplayName":"Filippo Pullara, PhD","PresenterKey":"13fb68f9-18c6-429a-9a29-b5d422b0eadb","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5445. Segmentation-free analysis of multiplexed images with unbiased spatial analytics and explainable AI for predicting disease outcomes","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Segmentation-free analysis of multiplexed images with unbiased spatial analytics and explainable AI for predicting disease outcomes","Topics":null,"cSlideId":""},{"Abstract":"Introduction: Deep learning-based H&#38;E slide analyzer, Lunit-SCOPE IO can classify the tumor microenvironment as three immune phenotypes (IPs): inflamed, immune-excluded and immune-desert. In our previous study, the IPs demonstrated distinct survival outcome and immunologic landscape in endometrial cancer. To further explore the application of IPs in other type of cancer, we applied Lunit-SCOPE in ovarian cancer (OV) and compared tumor microenvironments based on the IPs.<br \/>Methods: H&#38;E slide images, RNA-sequencing data, and clinical data were obtained from TCGA OV cohort. Lunit-SCOPE IO is a H&#38;E slide analyzer using deep learning algorithm and was trained with 1,824 H&#38;E slides of advanced NSCLC. We used the analyzer to classify H&#38;E slide images from TCGA OV cohort to three IPs. Cibersort was used to assess immune cell infiltration across the IPs. The cytolytic activity score was obtained from geometric mean of GZMA and PRF1 RNA expression. We further assessed transcriptomic characteristics across IPs via differentially expressed genes analysis and gene set enrichment analysis (GSEA). Additionally, we compared CD274 gene expression across IPs. Finally, survival analysis was performed to evaluate survival outcome based on IPs. We used Mann-Whitney method to compare non-parametric variables between the IPs.<br \/>Results: The proportion of inflamed, immune-excluded and immune-desert group in TCGA OV were 7 (10.2%), 13 (18.8%), and 49 (71%), respectively. Inflamed group showed significantly higher proportion of M1 macrophage compared with immune-desert group (6.6% vs. 2%, P=.012). We observed higher cytolytic activity score in inflamed group compared to immune-desert group (7.21 vs. 5.27, P=.016). In GSEA, inflamed group is significantly enriched in IL6 JAK STAT3 signaling, interferon gamma response, KRAS signaling up, and inflammatory response pathway (NES 2.19; adjusted P=.021, NES 1.70; adjusted P=.021, NES 1.62; adjusted P=.037, and NES 1.52; adjusted P=.037, respectively). Immune-desert is related to upregulated MYC target V2 pathway (NES -1.95; adjusted P=.037). Inflamed group did not show significant difference in CD274 expression, compared with others (Inflamed vs. immune-excluded, 4.97 vs. 4.19, P=.115 and Inflamed vs. immune-desert, 4.97 vs. 3.95, P=.058). Inflamed group did not show any significant difference in overall survival, compared with non-inflamed group (Inflamed vs. non-inflamed, HR 0.98; 95% CI 0.45 - 2.14; P=.958).<br \/>Conclusion: Deep learning-based H&#38;E slide analyzer can be used to classify tumor H&#38;E slide images with OV into three IPs. In this study, the classification demonstrated distinct immunologic traits and transcriptomic characteristics in tumor microenvironment. The enrichment of interferon gamma response pathway in inflamed OV group may indicate opportunities for targeted immunotherapy.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology ,,"},{"Key":"Keywords","Value":"Deep learning,Ovarian cancer,Tumor infiltrating lymphocyte,Digital pathology,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Horyun Choi<\/b><sup>1<\/sup>, Youjin Oh<sup>2<\/sup>, Chan-Young Ock<sup>3<\/sup>, Kyunghyun Paeng<sup>3<\/sup>, Young Kwang Chae<sup>2<\/sup><br><br\/><sup>1<\/sup>University of Hawaii John A. Burns School of Medicine, Honolulu, HI,<sup>2<\/sup>Northwestern University Feinberg School of Medicine, Chicago, IL,<sup>3<\/sup>Lunit, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"7a6c01ba-e3d8-4fa4-9800-ac545683a408","ControlNumber":"5979","DisclosureBlock":"&nbsp;<b>H. Choi, <\/b> None..<br><b>Y. Oh, <\/b> None.&nbsp;<br><b>C. Ock, <\/b> <br><b>Lunit<\/b> Employment, Stock. <br><b>K. Paeng, <\/b> <br><b>Lunit<\/b> Employment, Stock. <br><b>Y. Chae, <\/b> <br><b>Lunit<\/b> Other, Honoraria\/Advisory Boards. <br><b>Abbvie<\/b> Other, Research Grant. <br><b>BMS<\/b> Other, Research Grant. <br><b>Biodesix<\/b> Other, Research Grant, Honoraria\/Advisory Boards. <br><b>Lexent Bio<\/b> Other, Research Grant. <br><b>Freenome<\/b> Other, Research Grant. <br><b>Roche\/Genentech<\/b> Other, Honoraria\/Advisory Boards. <br><b>AstraZeneca<\/b> Other, Honoraria\/Advisory Boards. <br><b>Foundation Medicine<\/b> Other, Honoraria\/Advisory Boards. <br><b>Counsyl<\/b> Other, Honoraria\/Advisory Boards. <br><b>Neogenomics<\/b> Other, Honoraria\/Advisory Boards. <br><b>Guardant Health<\/b> Other, Honoraria\/Advisory Boards. <br><b>Boehringher Ingelheim<\/b> Other, Honoraria\/Advisory Boards. <br><b>Immuneoncia<\/b> Other, Honoraria\/Advisory Boards. <br><b>Lilly Oncology<\/b> Other, Honoraria\/Advisory Boards. <br><b>Merck<\/b> Other, Honoraria\/Advisory Boards. <br><b>Takeda<\/b> Other, Honoraria\/Advisory Boards. <br><b>Jazz Pharmaceutical<\/b> Other, Honoraria\/Advisory Boards. <br><b>Tempus<\/b> Other, Honoraria\/Advisory Boards.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8122","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"28","PosterboardNumber":"29","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5446","PresenterBiography":null,"PresenterDisplayName":"Horyun Choi, MD","PresenterKey":"da6d71e7-70fc-4a6a-836b-7d9cee31ded8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5446. Immune phenotypes classified by deep learning-based H&#38;E tissue analyzer demonstrate distinct immune landscape and transcriptomic features in ovarian cancer","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Immune phenotypes classified by deep learning-based H&#38;E tissue analyzer demonstrate distinct immune landscape and transcriptomic features in ovarian cancer","Topics":null,"cSlideId":""},{"Abstract":"<b>Background: <\/b>Many cancers are known to involve a desmoplastic stromal reaction. While cancer-associated stroma (CAS) has long been appreciated histologically, single-cell molecular analyses have revealed its heterogeneity, and the cellular composition of CAS has been linked to prognosis in several cancer types, including NSCLC. While pathologists have sought to manually classify CAS based on collagen architecture or nuclear density, this approach has not sufficiently captured the heterogeneity of CAS. To this end, we have developed an artificial intelligence (AI)-based model to predict stromal composition in NSCLC from hematoxylin and eosin (H&#38;E)-stained tissue.&nbsp;<br \/><b>Methods: <\/b>We developed a convolutional neural network-based model to classify CAS as immature, mature, densely inflamed, densely fibroblastic, or elastosis. This model was trained using manual pathologist-derived annotations (N=3019) of H&#38;E-stained whole slide images (WSIs) of PDAC obtained from the TCGA (N=126). This stromal subdivision model was deployed on H&#38;E-stained LUAD (N=468) and LUSC (N=430) WSIs. Model performance was assessed by qualitative review by expert pathologists. Human interpretable features (HIFs) were extracted from the stromal subdivision model (e.g., proportional area of mature relative to total stroma) and were assessed to identify associations with overall survival (OS) using univariate Cox regression analysis after adjusting for age, sex, and tumor stage.<br \/><b>Results: <\/b>The stromal subdivision model successfully predicted areas of immature, mature, densely inflammatory, and densely fibrotic stroma, as well as elastosis, in LUAD and LUSC. In LUAD, higher combined proportional areas of mature and fibroblastic stroma relative to total cancer stroma was associated with poor OS (p=0.007), while higher combined proportional areas of densely inflamed stroma and elastosis relative to total cancer stroma was associated with improved OS (p=0.007). These findings were validated by stratified tertile analysis based on the corresponding risk direction. Notably, while the average stromal compositions did not differ significantly between NSCLC subtypes, the stromal HIFs were only prognostic in LUAD but not in LUSC.<br \/><b>Conclusions: <\/b>We developed a first of its kind model to characterize CAS subtypes in NSCLC tissue. Features extracted from this model are related to prognosis in LUAD, but not in LUSC, further confirming the importance of CAS to tumor biology and the importance of considering histologic subtypes. Work is ongoing to identify relationships between stromal HIFs and treatment response in NSCLC as well as other cancer indications.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS02-02 Digital pathology ,,"},{"Key":"Keywords","Value":"Tumor microenvironment,Stroma,Image analysis,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Fedaa Najdawi<\/b><sup><\/sup>, Sandhya Srinivasan<sup><\/sup>, Neel Patel<sup><\/sup>, Michael G. Drage<sup><\/sup>, Christian Kirkup<sup><\/sup>, Chintan Parmar<sup><\/sup>, Jacqueline Brosnan-Cashman<sup><\/sup>, Michael Montalto<sup><\/sup>, Andrew H. Beck<sup><\/sup>, Archit Khosla<sup><\/sup>, Ilan Wapinski<sup><\/sup>, Ben Glass<sup><\/sup>, Murray Resnick<sup><\/sup>, Matthew Bronnimann<sup><\/sup><br><br\/>PathAI, Inc., Boston, MA","CSlideId":"","ControlKey":"c6757573-0529-4489-9096-87bcb2db769d","ControlNumber":"5099","DisclosureBlock":"<b>&nbsp;F. Najdawi, <\/b> <br><b>PathAI<\/b> Employment. <br><b>S. Srinivasan, <\/b> <br><b>PathAI<\/b> Employment. <br><b>N. Patel, <\/b> <br><b>PathAI<\/b> Employment. <br><b>M. G. Drage, <\/b> <br><b>PathAI<\/b> Employment. <br><b>C. Kirkup, <\/b> <br><b>PathAI<\/b> Employment. <br><b>nference, Inc.<\/b> Employment. <br><b>C. Parmar, <\/b> <br><b>PathAI<\/b> Employment. <br><b>Novartis<\/b> Employment. <br><b>J. Brosnan-Cashman, <\/b> <br><b>PathAI<\/b> Employment. <br><b>M. Montalto, <\/b> <br><b>PathAI<\/b> Employment. <br><b>A. H. Beck, <\/b> <br><b>PathAI<\/b> Employment. <br><b>A. Khosla, <\/b> <br><b>PathAI<\/b> Employment. <br><b>I. Wapinski, <\/b> <br><b>PathAI<\/b> Employment. <br><b>B. Glass, <\/b> <br><b>PathAI<\/b> Employment. <br><b>M. Resnick, <\/b> <br><b>PathAI<\/b> Employment. <br><b>M. Bronnimann, <\/b> <br><b>PathAI<\/b> Employment. <br><b>Roche<\/b> Employment.","End":"4\/18\/2023 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"8123","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"29","PosterboardNumber":"30","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"5447","PresenterBiography":null,"PresenterDisplayName":"Fedaa Najdawi, Unknown","PresenterKey":"2f29253f-7672-4e28-a023-a81ea61baf0b","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"5447. Artificial intelligence (AI)-based classification of stromal subtypes reveals associations between stromal composition and prognosis in NSCLC","SearchResultFooter":"","SearchResultHeader":"Apr 18 2023  1:30PM","SessionId":"306","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence: From Pathomics to Radiomics","ShowChatLink":"false","Start":"4\/18\/2023 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Artificial intelligence (AI)-based classification of stromal subtypes reveals associations between stromal composition and prognosis in NSCLC","Topics":null,"cSlideId":""}]