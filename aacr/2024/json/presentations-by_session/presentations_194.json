[{"Abstract":"Recent advancements in generative AI, including models such as GPT-4 and LLAMA2, have been rapidly integrated into cancer research. Cellformatica, Inc. has developed a pipeline designed to enhance the accuracy of functional and genomic drug target discovery screens by reducing the incidence of false positives and refining the interpretation process. This pipeline is capable of conducting comprehensive investigations, including genome-wide analyses, and is accessible via web and API interfaces. At the core of the pipeline is the use of the extensive global corpus of scientific literature to assess the relevance of each gene within the context defined by the experimental design of the screen. To address the issue of AI-generated inaccuracies, often referred to as 'hallucinations,' the pipeline incorporates a custom-tuned language model (LLM) component within the generative AI framework. This fine-tuning process is specifically tailored to the gene set under investigation. The pipeline's multi-agent architecture is a distinctive feature. It scores candidates based on three orthogonally-tuned criteria: effectiveness, confidence, and novelty. In benchmarking tests, this multi-agent scoring system has outperformed GPT-4 and has proven particularly adept at identifying candidate targets that may have been overlooked in previous research. These candidates are recognized for their significant therapeutic potential and are corroborated by existing scientific findings. The versatility of the Cellformatica pipeline is demonstrated through its application in three distinct areas of cancer research. First, it has been employed to optimize chimeric antigen receptor (CAR) T-cell therapies, a form of immunotherapy for cancer treatment. Second, the pipeline has been used to elucidate the network of chemotactic molecules that orchestrate immune cell infiltration and tissue remodeling in the lungs of patients with COVID-19. Third, it has been used to spatially define signaling pathways in humanized xenograft murine tumor experiments, for which existing cross-species database knowledge is limited. These applications underscore the pipeline's potential to contribute to the understanding and treatment of complex diseases.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Drug-discovery screen,Target discovery,Deep learning,Systems biology,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"A. Rech<sup>1<\/sup>, <b>Y. Goltsev<\/b><sup>2<\/sup>, N. Samusik<sup>2<\/sup>, A. Kaznadzey<sup>2<\/sup>; <br\/><sup>1<\/sup>University of Pennsylvania, Philadelphia, PA, <sup>2<\/sup>Cellformatica, Inc., Menlo Park, CA","CSlideId":"","ControlKey":"34291ca9-00b5-4e1b-a1a6-0dc9828b0417","ControlNumber":"8466","DisclosureBlock":"&nbsp;<b>A. Rech, <\/b> None..<br><b>Y. Goltsev, <\/b> None..<br><b>N. Samusik, <\/b> None..<br><b>A. Kaznadzey, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9366","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"1","PosterboardNumber":"1","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3509","PresenterBiography":null,"PresenterDisplayName":"Yury Goltsev","PresenterKey":"029beea1-9f40-4f08-be0a-81f9b723dc8e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3509. Using generative AI for filtering and comprehension of drug target discovery screen results","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Using generative AI for filtering and comprehension of drug target discovery screen results","Topics":null,"cSlideId":""},{"Abstract":"Background: Triple-negative breast cancer (TNBC) is an aggressive disease that accounts for 15-20% of all breast cancers. Expressions of ER, PR and HER2 receptors are lacking in this disease, and thus targeted therapies are not effective. TNBC has a shorter relapse-free survival, higher metastasis rate and decreased overall survival compared with other breast cancers. However, when undergoing standard treatment, some patients respond well, while others have poor outcome, suggesting TNBC heterogeneity. Early stratification of patients with long versus short survival could identify the subgroup of patients who would not benefit from exposure to toxicity of chemotherapy treatment. Here, we developed a non-invasive radiogenomic approach for TNBC risk stratification.<br \/>Methods: A transcriptomic-based prognostic gene signature was previously developed using the TCGA-BRCA cohort (n=860). Briefly, LASSO Cox regression model analysis with the &#8216;glmnet&#8217; R package was used to identify the transcriptomic signature gene-set consisting of 50 genes. We tested this signature to prognosticate overall survival in a Stanford cohort (n=63) and a previously published SCANB cohort (n=604). The patients were stratified into high- and low-risk groups based on the median risk-score. Next, we developed a machine learning model that identified a radiomic feature set to predict the prognostic transcriptomic risk-groups. Radiomic features were extracted from pre-treatment breast MRI. Radiomics features were extracted using PyRadiomics. The model utilized Decision Tree Classifier and LeaveOneOut method was used for cross-validation.<br \/>Results: The transcriptomic signature low-risk group was significantly associated with improved overall survival in the two TNBC cohorts, with hazard ratios of 0.11 [95% CI: 0.01-0.88] for the Stanford cohort and 0.71 [95% CI: 0.52-0.97] for the SCANB cohort (log-rank p-values p=0.012 and p=0.032, respectively). Including this transcriptomic signature in a multivariate analysis, which adjusted for clinical features (patient age, grade, stage and Ki67%), the transcriptomic prognostic signature remained a significant prognostic factor (p&#60;0.05). The radiomic feature set (consisting of 20 features) predicted the high- and low-risk transcriptomic groups with a mean accuracy of 72.2% and a mean AUROC of 71%. The precision, F1 and recall scores were 67%, 74% and 82%, respectively. In an independent dataset consisting of 116 Stanford TNBC patients, we used this model to predict risk groups based on the MRI radiomics features, and evaluated the prognostic effects of predicted risk groups. The overall survival of the predicted high-risk group was significantly poorer than the predicted low-risk group (p=0.013).<br \/>Conclusions: We present a prognostic model that can non-invasively stratify TNBC patients for low versus high mortality risk using radiomic features derived from pre-treatment patient MRI data.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Triple-negative breast cancer (TNBC),Magnetic resonance imaging,Prognostic markers,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>H. Noor<\/b><sup>1<\/sup>, Y. Zheng<sup>1<\/sup>, A. Mantz<sup>1<\/sup>, R. Zhou<sup>1<\/sup>, A. Kozlov<sup>2<\/sup>, W. B. DeMartini<sup>1<\/sup>, S.-t. Chen<sup>3<\/sup>, S. Okamoto<sup>4<\/sup>, D. Ikeda<sup>1<\/sup>, S. Mattonen<sup>5<\/sup>, S. Napel<sup>1<\/sup>, M. L. Telli<sup>1<\/sup>, G. Sledge<sup>1<\/sup>, A. Kurian<sup>1<\/sup>, M. Satoyoshi<sup>1<\/sup>, O. Gevaert<sup>1<\/sup>, H. Itakura<sup>1<\/sup>; <br\/><sup>1<\/sup>Stanford University School of Medicine, Stanford, CA, <sup>2<\/sup>University of Utah, Utah, UT, <sup>3<\/sup>Department of Diagnostic Radiology, Chang Gung Memorial Hospital, Taiwan, Taiwan, <sup>4<\/sup>St. Marianna University School of Medicine, Kawasaki, Japan, <sup>5<\/sup>Western University, London, ON, Canada","CSlideId":"","ControlKey":"d6788a54-6b67-419f-accd-084f292cbac5","ControlNumber":"867","DisclosureBlock":"&nbsp;<b>H. Noor, <\/b> None..<br><b>Y. Zheng, <\/b> None..<br><b>A. Mantz, <\/b> None..<br><b>R. Zhou, <\/b> None..<br><b>A. Kozlov, <\/b> None..<br><b>W. B. DeMartini, <\/b> None..<br><b>S. Chen, <\/b> None..<br><b>S. Okamoto, <\/b> None..<br><b>D. Ikeda, <\/b> None..<br><b>S. Mattonen, <\/b> None..<br><b>S. Napel, <\/b> None..<br><b>M. L. Telli, <\/b> None..<br><b>G. Sledge, <\/b> None..<br><b>A. Kurian, <\/b> None..<br><b>M. Satoyoshi, <\/b> None..<br><b>O. Gevaert, <\/b> None..<br><b>H. Itakura, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9367","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"2","PosterboardNumber":"2","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3510","PresenterBiography":null,"PresenterDisplayName":"Humaira Noor, M Eng,M Phil,PhD","PresenterKey":"56d1d7ee-692a-428e-bcaa-e5965893bcca","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3510. A radiogenomic approach for triple-negative breast cancer risk stratification","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A radiogenomic approach for triple-negative breast cancer risk stratification","Topics":null,"cSlideId":""},{"Abstract":"Problem: This 21st century has produced an eruption of research using AI for the detection and diagnosis of cancer. Yet, an often-unspoken core premise in this field of computational pathology is that a glass slide suitably represents the patient&#8217;s disease. Here, we report systematic confounds<\/u> may dominate slides from a medical center, such that slides are <u>unsuitable for diagnosis<\/u>.<br \/>Methods: We mathematically define high quality data as a whole slide image set where the <u>patient&#8217;s surgery may be accurately predicted<\/u> by an automated system. Our system &#8220;iQC&#8221; accurately distinguished biopsies (i.e. thin strands of tissue) from nonbiopsies, e.g. transurethral resections (TURPs) or prostatectomies, only when the data appeared high quality, e.g. bright histopathology stains and few artifacts. Thus, when the data are of high quality, iQC (i) accurately classifies pixels as tissue, (ii) accurately generates stats that describe the distribution of tissue, and (iii) accurately predicts surgical procedure from those stats. We compare iQC against the published HistoQC tool.<br \/>Results: iQC holds all data to the same objective quality standard. We validate this standard in five Veterans Affairs Medical Centers (VAMCs) and the public Automated Gleason Grading Challenge (AGGC) dataset. For the <u>surgery prediction task, we report an AUROC of 0.9966-1.000 at VAMCs<\/u> that produced high quality data and <u>AUROC=0.9824 for AGGC<\/u>. In contrast, we report <u><u>AUROC=0.7115 at the VAMC that produced poor quality data<\/u>. A pathologist found poor quality may be explained by faded histopathology stains and VAMC protocol differences. Supporting this, iQC's novel stain strength statistic finds this VAMC had weaker stains (p &#60; 2.2e-16, two-tailed Wilcoxon rank-sum test; Cohen's d=1.208) than the VAMC that contributed most of the slides. Additionally, iQC recommended only 2 of 3736 (0.005%) VAMC slides for review due to inadequate tissue. In contrast, HistoQC in its default configuration excluded 89.9% of VAMC slides because tissue was not detected, but we reduced this to 16.7% with our custom HistoQC configuration.<br \/>Conclusion: Our surgery prediction AUROC may be a quantitative indicator positively associated with data quality for a dataset. Unless data are poor quality, iQC accurately locates tissue in slides and excludes few slides. iQC is, to our knowledge, the <u>first automated system in computational pathology that validates quality against objective evidence<\/u>, e.g. surgical procedure data available in the EHR\/LIMS, which requires <u>no efforts or annotations from anatomic pathologists<\/u>.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Prostate cancer,Image analysis,Surgical resection,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>A. J. Schaumberg<\/b><sup>1<\/sup>, M. S. Lewis<sup>2<\/sup>, R. Nazarian<sup>2<\/sup>, A. Wadhwa<sup>2<\/sup>, N. Kane<sup>2<\/sup>, G. Turner<sup>1<\/sup>, P. Karnam<sup>1<\/sup>, P. Devineni<sup>1<\/sup>, N. Wolfe<sup>1<\/sup>, R. Kintner<sup>1<\/sup>, M. B. Rettig<sup>2<\/sup>, B. S. Knudsen<sup>3<\/sup>, I. P. Garraway<sup>2<\/sup>, S. Pyarajan<sup>1<\/sup>; <br\/><sup>1<\/sup>VA Boston Healthcare System, Boston, MA, <sup>2<\/sup>VA Greater Los Angeles Medical Center, Los Angeles, CA, <sup>3<\/sup>University of Utah, Salt Lake City, UT","CSlideId":"","ControlKey":"641e3d00-b6fe-4540-ab2f-0062fdbac309","ControlNumber":"924","DisclosureBlock":"&nbsp;<b>A. J. Schaumberg, <\/b> None..<br><b>M. S. Lewis, <\/b> None..<br><b>R. Nazarian, <\/b> None..<br><b>A. Wadhwa, <\/b> None..<br><b>N. Kane, <\/b> None..<br><b>G. Turner, <\/b> None..<br><b>P. Karnam, <\/b> None..<br><b>P. Devineni, <\/b> None..<br><b>N. Wolfe, <\/b> None..<br><b>R. Kintner, <\/b> None..<br><b>M. B. Rettig, <\/b> None..<br><b>B. S. Knudsen, <\/b> None..<br><b>I. P. Garraway, <\/b> None..<br><b>S. Pyarajan, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9368","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"3","PosterboardNumber":"3","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3511","PresenterBiography":null,"PresenterDisplayName":"Andrew Schaumberg, PhD","PresenterKey":"6547ae15-1092-44e8-9a0f-184f9c18388b","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3511. iQC: machine-learning-driven prediction of surgery reveals systematic confounds in cancer whole slide images from hospitals by protocol","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"iQC: machine-learning-driven prediction of surgery reveals systematic confounds in cancer whole slide images from hospitals by protocol","Topics":null,"cSlideId":""},{"Abstract":"Metabolites play a crucial role in the functioning of biological systems. Measurements of metabolite abundances by metabolomics and metabolic pathway activity by isotope-tracing are powerful approaches to study metabolic phenotypes. However, large-scale measurements of metabolite levels and pathway activity remain extremely scarce due to the technical challenges. Motivated by the strength of RNA-metabolite covariation, we present UnitedMet, a Bayesian probabilistic method for end-to-end joint modeling of RNA-sequencing and metabolic datasets that is capable of dimensionality reduction, data integration and metabolic modality prediction. UnitedMet demonstrates high accuracy predicting metabolite levels and isotopologue distributions from gene expression data in human tumor samples. To evaluate UnitedMet&#8217;s efficacy in clinical applications, we inferred metabolomic profiles and isotope labeling patterns from the RNA sequencing data of clear cell renal cell carcinoma (ccRCC) patients enrolled in TCGA and clinical trials. Correlation analysis between genetic mutations and predicted metabolic phenotypes revealed that BAP1 mutations were associated with increased contribution of glucose to TCA cycle in ccRCC. Increased TCA cycle activity was found to be associated with disease progression and poorer clinical outcome. UnitedMet, therefore, provides a solution that could be broadly applicable to enhance multimodal metabolomic datasets and facilitates comprehensive study of interplays between metabolic profiles, molecular alterations and human phenotypes.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Metabolomics,Machine learning,Cancer metabolism,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>A. X. Xie<\/b>, C. Bradshaw, C. Tosh, W. Tansey, E. Reznik; <br\/>Memorial Sloan Kettering Cancer Center, New York, NY","CSlideId":"","ControlKey":"8dcd0363-15d2-4d19-bf6d-50c2a30f5a97","ControlNumber":"1348","DisclosureBlock":"&nbsp;<b>A. X. Xie, <\/b> None..<br><b>C. Bradshaw, <\/b> None..<br><b>C. Tosh, <\/b> None..<br><b>W. Tansey, <\/b> None..<br><b>E. Reznik, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9369","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"4","PosterboardNumber":"4","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3512","PresenterBiography":null,"PresenterDisplayName":"Amy Xie","PresenterKey":"b0260389-e85f-4247-b537-8fd253291871","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3512. Joint probabilistic modeling of multimodal metabolic data with UnitedMet","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Joint probabilistic modeling of multimodal metabolic data with UnitedMet","Topics":null,"cSlideId":""},{"Abstract":"MicroRNAs play a crucial role in post-transcriptional regulation, influencing over 60% of human protein-coding genes by targeting specific mRNA sites to suppress protein translation. Various predictive algorithms aim to discern potential microRNA-mRNA pairs. Current approaches primarily employ sequence alignment, machine learning, and deep learning, yet encounter challenges such as complex data pre-processing, time-consuming model generation, and limited binding site precision. Additionally, some methods rely on inefficient RNN-based models, resulting in sluggish predictions. To address these issues, we proposed a CNN-based algorithm combined with transfer learning for direct and precise prediction of microRNA-mRNA binding sites, eliminating the need for extensive preprocessing. We introduced two models in this study: the per-based model and the miRNA-target binding decision model. The former screens potential target sites on 3&#8217;-UTR sequences, while the latter guides the decision-making process for miRNA-target pairs. The per-based model utilized a public database, extracting 786,447 human microRNA-mRNA pairs verified by CLIP-seq. It employed sequence alignment approaches to determine putative binding sites and per-base binding states. MicroRNA sequences and seed regions served as the initial convolutional kernels in the deep learning model, combined with encoded full-length 3&#8217;-UTR sequences of mRNAs as inputs for the fine-tuned U-Net architecture. For the miRNA-target binding decision model, we excluded the per-based model's decoder and initialized a new classification layer for target-site prediction. Leveraging experimental validation datasets from public databases, we extracted 2,846 binding and 1,058 non-binding human microRNA-mRNA pairs. The pre-trained model was fine-tuned on these 3,904 pairs. Both models underwent training with cycle learning rate, focal loss, gradient clipping, and weighted decay to address dataset imbalances. The dataset was split into 80% training and 20% testing data, with balanced accuracy as the evaluation metric. The per-based model achieved a robust 82.14% balanced accuracy on the test data, excelling in handling imbalanced datasets in per-based tasks. It swiftly and accurately identified nucleotide binding states. The miRNA-target binding decision model outperformed existing methods with a balanced accuracy of 80.39% on the test data. In contrast to many deep learning methods requiring additional preprocessing, our algorithm directly predicts per-base binding states from full-length sequences. It seamlessly transfers knowledge from the per-based to the miRNA-target model. Importantly, our approach relies solely on seed regions, eliminating the need for prior knowledge and enhancing microRNA target prediction reliability. This advancement holds promise for biomedical and clinical researchers, offering valuable insights.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"MicroRNA,mRNA,Deep learning,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>C.-H. Peng<\/b><sup>1<\/sup>, H.-Y. Chen<sup>1<\/sup>, D.-C. Cheng<sup>1<\/sup>, E. Chuang<sup>2<\/sup>, C.-Y. Lee<sup>3<\/sup>; <br\/><sup>1<\/sup>China Medical University, Taichung City, Taiwan, <sup>2<\/sup>National Taiwan University, Taipei, Taiwan, <sup>3<\/sup>National Taipei University of Technology, Taipei City, Taiwan","CSlideId":"","ControlKey":"52161425-d17a-4dac-a14a-ed25374dd785","ControlNumber":"2370","DisclosureBlock":"&nbsp;<b>C. Peng, <\/b> None..<br><b>H. Chen, <\/b> None..<br><b>D. Cheng, <\/b> None..<br><b>E. Chuang, <\/b> None..<br><b>C. Lee, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9370","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"5","PosterboardNumber":"5","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3513","PresenterBiography":null,"PresenterDisplayName":"Chen-Hao Peng, BS","PresenterKey":"e5b4ab33-e55e-449e-b7dc-c281798c2931","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3513. A CNN-based approach with efficient transfer learning improves microRNA-mRNA prediction","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A CNN-based approach with efficient transfer learning improves microRNA-mRNA prediction","Topics":null,"cSlideId":""},{"Abstract":"Tertiary lymphoid structures (TLSs) are ectopic aggregates of a number of immune cells in nonlymphoid tissues under chronically inflamed environments and cancer. Emergence evidence suggested that TLSs were found in diverse cancers and TLSs have been referred as an independently predictive biomarker for immunotherapy response, especially immune checkpoint inhibitors. Moreover, the density and mature status of TLSs often positively associated with the favorable outcomes in cancers. Pancreatic ductal adenocarcinoma (PDAC) is one of the leading causes of cancer-related mortality with low survival rate in the whole world. Here, we developed a multi-resolution machine learning model for detection of TLSs from hema-toxylin and eosin (H&#38;E) stained digital pathology slides as a potential clinical biomarker in PDAC. We selected 120 H&#38;E slides (patients) with a total of 1,896 TLSs manually annotated as immature or mature TLSs by two pathologists. We also used immunohistochemistry (IHC) for CD20 and CD23 markers as a reference standard for H&#38;E-based manual annotations. Our model mainly included detection and segmentation of individual TLSs. First, we used a transformer convolutional neural network to build a classification task to detect the presence of immature or mature TLSs. Then the instance segmentation model was applied to quantify the number of lymphocytes per unit square to validate the presence and maturation of TLSs. F1-score, calculated by the harmonic mean of precision (positive predictive value) and recall (sensitivity), was finally used to quantitatively evaluate the performance of model for each H&#38;E slide. In validation dataset with 250 H&#38;E slides (patients), we selected 50 slides to calculate F1-score, suggesting that our machine learning model achieved high F1-scores for detection and classification of immature TLSs (mean = 0.87, range from 0.79 to 0.95), and mature TLSs (mean = 0.92, range from 0.86 to 0.97). We further stratified 370 PDAC patients into three groups with mature TLSs (23%), immature TLSs (16%), and no TLSs (61%), respectively. Combined the clinical information, survival analysis revealed that patients with mature TLS had better survival outcomes than those without TLS (HR = 0.63; 95% CI, 0.44 - 0.90; P = 0.010). We developed a machine learning model that can accurately detect and classify TLSs in PDAC, and also demonstrated the prognosis value of predictive TLSs in H&#38;E slides by automatedly machine learning model. These data highlight the promise of machine learning model for automated identification and quantification of the TLS on H&#38;E slides in PDAC pathology.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Pancreatic cancer,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>C. Zhao<\/b><sup>1<\/sup>, J. Jia<sup>2<\/sup>, M. Lv<sup>2<\/sup>, J. Feng<sup>1<\/sup>, Y. Wang<sup>1<\/sup>, Y. Liu<sup>1<\/sup>; <br\/><sup>1<\/sup>Renji Hospital affiliated with Shanghai Jiao Tong University School of Medicine, Shanghai, China, <sup>2<\/sup>Shanghai Jiao Tong University, Shanghai, China","CSlideId":"","ControlKey":"4ef8cee3-3911-4533-a6fe-6d73858f708b","ControlNumber":"2413","DisclosureBlock":"&nbsp;<b>C. Zhao, <\/b> None..<br><b>J. Jia, <\/b> None..<br><b>M. Lv, <\/b> None..<br><b>J. Feng, <\/b> None..<br><b>Y. Wang, <\/b> None..<br><b>Y. Liu, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9371","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"6","PosterboardNumber":"6","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3514","PresenterBiography":null,"PresenterDisplayName":"Chaoxian Zhao, PhD","PresenterKey":"48a05e58-78ec-4387-930a-62ae085c3de8","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3514. A deep learning model for detection and characterization of tertiary lymphoid structures in H&#38;E-stained images from pancreatic ductal adenocarcinoma","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A deep learning model for detection and characterization of tertiary lymphoid structures in H&#38;E-stained images from pancreatic ductal adenocarcinoma","Topics":null,"cSlideId":""},{"Abstract":"Introduction: The SynAI solution is an adaptive AI-driven <i>in silico <\/i>drug synergism screening solution aiming to discover the potential therapeutic value of compounds at an early development stage. Given one of both compound inputs in SMILE sequences, SynAI can predict the potential Bliss score of compounds in any given cell line without the need for compound synthesis or structural analysis.The evaluation version of SynAI is accessible at https:\/\/synai.crownbio.com<br \/>Methods: The AI core of SynAI was constructed using the MLP (multi-layer perceptron) network under the PyTorch machine learning framework. The AI core of SynAI was trained against NCI-Almanac and DrugCombDB datasets. In total, these datasets consist of over 12 million <i>in vitro<\/i> synergism tests across 150 cancer cell lines of different origins. On average, each cell line is tested against over 6000 two-compound combinations of FDA-approved cancer drugs. One MLP network was trained for each cell line. Essentially, these networks predict the Bliss score for any combination of SMILE-based feature sets known as molecular fingerprints. The networks were trained against the NCI Almanac set and verified against NCI and DrugCombDB using n-fold cross-validation to avoid model overfitting. During the training, a hyperparameter tuning (HT) study was performed for SynAI and other popular algorithms; allowing an objective comparison of SynAI performances.<br \/>Results: Compared to existing synergism prediction platforms, SynAI yields similar performance in all categories (cf. Table 1) but provides more flexibility for data input using SMILE sequences directly. In addition, the AI core of SynAI can be constantly updated with new inputs from different cell lines and drug combinations. Table 1. Pearson cross correlation (PCC) between measured and predicted Bliss scores of NCI test set<table class=\"AbstractTable\" id=\"{D93ACDFC-5680-43EF-ACF9-4B4C57E2AB2A}\"><caption class=\"AbstractTableCaption\"><\/caption><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>PCC Score<\/b><\/td><td rowspan=\"1\" colspan=\"3\"><b>Cell Lines<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Algorithm<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>MCF7<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>OVCAR-8<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>SK-MEL-5<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>SynAI<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.68 &#177; 0.02<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.56 &#177; 0.07<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>0.86 &#177; 0.02<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">RF<\/td><td rowspan=\"1\" colspan=\"1\">0.64 &#177; 0.02<\/td><td rowspan=\"1\" colspan=\"1\">0.55 &#177; 0.03<\/td><td rowspan=\"1\" colspan=\"1\">0.89 &#177; 0.02<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">GBX<\/td><td rowspan=\"1\" colspan=\"1\">0.66 &#177; 0.02<\/td><td rowspan=\"1\" colspan=\"1\">0.48 &#177; 0.05<\/td><td rowspan=\"1\" colspan=\"1\">0.88 &#177; 0.02<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">RNN<\/td><td rowspan=\"1\" colspan=\"1\">0.54 &#177; 0.12<\/td><td rowspan=\"1\" colspan=\"1\">0.43 &#177; 0.06<\/td><td rowspan=\"1\" colspan=\"1\">0.83 &#177; 0.08<\/td><\/tr><\/table><br \/>Conclusions: Its adaptive and dynamic nature allows SynAI to learn from new data feeds from future studies and has significant potential in reducing the time and cost of synergism screening.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Synergism,Deep learning,Screening,Small molecule drugs,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>K. Yan<\/b><sup>1<\/sup>, R. Jia<sup>2<\/sup>, S. Guo<sup>2<\/sup>; <br\/><sup>1<\/sup>Crown Bioscience, Inc., Leiden, Netherlands, <sup>2<\/sup>Crown Bioscience, Inc., Suzhou, China","CSlideId":"","ControlKey":"a29e22d0-a1f6-4d50-b081-9da6e2924228","ControlNumber":"2466","DisclosureBlock":"&nbsp;<b>K. Yan, <\/b> None..<br><b>R. Jia, <\/b> None..<br><b>S. Guo, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9372","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"7","PosterboardNumber":"7","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3515","PresenterBiography":null,"PresenterDisplayName":"Kuan Yan","PresenterKey":"9577dd16-d6c8-4fac-9283-6e3db1c1c68f","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3515. SynAI: An AI-driven cancer drug synergism prediction platform","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"SynAI: An AI-driven cancer drug synergism prediction platform","Topics":null,"cSlideId":""},{"Abstract":"Introduction: Prostate cancer is the most common cancer in American men and is mainly diagnosed from two-dimensional histology sections. Recently, three-dimensional (3D) prostate histopathology has emerged as a valuable strategy to enhance the understanding of the disease by increasing microscopic sampling of specimens. This strategy enhances the microscopic examination of specimens by facilitating the analysis of the volumetric shape of cells and glands, as well as the pathway structures through entire biopsies and other morphological features. These aspects hold the potential to be linked with biochemical recurrence (BCR) outcomes. This study highlights the potential of features derived from the 3D structure of glands in samples of patients with prostate cancer for identifying patients who are at higher risk of BCR.<br \/>Methods: Radical prostatectomy specimens were collected from 50 patients along with 5-year postoperative BCR follow-up from the University of Washington. A total of 118 <i>ex vivo<\/i> whole-biopsy 3D pathology images were obtained from RP by an open-top light-sheet microscopy platform. Images were converted into a synthetic CK8 immunofluorescence dataset using an image-sequence translation model. From these 3D images, a glandular structure mask was generated by a computer-vision algorithm. The 3D structure of prostate glands was modeled through a Tree-structure Extraction Algorithm for Accurate and Robust Skeletons (TEASER), which provides a simplification of the length of the gland, its shape, and its pathway. 91 features were then extracted from the glandular skeleton architecture. A 3-fold cross-validation approach was used in which patients were divided into training (D<sub>1<\/sub>) and test (D<sub>2<\/sub>) sets of 33 and 17 patients, respectively. Fisher&#8217;s score, used to select features based on their correlation to the outcome, was applied to D1 to identify the top 5 features most correlated with BCR. We then utilized these features to train a K-Nearest Neighbors classifier on D<sub>1<\/sub>, aimed at predicting whether a patient would experience BCR. The model&#8217;s performance was evaluated on D<sub>2 <\/sub>and averaged across all folds.<br \/>Results: The classifier was able to accurately differentiate between BCR+ and BCR- patients, achieving an average ROCAUC of 0.73 (&#177;0.04) in D<sub>2<\/sub>. Significant differences in 3D skeletal features were observed between BCR+ and BCR- groups (p&#60;0.05). Among the five selected features, three were related to the length and diameter of the gland, with the longest glands observed in BCR- patients. The remaining two features pertained to gland curvature and tortuosity, revealing more twisted glands in BCR+ patients.<br \/>Conclusion: Features derived from a skeleton model of the 3D glandular structure of biopsies showed promise in identifying patients with prostate cancer who are at a higher risk of BCR. Additional, multi-site independent validation of these findings is warranted.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Prostate cancer,Artificial Intelligence,3D pathology ,Prognosis,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>J. Salguero<\/b><sup>1<\/sup>, H. Abdeltawab<sup>1<\/sup>, K. Hammouda<sup>1<\/sup>, G. Corredor<sup>1<\/sup>, S. Hawley<sup>2<\/sup>, P. Mutha<sup>1<\/sup>, R. Dhamdhere<sup>1<\/sup>, S. Medina<sup>1<\/sup>, T. Pathak<sup>1<\/sup>, K. Bishop<sup>3<\/sup>, R. Serafin<sup>3<\/sup>, T. Mirtti<sup>4<\/sup>, P. Lal<sup>5<\/sup>, L. True<sup>3<\/sup>, J. Liu<sup>3<\/sup>, A. Madabhushi<sup>6<\/sup>; <br\/><sup>1<\/sup>Emory University, Atlanta, GA, <sup>2<\/sup>Canary Foundation, Palo Alto, CA, <sup>3<\/sup>University of Washington, Seattle, WA, <sup>4<\/sup>University of Helsinki & Helsinki University Hospital, Helsinki, Finland, <sup>5<\/sup>University of Pennsylvania, Philadelphia, PA, <sup>6<\/sup>Emory University and Georgia Institute of Technology, Atlanta, GA","CSlideId":"","ControlKey":"079f5819-81f6-4436-a2e6-9393da464767","ControlNumber":"2753","DisclosureBlock":"&nbsp;<b>J. Salguero, <\/b> None..<br><b>H. Abdeltawab, <\/b> None..<br><b>K. Hammouda, <\/b> None..<br><b>G. Corredor, <\/b> None..<br><b>S. Hawley, <\/b> None..<br><b>P. Mutha, <\/b> None..<br><b>R. Dhamdhere, <\/b> None..<br><b>S. Medina, <\/b> None..<br><b>T. Pathak, <\/b> None..<br><b>K. Bishop, <\/b> None..<br><b>R. Serafin, <\/b> None.&nbsp;<br><b>T. Mirtti, <\/b> <br><b>Aiforia Technologies Plc.<\/b> Independent Contractor, Other, consultation fees\/individual contractor.<br><b>P. Lal, <\/b> None.&nbsp;<br><b>L. True, <\/b> <br><b>Alpineglow Biosciences<\/b> Other, Small equity position. <br><b>J. Liu, <\/b> <br><b>Alpenglow Biosciences Inc.<\/b> Stock, Patent, Other, Co-founder and board member. <br><b>A. Madabhushi, <\/b> <br><b>Inspirata Inc.<\/b> Stock, Grant\/Contract. <br><b>Picture Health<\/b> Stock, Patent, Other, Advisory board. <br><b>Elucid Bioimaging<\/b> Stock, Patent. <br><b>Aiforia Inc<\/b> Other, Advisory board. <br><b>SimBioSys<\/b> Other, Consulting, Advisory board. <br><b>AstraZeneca<\/b> Other, Sponsored research agreements. <br><b>Boehringer-Ingelheim<\/b> Other, Sponsored research agreements. <br><b>Eli-Lilly<\/b> Other, Sponsored research agreements. <br><b>Bristol Myers-Squibb<\/b> Other, Sponsored research agreements. <br><b>Frederick National Laboratory Advisory Committee<\/b> Other, Member.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9373","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"8","PosterboardNumber":"8","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3516","PresenterBiography":null,"PresenterDisplayName":"Jennifer Salguero","PresenterKey":"e51af3e3-2dae-48a6-bfd5-c8bfd60916fa","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3516. AI-derived features of 3D glandular networks are associated with likelihood of biochemical recurrence post radical prostatectomy","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AI-derived features of 3D glandular networks are associated with likelihood of biochemical recurrence post radical prostatectomy","Topics":null,"cSlideId":""},{"Abstract":"Purpose: This study introduces a novel multimodal-attention-based virtual mIF staining (MAS) system designed for efficient, reliable virtual mIF staining from label-free fluorescence images. Our goal was to overcome the performance bottleneck and time-cost limitations associated with traditional mIF techniques and thereby enhance their clinical utility.<br \/>Method and Materials: Our approach involved developing a cutting-edge MAS model. This model is built upon a sophisticated end-to-end generative convolutional neural network (CNN) architecture. It ingeniously leverages autofluorescence and 4',6-diamidino-2-phenylindole (DAPI) slides as inputs to generate mIF images. To achieve this, we equipped the model with feature extractors enhanced by pretrained masked auto-encoders (MAEs) and a self-attention combination strategy. These components worked harmoniously to extract antigen-label-related features and precisely locate specific cells within the images.<br \/>Results: In our comprehensive study, we engaged 94 gastric cancer patients, utilizing the MAS system for automated virtual mIF staining of seven biomarkers, namely CD3, CD20, FOXP3, PD1, CD8, CD163, and PDL1, in both cancerous and non-cancerous tissues. Importantly, the MAS-produced virtual mIF stains matched the quality of traditional manual stains. Furthermore, we validated the prognostic accuracy for gastric cancer using these virtual mIF images, demonstrating their ability to provide clinical information that is as reliable and valuable as that obtained from manually stained mIF images.<br \/>Conclusions: Our study identifies the MAS system as an important advancement in mIF staining, enhancing personalized medicine with its efficiency and quality. This tool holds significant potential to enable personalized medicine efficiently and cost-effectively, streamlining the process of diagnosing diseases, making prognoses, and developing treatment plans.<table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{F9AA7586-CABF-45AA-9ED4-6DF8A822F6FC}\"><caption>Quantitative Comparison of Ablation Experiments for MAS system in predicting multiple biomarkers<\/caption><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">Biomarkers<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">Index<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">U-Net (<span lang=\"EN-US\" style=\"font-size: 9pt;\">Avg<\/span><span style=\"font-size:9.0pt;font-family:DengXian;mso-ascii-theme-font: minor-fareast;mso-fareast-theme-font:minor-fareast;mso-hansi-theme-font:minor-fareast; mso-bidi-font-family:Arial;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN; mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size: 9pt;\">Std<\/span>)<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">ReU-Net&nbsp;<\/span><span style=\"font-family: Arial, sans-serif; font-size: 12px;\">(<\/span><span lang=\"EN-US\" style=\"font-family: Arial, sans-serif; font-size: 9pt;\">Avg<\/span><span style=\"font-size: 9pt; font-family: DengXian;\">±<\/span><span lang=\"EN-US\" style=\"font-family: Arial, sans-serif; font-size: 9pt;\">Std<\/span><span style=\"font-family: Arial, sans-serif; font-size: 12px;\">)<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">Att-ReU-Net&nbsp;<\/span><span style=\"font-family: Arial, sans-serif; font-size: 12px;\">(<\/span><span lang=\"EN-US\" style=\"font-family: Arial, sans-serif; font-size: 9pt;\">Avg<\/span><span style=\"font-size: 9pt; font-family: DengXian;\">±<\/span><span lang=\"EN-US\" style=\"font-family: Arial, sans-serif; font-size: 9pt;\">Std<\/span><span style=\"font-family: Arial, sans-serif; font-size: 12px;\">)<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">MAS&nbsp;<\/span><span style=\"font-family: Arial, sans-serif; font-size: 12px;\">(<\/span><span lang=\"EN-US\" style=\"font-family: Arial, sans-serif; font-size: 9pt;\">Avg<\/span><span style=\"font-size: 9pt; font-family: DengXian;\">±<\/span><span lang=\"EN-US\" style=\"font-family: Arial, sans-serif; font-size: 9pt;\">Std<\/span><span style=\"font-family: Arial, sans-serif; font-size: 12px;\">)<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">CD3<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">PSNR<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">27.053<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.10<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">27.419<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.15<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">28.073<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.00<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">28.546<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.40<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">CD3<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">SSIM<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.733<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.07<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.724<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.07<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.728<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.05<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.742<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.07<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">CD20<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">PSNR<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">28.835<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.66<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">29.244<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.76<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">28.672<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.52<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">29.243<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.99<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">CD20<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">SSIM<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.921<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.058<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.921<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.057<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.915<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.051<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.923<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.051<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">FOXP3<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">PSNR<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">31.769<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">3.29<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">31.838<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">3.10<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">31.098<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">3.20<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">31.862<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">3.11<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">FOXP3<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">SSIM<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.613<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.11<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.618<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.11<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.617<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.112<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.617<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.12<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">PD1<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">PSNR<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">27.908<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.47<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">27.950<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.43<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">30.283<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.37<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">31.717<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">4.17<\/span><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">PD1<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">SSIM<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.654<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.13<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.659<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.13<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family: &quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.694<\/span><span style=\"font-size:9.0pt;font-family:DengXian; mso-ascii-theme-font:minor-fareast;mso-fareast-theme-font:minor-fareast; mso-hansi-theme-font:minor-fareast;mso-bidi-font-family:Arial;mso-ansi-language: EN-US;mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.12<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><a name=\"OLE_LINK33\"><b><span lang=\"EN-US\" style=\"font-size:9.0pt;font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family: DengXian;mso-fareast-theme-font:minor-fareast;mso-ansi-language:EN-US; mso-fareast-language:ZH-CN;mso-bidi-language:AR-SA\">0.726<\/span><\/b><span style=\"font-size:9.0pt;font-family:DengXian;mso-ascii-theme-font:minor-fareast; mso-fareast-theme-font:minor-fareast;mso-hansi-theme-font:minor-fareast; mso-bidi-font-family:Arial;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN; mso-bidi-language:AR-SA\">±<\/span><span lang=\"EN-US\" style=\"font-size:9.0pt; font-family:&quot;Arial&quot;,sans-serif;mso-fareast-font-family:DengXian;mso-fareast-theme-font: minor-fareast;mso-ansi-language:EN-US;mso-fareast-language:ZH-CN;mso-bidi-language: AR-SA\">0.11<\/span><\/a><\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Gastric cancer,Image analysis,Biomarkers,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Z. Zhou<\/b><sup>1<\/sup>, Y. Jiang<sup>2<\/sup>, R. Li<sup>1<\/sup>, L. Xing<sup>1<\/sup>; <br\/><sup>1<\/sup>Stanford University, Stanford, CA, <sup>2<\/sup>Wake Forest University School of Medicine, Winston Salem, NC","CSlideId":"","ControlKey":"a0ccf14b-74ee-4f16-8ccc-b4664652392a","ControlNumber":"2907","DisclosureBlock":"&nbsp;<b>Z. Zhou, <\/b> None..<br><b>Y. Jiang, <\/b> None..<br><b>R. Li, <\/b> None..<br><b>L. Xing, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9374","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"9","PosterboardNumber":"9","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3517","PresenterBiography":null,"PresenterDisplayName":"Zixia Zhou","PresenterKey":"350f1a73-f324-4a47-800b-d135ce43a576","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3517. A deep learning-based virtual staining system with multimodal-attention for precision medicine","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"A deep learning-based virtual staining system with multimodal-attention for precision medicine","Topics":null,"cSlideId":""},{"Abstract":"Haematoxylin &#38; &#8206;Eosin (H&#38;E)-based deep learning algorithms require a large number of human-based cell annotations for model training, and are limited by what a human eye can see. Multiplex immunofluorescence (mIF) offers a more comprehensive and accurate method for classifying cells because annotations are based on cell status, i.e. whether a cell expresses certain markers or not. In this study, we leverage mIF-based cell type predictions<sup>1<\/sup> to enhance H&#38;E model performance.We used a publicly available CODEX\/PhenoCycler dataset<sup>2<\/sup> consisting of 140 tissue cores obtained from 35 patients with colorectal cancer, which were stained with 56 protein markers and subsequently with H&#38;E. mIF data was used to create over 60,000 prediction-based annotations on the corresponding H&#38;E-stained images that were used to train deep learning H&#38;E classifiers.<br \/>The final model performance reached AUC of 0.91 when evaluated on the H&#38;E test annotations and 0.90 on the mIF predictions. Notably, the mIF annotations-based H&#38;E model surpassed the manual annotations-based H&#38;E model in effectively identifying challenging cell types, demonstrating its superior performance. These findings highlight the potential of leveraging mIF cell type predictions to train accurate and automated H&#38;E models.<br \/><sup>1<\/sup>Markovits et al, BioRxiv, https:\/\/doi.org\/10.1101\/2022.11.09.515776<sup>2<\/sup>Sch&#252;rch et al, Cell. 2020,182(5): 1341-1359.PMID: 32763154","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Immuno-oncology,Deep learning,Bioinformatics,Fluorescence imaging,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>B. Arbiv<\/b>, A. Bart, T. Dankovich, R. Elran, S. Bookstein, A. Laniado, T. Dicker, S. Dagan, O. Puig, K. Bloom, E. Markovits; <br\/>Nucleai, Chicago, IL","CSlideId":"","ControlKey":"7ed8e0ab-d8f1-4c9f-8172-4726955fa5ad","ControlNumber":"3421","DisclosureBlock":"<b>&nbsp;B. Arbiv, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>A. Bart, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>T. Dankovich, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>R. Elran, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>S. Bookstein, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>A. Laniado, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>T. Dicker, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>S. Dagan, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>O. Puig, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>K. Bloom, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option. <br><b>E. Markovits, <\/b> <br><b>Nucleai<\/b> Employment, Stock Option.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9375","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"10","PosterboardNumber":"10","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3518","PresenterBiography":null,"PresenterDisplayName":"Becky Arbiv, BS","PresenterKey":"bb5b0b13-3932-488c-8d27-25643bd25a0d","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3518. Next generation H&#38;E cell modeling: Using same-slide multiplex immunofluorescence (mIF) data to train H&#38;E","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Next generation H&#38;E cell modeling: Using same-slide multiplex immunofluorescence (mIF) data to train H&#38;E","Topics":null,"cSlideId":""},{"Abstract":"Background: Molecularly and clinically well-annotated patient datasets are ideal for studying tumor biology and developing robust machine learning (ML) models for predicting outcome and treatment response. These data however rarely exist in real-world settings or in sufficient quantities within research contexts. Large publicly available datasets like The Cancer Genome Atlas (TCGA) which provid multi-omic profiles for diverse cancer types, have profoundly advanced cancer research and facilitated development of novel therapies and personalized medicines. However, the absence of patient outcome data tied to treatment limits the applicability of these data for understanding and modeling treatment response. Real-world clinicogenomics cohorts, such as the AACR Project GENIE, on the other hand are typically very rich in clinical annotations, including treatment regimens and outcomes measures. These data are however sparsely annotated for patient tumor molecular profiles, rarely exceeding ~100&#8217;s of genes profiled. We hypothesized that it would be possible to reconstruct latent tumor mRNA representations from limited genomic and clinical data available in real-world clinicogenomic cohorts, and that these reconstructed expression profiles would be useful for a variety of clinically meaningful downstream applications.<br \/>Methods: We developed an ML model, called Mut2Ex, to reconstruct tumor gene expression profiles using genetic information available on commercial next generation sequencing panels using a Principle Label Space Transformation (PLST) we adapted to regression problem, along with embeddings from clinical information (OncoTree code, sex and stage) generated by a language model. Mut2Ex was trained on ~1200 cell lines from DepMap representing 26 cancer types, to generate ~2000 reconstructed mRNA gene profiles that were applied to a variety of clinical tasks. We used Mut2Ex to reconstruct mRNA profiles for ~10,000 tumors from TCGA and ~180,000 tumors from AACR Project GENIE.<br \/>Results: Reconstructed mRNA expression by Mut2Ex was highly correlated with true expression in cell lines (rho = 0.926, [0.924-0.928 95% CI, N = 1184]). Compared to true expression, reconstructed profiles recapitulate sub-clusters within cancer types, PAM50 subtyping in breast tumors, survival signatures in colorectal tumors and multiple oncogenic signatures in a pan-cancer manner. Analysis of reconstructed expression for AACR Project GENIE tumors revealed expected enrichment of known driver genes within expression subtypes and enrichment of oncogenic signatures associated with distinct clinical outcomes in a cancer type specific manner.<br \/>Conclusions: Our flexible analytic framework for reconstructing gene expression profiles from clinicogenomics data substantially augments the clinical utility and value of data acquired in real-world settings.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Gene expression,Cancer genomics,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>M. Baron<\/b>, S. Kumar, F. Kuperwaser, D. Tracy, E. Vucic, J. Sherman; <br\/>Zephyr AI, McLean, VA","CSlideId":"","ControlKey":"b0f15017-a045-42fa-922b-6084276ee9bf","ControlNumber":"3461","DisclosureBlock":"<b>&nbsp;M. Baron, <\/b> <br><b>ZephyrAI<\/b> Employment, Stock, Stock Option. <br><b>S. Kumar, <\/b> <br><b>ZephyrAI<\/b> Employment, Stock, Stock Option. <br><b>F. Kuperwaser, <\/b> <br><b>ZephyrAI<\/b> Employment, Stock, Stock Option. <br><b>D. Tracy, <\/b> <br><b>ZephyrAI<\/b> Employment, Stock, Stock Option. <br><b>E. Vucic, <\/b> <br><b>ZephyrAI<\/b> Employment, Stock, Stock Option. <br><b>J. Sherman, <\/b> <br><b>ZephyrAI<\/b> Employment, Stock, Stock Option.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9376","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"11","PosterboardNumber":"11","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3519","PresenterBiography":null,"PresenterDisplayName":"Maayan Baron, B Eng;M Phil;MS;PhD","PresenterKey":"6f64fe41-5462-4010-b234-46dcdb2a26b5","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3519. Reconstructing a latent representation of gene expression from genomic alterations to improve clinical utility of real-world clinicogenomics data","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Reconstructing a latent representation of gene expression from genomic alterations to improve clinical utility of real-world clinicogenomics data","Topics":null,"cSlideId":""},{"Abstract":"Single cell RNA-seq (scRNA-seq) technology transformed our understanding of biology at the cell level. Inferring cell types provide insights into the relative abundance of, and genomic differences between, different cell types. Current methods leverage known cell type markers and genomic similarity measures to attribute cell types to groups of cells.<br \/>We present a scalable machine learning-based pipeline that can leverage high quality reference annotation data to infer cell types quickly for multiple scRNA-seq experimental samples. This pipeline leverages two machine learning technologies: variational autoencoders (VAE) to create a low-dimensional representation of the reference transcriptome; and, supervised learning methods that use this representation to learn cell types from the reference data. This pipeline can quickly score new experimental data using GPU-enabled computing platforms and provide probabilities of a cell being each cell type present in the reference data.<br \/>This novel pipeline is evaluated using 5 public reference data sets. We evaluate whether VAE-based representations benefit supervised learning, compared to PCA and t-SNE. We next evaluate different supervised learning methods for predictive performance. Finally, we compare the pipeline&#8217;s performance with commonly-used cell type prediction algorithms (Seurat, scANVI). We find that using a VAE is generally better than both PCA and t-SNE for feature generation to predict cell type. Using the VAE representation, there is no significant difference in accuracy between logistic regression and other supervised learning algorithms. Finally, using logistic regression as the learning machine, this pipeline is as accurate as Seurat and better than scANVI, while running about <u>2-5x faster<\/u> than Seurat.<br \/><table class=\"AbstractTable\" id=\"{2B3606E9-C703-4178-8D2E-45629655E54B}\"><caption class=\"AbstractTableCaption\"><\/caption><tr><td rowspan=\"1\" colspan=\"1\">Algorithm<\/td><td rowspan=\"1\" colspan=\"1\">PBMC (10X)<\/td><td rowspan=\"1\" colspan=\"1\">HLCA<\/td><td rowspan=\"1\" colspan=\"1\">Eraslan snRNA<\/td><td rowspan=\"1\" colspan=\"1\">Blueprint Breast<\/td><td rowspan=\"1\" colspan=\"1\">Blueprint Lung<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Our pipeline<\/td><td rowspan=\"1\" colspan=\"1\">92 (87-95)<\/td><td rowspan=\"1\" colspan=\"1\">92 (88-93)<\/td><td rowspan=\"1\" colspan=\"1\">93 (90-97)<\/td><td rowspan=\"1\" colspan=\"1\">89 (80-96)<\/td><td rowspan=\"1\" colspan=\"1\">97 (95-99)<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Seurat<\/td><td rowspan=\"1\" colspan=\"1\">96 (95-97)<\/td><td rowspan=\"1\" colspan=\"1\">90 (94-98)<\/td><td rowspan=\"1\" colspan=\"1\">94 (93-97)<\/td><td rowspan=\"1\" colspan=\"1\">96 (87-98)<\/td><td rowspan=\"1\" colspan=\"1\">98 (94-99)<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">scANVI<\/td><td rowspan=\"1\" colspan=\"1\">91 (84-95)<\/td><td rowspan=\"1\" colspan=\"1\">72 (78-86)<\/td><td rowspan=\"1\" colspan=\"1\">92 (88-96)<\/td><td rowspan=\"1\" colspan=\"1\">94 (80-97)<\/td><td rowspan=\"1\" colspan=\"1\">88 (86-100)<\/td><\/tr><\/table><br \/>Table 1 Balanced accuracy (%) from leave-one-subject-out cross-validation across 5 public data sets. Intervals are the range of the metric across the cross-validation folds.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Single cell,cell annotation,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>A. Dasgupta<\/b><sup>1<\/sup>, G. Duclos<sup>2<\/sup>, R. Miragaia<sup>3<\/sup>, B. Manry<sup>1<\/sup>, E. Jacob<sup>2<\/sup>, N. Markuzon<sup>2<\/sup>, A. Rotem<sup>2<\/sup>; <br\/><sup>1<\/sup>AstraZeneca US, Gaithersburg, MD, <sup>2<\/sup>AstraZeneca US, Waltham, MA, <sup>3<\/sup>AstraZeneca UK, Cambridge, United Kingdom","CSlideId":"","ControlKey":"61c6d0d3-6f63-4887-8c0a-158efb7fd8c2","ControlNumber":"4205","DisclosureBlock":"<b>&nbsp;A. Dasgupta, <\/b> <br><b>AstraZeneca US<\/b> Employment, Stock, Stock Option. <br><b>G. Duclos, <\/b> <br><b>AstraZeneca US<\/b> Employment, Stock, Stock Option. <br><b>R. Miragaia, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Stock Option. <br><b>B. Manry, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Stock Option. <br><b>E. Jacob, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Stock Option. <br><b>N. Markuzon, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Stock Option. <br><b>A. Rotem, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock, Stock Option.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9377","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"12","PosterboardNumber":"12","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3520","PresenterBiography":null,"PresenterDisplayName":"Abhijit Das Gupta","PresenterKey":"9502dd9e-bb24-4afb-a89a-9178d04d2b90","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3520. &#173;&#173;&#173;&#173;&#173;&#173;A scalable single cell RNA-seq pipeline leveraging machine learning and high-quality references for cell-type prediction","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"&#173;&#173;&#173;&#173;&#173;&#173;A scalable single cell RNA-seq pipeline leveraging machine learning and high-quality references for cell-type prediction","Topics":null,"cSlideId":""},{"Abstract":"The diagnostic workup of prostate cancer (PCa) requires a thorough manual histopathological inspection of prostate tissue specimens stained with hematoxylin and eosin (H&#38;E). While immunohistochemistry and advanced molecular tests like FISH could uncover key genetic alterations, they are not cost-effective and often require special training, necessitating the development of more effective tools that can accurately infer the status of such alterations directly from the tissue morphology depicted in routine H&#38;E-stained glass slides. PTEN deletion, which is present in 15-20% of PCa, is significantly associated with tumor aggressiveness and negative prognostic impact. Deep learning (DL) models can be trained to predict the presence of PTEN deletion on routine whole slide images (WSIs) and select patients that could benefit from further treatment. In this study, we trained and tested the performance of a weakly supervised, multiple-instance learning network on a cohort of 449 WSIs radical prostatectomy specimens stained with hematoxylin &#38; eosin. Our model demonstrated robust performance in predicting PTEN loss based on tumor morphology alone. Through the model, we also generated attention heatmaps of the most informative tiles of each slide, allowing us to quantify the different cellular components, thus inferring the morphological features associated with PTEN loss. This study shows that DL is a potential tool that can assist the pathologist in accurately inferring the molecular status of key genetic alterations using the tissue morphology depicted in histopathology slides. Moreover, the morphological information that can be obtained by attention-based models can be leveraged to close the gap between the pathologist&#8217;s morphological analysis and the interpretability of artificial intelligence models.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,PTEN,Image analysis,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>F. Scarfò<\/b><sup>1<\/sup>, M. Omar<sup>2<\/sup>, L. Marchionni<sup>2<\/sup>; <br\/><sup>1<\/sup>IRCCS Ospedale San Raffaele, Milan, Italy, <sup>2<\/sup>Weill Cornell Medicine, New York City, NY","CSlideId":"","ControlKey":"e5ec87f6-e415-4a77-a70b-73528e6c88bc","ControlNumber":"4708","DisclosureBlock":"&nbsp;<b>F. Scarfò, <\/b> None..<br><b>M. Omar, <\/b> None..<br><b>L. Marchionni, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9378","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"13","PosterboardNumber":"13","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3521","PresenterBiography":null,"PresenterDisplayName":"Federico Scarfò","PresenterKey":"572bd512-6b31-43c2-9c89-bc81f2d6a997","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3521. Robust inference of PTEN deletion in prostate cancer from routine histopathology whole slide images using attention-based deep learning","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Robust inference of PTEN deletion in prostate cancer from routine histopathology whole slide images using attention-based deep learning","Topics":null,"cSlideId":""},{"Abstract":"Ovarian cancer is a challenging disease, often exhibiting recurrence after initial treatment. The complexity arises from simultaneous disruptions in multiple signaling pathways within tumor cells, rendering targeted inhibitors ineffective in providing sustained therapeutic impact. While targeted sequencing panels can identify specific therapeutically relevant events, they often fail to capture the complete picture of targetable tumor driving aberrations, and provide biomarkers relevant to disease resistance and\/or recurrence. A potential solution lies in comprehensively defining the landscape of signaling pathway alterations by identifying molecular triggers underlying their dysregulation. While individual DNA mutations sometimes may not lead to carcinogenesis or changes in tumor cell behavior, combination of deactivating mutations in suppressor genes, can influence tumor development and prognosis, warranting a comprehensive delineation of their effect on the broad signaling network level. To this end, we propose the Large Language Models (LLMs), which have been successful in natural language processing, particularly in understanding context. Such tools are essential for discerning the effect of mutation combinations, their physical proximity to other mutations, and functional gene regions. We obtained mutation annotation files for 177 ovarian cancer patients from the TCGA database, reconstructing consensus nucleotide sequences using a reference genome. To input this data into LLMs, we generated embeddings for these sequences using the Nucleotide Transformer algorithm, pre-trained on 500 million variants of the reference genome. Additionally, we extracted data on detected disruptions in 10 signaling pathways (Cell Cycle, HIPPO, MYC, NOTCH, NRF2, PI3K, RTK RAS, TP53, TGF-Beta, WNT) for these patients from TCGA. Each pathway was associated with the percentage of its alteration. We trained a deep learning algorithm on these data to predict a combination of 10 numerical values, each corresponding to the percentage of disruption for a given signaling pathway. Our findings revealed that nearly half of the patients exhibited disruptions in 5 or more signaling pathways. The algorithm developed enables the determination of the extent of disruption in each pathway based on whole exome sequencing results. This approach facilitates more informed treatment strategy planning and enhances the efficient development of new drugs for ovarian cancer treatment.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Ovarian cancer,Sequence context,Sequencing,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>D. K. Chebanov<\/b>, N. S. Tatevosova; <br\/>BioAlg Corp., Covina, CA","CSlideId":"","ControlKey":"090565dc-49f7-4a5b-b707-e8388c90ad4f","ControlNumber":"4824","DisclosureBlock":"<b>&nbsp;D. K. Chebanov, <\/b> <br><b>BioAlg<\/b> Employment, Stock. <br><b>N. S. Tatevosova, <\/b> <br><b>BioAlg<\/b> Employment, Stock.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9379","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"14","PosterboardNumber":"14","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3522","PresenterBiography":null,"PresenterDisplayName":"Dmitrii Chebanov, MS,PhD","PresenterKey":"06a52bd3-4c64-4b46-bb3b-e95a3605d979","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3522. Application of large language models to nucleotide sequences for profiling signaling pathway disruptions in ovarian cancer patients","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Application of large language models to nucleotide sequences for profiling signaling pathway disruptions in ovarian cancer patients","Topics":null,"cSlideId":""},{"Abstract":"Our knowledge of cancer biology has advanced with the characterization of distinct cell types and cell states within heterogeneous tumor environments. Many methods for imaging and sorting tumor cells require biomarker labels that alter cell characteristics and create a selection bias. The use of label-free single-cell methods should further improve cancer studies involving viable, unperturbed cells for downstream assays such as RNA-Seq, cell culture expansion, and functional assays. To eliminate biomarkers and enable broader assessment of cells, we developed REM-I, a platform that characterizes and sorts unlabeled single cells based on high-dimensional morphology. Cells are captured with brightfield imaging and processed in real-time by self-supervised deep learning models to generate quantitative AI embeddings representative of cell morphology. A significant technical challenge in building REM-I was developing an AI model based on extracted features from cell images without prior knowledge of cell types, cell preparation, or other application-specific knowledge. Accordingly, we developed the Human Foundation Model (HFM), a hybrid architecture that combines self-supervised learning (SSL) and morphometrics (computer vision) to extract 115 dimensional embeddings representing cell morphology from high-resolution REM-I cell images. SSL produces a foundation model with high generalization capacity that enables hypothesis-free sample exploration and efficient generation of application-specific models. Meanwhile, computer vision extracts features that represent measurable and interpretable concepts (e.g., cell size, shape, texture, intensity). The training process for the HFM self-supervised backbone model utilizes the discriminatory power of supervised tasks. Using synthetic cells and three cancer cell lines, we trained and then validated the reproducibility and generalization capabilities of the resulting model. Results show combining deep learning and morphometrics improve interpretability of data and enable rapid characterization and classification of tumor cells with high accuracy. We also report on the Deepcell&#174; Axon data suite, a tool to analyze data and customize reusable workflows. This includes the ability to store and manage data, visualize high dimensional data as low-dimensional projections, and train classifiers to identify and sort cell populations. To enable compatibility with user-preferred downstream analysis pipelines, Axon provides data export options for images, plots, and embeddings. Our approach allows users of all skill levels to access and interpret AI-enabled morphological profiling. Applications of REM-I include hypothesis-free evaluation of heterogeneous tumor samples, label-free cancer cell enrichment, characterization of distinct cell states, and multi-omic integration.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Image analysis,Multiomics,Imaging,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>K. Saini<\/b>, S. Zhang, R. Carelli, K. B. Jacobs, A. Wong-Thai, C. Luengo, V. Lu, A. Mavropoulos, A. Jovic, J. Mei, T. Vollbrecht, S. C. Boutet, M. Salek, M. Masaeli; <br\/>Deepcell Inc., Menlo Park, CA","CSlideId":"","ControlKey":"8dca26a2-406a-411a-a666-73837424d5c6","ControlNumber":"5340","DisclosureBlock":"&nbsp;<b>K. Saini, <\/b> None..<br><b>S. Zhang, <\/b> None..<br><b>R. Carelli, <\/b> None..<br><b>K. B. Jacobs, <\/b> None..<br><b>A. Wong-Thai, <\/b> None..<br><b>C. Luengo, <\/b> None..<br><b>V. Lu, <\/b> None..<br><b>A. Mavropoulos, <\/b> None..<br><b>A. Jovic, <\/b> None..<br><b>J. Mei, <\/b> None..<br><b>T. Vollbrecht, <\/b> None..<br><b>S. C. Boutet, <\/b> None..<br><b>M. Salek, <\/b> None..<br><b>M. Masaeli, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9380","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"15","PosterboardNumber":"15","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3523","PresenterBiography":null,"PresenterDisplayName":"Kiran Saini, MS","PresenterKey":"5748c7c2-bf9b-4351-8dd8-152517870a4e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3523. Self-supervised foundation model captures high-dimensional morphology data from single cell brightfield images","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Self-supervised foundation model captures high-dimensional morphology data from single cell brightfield images","Topics":null,"cSlideId":""},{"Abstract":"Approximately 5,000 new articles are indexed by PubMed daily, many providing critical insights into novel gene-drug relationships. However, searching and distilling the wealth of biomedical literature to infer specific pharmacogenomic relationships between a gene and a drug poses a significant burden for researchers. Recent advances in large language models, such as ChatGPT, offer a promising solution to tackle this challenge. This study aims to prototype a literature-based inference for drug-gene relationships in the context of cancer using ChatGPT, marking an exploratory effort in this emerging domain. Our approach involves developing an automated pipeline that integrates the Application Programming Interfaces (APIs) of PubMed and ChatGPT, specifically GPT-3.5. Given a gene, a drug, and a disease, the pipeline searches PubMed for relevant articles and extracts their abstracts. Leveraging prompt engineering techniques, we formulated a prompt that facilitates accurate summarization of these abstracts. The output of our pipeline includes three key components: 1) a concise, one-sentence summary elucidating the relationship between the drug-gene pair; 2) a step-by-step explanation of the inference process; and 3) the confidence level associated with the generated summary. Our approach was able to confirm well-known gene-drug relationships in cancer, such as palbociclib and <i>CDK4<\/i>. We further examined a challenging case of CX-5461, an inhibitor of ribosomal RNA synthesis currently under clinical investigation for various cancers. Until recent evidence emerged in 2021, this drug was mischaracterized as an RNA-Pol I inhibitor, whereas it primarily targets topoisomerase II beta (<i>TOP2B<\/i>). Notably, our pipeline correctly identified <i>TOP2B<\/i> as the primary target of CX-5461, despite an extensive body of literature prior to 2021 supporting the RNA-Pol I relationship. To evaluate the sensitivity of our pipeline, we conducted a systematic assessment using a mixture of relevant and irrelevant abstracts. Utilizing bevacizumab, VEGF, and hepatocellular carcinoma as a demonstrating example, we showed that ChatGPT achieved nearly 95% accuracy even when only 30% of the abstracts were relevant to the case. In summary, this pilot research serves as a foundational step towards the utilization of large language models in the field of drug discovery and development. Our ongoing efforts involve the rigorous evaluation of our approach across a diverse spectrum of drug targets and cancer types, as well as the optimization of prompts through state-of-the-art prompt engineering techniques.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Cancer,Bioinformatics,Drug discovery,Pharmacogenomics,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"Y. Shin, <b>M. Ning<\/b>, L.-J. Wang, Y. Huang, Y.-C. Chiu; <br\/>UPMC Hillman Cancer Center, Pittsburgh, PA","CSlideId":"","ControlKey":"0b79bd56-38ff-43c4-a125-b693830d56e3","ControlNumber":"5412","DisclosureBlock":"&nbsp;<b>Y. Shin, <\/b> None..<br><b>M. Ning, <\/b> None..<br><b>L. Wang, <\/b> None..<br><b>Y. Huang, <\/b> None..<br><b>Y. Chiu, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9381","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"16","PosterboardNumber":"16","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3524","PresenterBiography":null,"PresenterDisplayName":"Michael Ning, Undergraduate Student","PresenterKey":"46b2a76c-ab36-4f37-bdda-e757c933b1cd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3524. Leveraging ChatGPT for literature-based inference of drug-gene relationships in cancer","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Leveraging ChatGPT for literature-based inference of drug-gene relationships in cancer","Topics":null,"cSlideId":""},{"Abstract":"Background: The advent of immune checkpoint inhibitors has improved morbidity and mortality for some cancers, and recent breakthroughs in gene &#38; cell therapy have shed light on curing some types of blood cancers. However, many cancers remain intractable and the development of novel, effective and safe therapies continue to be a priority. Cancer vaccines as a cancer immunotherapy approach has seen a resurgence in recent years, due to the success of mRNA vaccines for the COVID-19. However, the accurate prediction of immunogenicity of cancer vaccines remains elusive.<br \/>Methods: Our models predict the probability of a given peptide derived from the protein of interest to be presented by MHC-I or MHC-II. For MHC-I antigen presentation model development, over 17 million entries in the dataset were collected from published literature and available databases, e.g., IEDB, with peptide lengths ranging from 8 to 11. The peptides were restricted to 150 unique MHC-I alleles. Similarly, ~4 million entries with peptide lengths ranging from 13 to 21 were collected for MHC-II antigen presentation model development, and the peptides were restricted to 19 unique MHC-II alleles. To develop advanced antigen presentation models, a language model was chosen as the backbone network and contrast learning was used to better discriminate the peptide-MHC match versus mismatch. Overall, both MHC-I and MHC-II presentation models were constructed with about 30 million parameters. To validate the model prediction accuracy, automated peptide synthesis and surface plasmon resonance (SPR) technologies were applied.<br \/>Results: Using open-sourced data, our developed AI models surpassed the performance of state-of-the-art prediction algorithms, the latest versions of NetMHCpan and MixMHCpred, for both MHC-I and MHC-II antigen presentation. Furthermore, to validate the algorithm accuracy and the peptide immunogenicity, 28 predicted patentable peptides derived from mutated TP53 protein were synthesized and their binding to respective common HLA alleles were validated using SPR. We found that greater than 80% of the peptides display binding affinities that are stronger than the positive control, suggesting that AI significantly improves neoantigen peptide vaccine design.<br \/>Conclusions: We developed advanced AI algorithms to rapidly design shared neoantigen T cell epitopes with predicted strong binding affinity to MHC-I and MHC-II. We envision that the epitopes predicted and designed by our AI algorithms possess great potential in advancing the field of off-the-shelf cancer vaccine development and hold the promise of significantly benefiting patients, once translated into the clinic.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Neoantigens,Deep learning,Vaccines,Peptides,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"G. Zhang<sup>1<\/sup>, J. Du<sup>1<\/sup>, X. Gao<sup>1<\/sup>, T. Wang<sup>1<\/sup>, Z. Wang<sup>1<\/sup>, Q. Zhang<sup>1<\/sup>, T. Liu<sup>1<\/sup>, D. Chen<sup>1<\/sup>, R. Zhu<sup>1<\/sup>, Y. Zhao<sup>1<\/sup>, C. Li<sup>2<\/sup>, M. Toh<sup>2<\/sup>, <b>L. Lai<\/b><sup>1<\/sup>; <br\/><sup>1<\/sup>Xtalpi, Beijing, China, <sup>2<\/sup>CK Life Sciences Development Limited, Hong Kong, Hong Kong","CSlideId":"","ControlKey":"903e006e-92e4-4d27-9223-7682e7b4a212","ControlNumber":"5861","DisclosureBlock":"&nbsp;<b>G. Zhang, <\/b> None..<br><b>J. Du, <\/b> None..<br><b>X. Gao, <\/b> None..<br><b>T. Wang, <\/b> None..<br><b>Z. Wang, <\/b> None..<br><b>Q. Zhang, <\/b> None..<br><b>T. Liu, <\/b> None..<br><b>D. Chen, <\/b> None..<br><b>R. Zhu, <\/b> None..<br><b>Y. Zhao, <\/b> None..<br><b>C. Li, <\/b> None..<br><b>M. Toh, <\/b> None..<br><b>L. Lai, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9382","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"17","PosterboardNumber":"17","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3525","PresenterBiography":null,"PresenterDisplayName":"Lipeng Lai, PhD","PresenterKey":"bc17949c-22bf-41bb-8a1b-d9633c146cbf","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3525. Towards the efficient design of shared neoantigen peptide cancer vaccines using artificial intelligence","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Towards the efficient design of shared neoantigen peptide cancer vaccines using artificial intelligence","Topics":null,"cSlideId":""},{"Abstract":"Higher standards for precise distinction and classification among the four breast cancer subtypes, i.e., Luminal A. Luminal B, HER-2-enriched, and Basal, are essential to delivering customized treatment in precision oncology. The effective integration of readily accessible multi-omics datasets from the same patient may improve the accuracy of subtype prediction algorithms and help decipher reliable molecular features for the prediction and prognosis of breast cancer. Previous models for predicting breast cancer subtypes relied mostly on concatenation and autoencoder methods but rarely utilized graph-based integration to leverage the biological associations among omics datatypes. To overcome these limitations, we developed a graph-based multi-omics integration method using features from mRNA, DNA methylation, and miRNA data and synthesized features from their interactions. GAIN-BRCA computes weightage scores from miRNA-mRNA and DNA methylation-mRNA interactions to derive a new transformed feature vector without compromising biological information. The neural network architecture was designed and trained on the transformed features to classify breast cancer subtypes. Neural network prediction accuracies were compared using concatenated, autoencoder, and GAIN-BRCA-based integrated datasets. GAIN-BRCA outperforms the existing similar models MOGONET (Acc: 0.72) and moBRCA-net (Acc: 0.86) with an accuracy of 0.91. These transformed features were then processed using SHAP, and the top 357 features were selected for functional characterization and pathway analysis. We identified specific pathways and genes related to each breast cancer subtype separately. The most enriched pathways found in each subtype are ribonucleotide reductase signaling and glucocorticoid signaling pathways in luminal A, PFKB4 signaling pathway in luminal B, adipogenesis and DNA methylation and transcriptional signaling in HER2+, and the role of OCT4 in mammalian embryonic stem cell pluripotency in basal. Similarly, the most discriminated gene features are BRAF, ESR1, KRAS, MAPK1, SMARCE1, PPP3CA, and TGFBR2 in luminal A, TGFB3 and NCOA3 in luminal B, HNF4A, SIN3A, and SOX9 in HER2+, and POU5F1 and FOXA2 in basal subtypes. The GAIN-BRCA framework, combined with SHAP, weighs independent omics as cross-disciplinary rather than multidisciplinary and presents a distinctive picture for each subtype. As a result, the framework presents the importance of features about the corresponding subtype, which might lead to a greater understanding of the molecular basis of breast cancer subtypes.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,Methylation,RNA,Deep learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>J. Patel<\/b>, S. K. Shakyawar, S. Sethi, C. Guda; <br\/>University of Nebraska Medical Center, Omaha, NE","CSlideId":"","ControlKey":"d87cd471-3d34-4271-bd98-6b4743a98697","ControlNumber":"5929","DisclosureBlock":"&nbsp;<b>J. Patel, <\/b> None..<br><b>S. K. Shakyawar, <\/b> None..<br><b>S. Sethi, <\/b> None..<br><b>C. Guda, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9383","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"18","PosterboardNumber":"18","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3526","PresenterBiography":"I am Jai Chand Patel joined as Postdoctoral Research Associate at UNMC in Professor Guda’s lab on October 1st, 2021. I completed my Ph.D. from DRDO (India) in 2021. During my Ph.D., I worked on developing a predictive model for hypoxia-induced pathologies using network biology, time series analysis, machine learning, and microarray analysis. I received my M.Sc (2014) and B.Sc. (2012) from Kurukshetra University (India). Currently, I am developing machine learning models for survival prediction, subtyping, and early diagnosis of different types of cancer. Primarily, I am focusing on integrating multi-omics cancer data from public repositories using deep learning models.","PresenterDisplayName":"Jai Chand Patel, PhD","PresenterKey":"20f697c7-0476-4ae4-864b-d4abec45d421","PresenterPhoto":"https:\/\/files.abstractsonline.com\/assocphotos\/101\/20f697c7-0476-4ae4-864b-d4abec45d421.profile.jpeg","SearchResultActions":null,"SearchResultBody":"3526. GAIN-BRCA: A graphical explainable AI-net framework for breast cancer subtype classification using multiomics data","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"GAIN-BRCA: A graphical explainable AI-net framework for breast cancer subtype classification using multiomics data","Topics":null,"cSlideId":""},{"Abstract":"Discovery of a candidate drug molecule through the preclinical stages is an iterative multiparametric process until a candidate is selected for investigational new drug submission enabling studies. This iterative approach takes up significant time and effort to design, synthesize, and test new compounds. A specific testing step is evaluation of half maximal inhibitory concentration (IC50) of compounds on cell line (CL) models. To augment CL testing, computational approaches predicting the IC50 of a drug can be used to guide choice of optimization as the molecule goes through hit to lead optimization onto candidate selection. DeepDSC [1] is a deep learning (DL) model developed to predict the IC50 in a specific CL of a given drug by integrating public data from large-scale drug screens and high-throughput RNAseq profiling. The Cancer Cell Line Encyclopedia (CCLE) [2] and Genomics of Drug Sensitivity (GDSC) [3] projects compiled pharmacological profiles of 23 and 139 drugs across 491 and 655 cancer CLs, respectively. A 10-fold cross validation (CV) approach was employed to train DeepDSC on the datasets independently and reported the average root mean squared error (RMSE) and the coefficient of determination (R<sup>2<\/sup>) on the held-out sets across the folds. However, the model&#8217;s generalizability to novel compounds not in the dataset, specifically compounds that are structurally dissimilar, is yet to be tested. In this regard, the DeepDSC model was retrained, with modifications, on a subset of the GDSC dataset - GDSC2 - to access the generalizability of DL models on BRG399, a proprietary microtubule targeting agent (MTA) developed by BPGbio Inc. GDSC2 was used since data generated for BRG399 and GDSC2 share the same potency assay (CellTiter-Glo [6]), The GDSC2 set was split into training and held-out sets using a 80-20 random split. Further, we chose to optimize the learning rate for both the autoencoder and feed forward networks (FFN), and the L2 regularization factor for the FFN only. Hyperparameters were optimized using 5-fold CV on the training set. Finally, we evaluated the predictive performance of the model on BRG399, which was not present in the training set. We encoded each compound in GDSC2 (n=234) using Circular Fingerprints [4] and observed an average Jaccard (or Tanimoto) distance (JD) [5] of 0.892 across 27261 drug pairs. BRG399 showed an average JD of 0.873 across 234 drug pairs, with the most similar compound JD of 0.785. Our retrained DeepDSC model had RMSE 1.15 and R<sup>2<\/sup> 0.82 on the training set and RMSE 1.19 and R<sup>2<\/sup> 0.86 on the held-out set. However, on BRG399 tested CLs (n=101) model had RMSE 1.84 and R<sup>2<\/sup> &#60; 0, which indicated that predictions were on average worse compared to a mean-predictor model for BRG399. These results suggest that DL models that can generalize predictions to a held-out set for compounds that were present in the training set may not accurately predict IC50 of novel compounds not in the training set.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Microtubule-interfering agents,Drug sensitivity,Antitumor agents,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>N. M. Chand<\/b>, V. Vishnudas, M. A. Kiebish, A. Thakurta, N. R. Narain, S. Gesta, G. M. Miller; <br\/>BPGbio Inc., Framingham, MA","CSlideId":"","ControlKey":"78bcfa9f-5c95-4eda-8fae-176543347655","ControlNumber":"6073","DisclosureBlock":"<b>&nbsp;N. M. Chand, <\/b> <br><b>BPGbio<\/b> Employment. <br><b>V. Vishnudas, <\/b> <br><b>BPGbio<\/b> Employment. <br><b>M. A. Kiebish, <\/b> <br><b>BPGbio<\/b> Employment. <br><b>A. Thakurta, <\/b> <br><b>BPGbio<\/b> Employment. <br><b>N. R. Narain, <\/b> <br><b>BPGbio<\/b> Employment. <br><b>S. Gesta, <\/b> <br><b>BPGbio<\/b> Employment. <br><b>G. M. Miller, <\/b> <br><b>BPGbio<\/b> Employment.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9384","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"19","PosterboardNumber":"19","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3527","PresenterBiography":null,"PresenterDisplayName":"Nischal Chand, MS","PresenterKey":"eb29ba9d-17f0-4618-a339-737aa5570220","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3527. Application of a deep learning based drug sensitivity prediction model on a novel anticancer drug","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Application of a deep learning based drug sensitivity prediction model on a novel anticancer drug","Topics":null,"cSlideId":""},{"Abstract":"N<sup>6<\/sup>-methyladenosine (m<sup>6<\/sup>A) is the most abundant mRNA modification with a crucial role in cellular processes. Its involvement in cancers is well-established. Dysregulation of m<sup>6<\/sup>A is linked to cancer initiation, progression, and therapy resistance, impacting the tumor microenvironment (TME) and promoting metastasis. Understanding m<sup>6<\/sup>A's regulatory role in cancer is essential for identifying new therapeutic targets. We considered the construction of a knowledge graph (KG) representing molecular regulatory mechanisms (MRMs) of m<sup>6<\/sup>A in healthy conditions and different cancers from PubMed papers. Such a KG consists of interconnected triplets of (head node, regulatory relationship, tail node), each denoting regulation between genes or a gene and a phenotype\/process. Advances in natural language processing (NLP) have provided tools such as SemRep and GNBR to automate the extraction of these triplets from the literature. However, these methods don&#8217;t extract contextual information, such as the type of cancers or cells in which these MRMs occur, leading to contradictory regulations in the constructed KG. In addition, existing approaches were designed to extract generic regulatory relations and therefore struggled in properly capturing unique concepts associated with m<sup>6<\/sup>A regulatory mechanisms. To tackle this challenge, we designed a novel ChatGPT-4 prompt to extract relational graphs from papers tailored for m<sup>6<\/sup>A regulatory mechanisms. An annotated dataset of 400 titles on m<sup>6<\/sup>A-related MRMs were created to evaluate the performance. We then applied the prompt to 1023 papers to create a m<sup>6<\/sup>A Molecular Regulatory Mechanism Knowledge Graph (m6A-MRM-KG). This graph illuminates m<sup>6<\/sup>A's roles in gene expression regulation, especially in cancer and immunity. Anticipated to enhance our understanding of cancer development, it provides insights into potential therapeutic strategies. The m6A-MRM-KG not only organizes information but also empowers researchers to uncover novel insights in the dynamic relationships of m<sup>6<\/sup>A modifications in diverse biological contexts.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,N6-methyladenosine,knowledge graph,ChatGPT,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>S. Jo<\/b><sup>1<\/sup>, X. Wu<sup>1<\/sup>, Y. Zeng<sup>2<\/sup>, A. Das<sup>2<\/sup>, T.-H. Zhang<sup>2<\/sup>, D. A. Spellman<sup>2<\/sup>, A. Ferris<sup>2<\/sup>, S.-J. Gao<sup>2<\/sup>, J. Zhang<sup>3<\/sup>, Y.-C. Chiu<sup>2<\/sup>, Y. Huang<sup>2<\/sup>; <br\/><sup>1<\/sup>University of Pittsburgh, Pittsburgh, PA, <sup>2<\/sup>University of Pittsburgh School of Medicine, Pittsburgh, PA, <sup>3<\/sup>The University of Texas at San Antonio, San Antonio, TX","CSlideId":"","ControlKey":"f4a10744-0928-46e3-b726-477fbc78a63b","ControlNumber":"6152","DisclosureBlock":"&nbsp;<b>S. Jo, <\/b> None..<br><b>X. Wu, <\/b> None..<br><b>Y. Zeng, <\/b> None..<br><b>A. Das, <\/b> None..<br><b>T. Zhang, <\/b> None..<br><b>D. A. Spellman, <\/b> None..<br><b>A. Ferris, <\/b> None..<br><b>S. Gao, <\/b> None..<br><b>J. Zhang, <\/b> None..<br><b>Y. Chiu, <\/b> None..<br><b>Y. Huang, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9385","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"20","PosterboardNumber":"20","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3528","PresenterBiography":null,"PresenterDisplayName":"Sumin Jo, MS","PresenterKey":"f0720864-2a73-455a-8d67-941efae3cdac","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3528. Constructing knowledge graph of N<sup>6<\/sup>-methyladnosion regulations in cancer from literature using ChatGPT-4","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Constructing knowledge graph of N<sup>6<\/sup>-methyladnosion regulations in cancer from literature using ChatGPT-4","Topics":null,"cSlideId":""},{"Abstract":"Turning early-cancer diagnosis into actionable treatment often relies on highly accurate and sensitive imaging techniques to guide surgical intervention or to monitor therapeutic efficacy. Earli is developing a highly sensitive, orthogonal approach that uses genetic constructs to usurp dysregulated cancer pathways to force the tumor to produce a PET reporter gene, enabling the use of radiotracers amenable to positron emission tomography\/computed tomography (PET\/CT) to guide precision imaging. However, analysis of PET\/CT images using standard manual and semi-automated methods is challenging resulting in reduced experimental throughput and user variability, highlighting the need for a fully automated PET\/CT analysis pipeline using Deep Learning (DL). To increase pre-clinical throughput and reduce inter-user variability, we developed an automated DL processing pipeline in Python to perform three major tasks: separation of multi-mouse bed data for PET uptake quantification by mouse, segmentation of tumors and background organs, and quantification of PET signal for PK\/PD analysis. Preclinical PET\/CT data was acquired using a 4 animal, multi-mouse bed and separated into individual mice by co-registering the reconstructed CT image against a multi-mouse bed reference mask using a rigid 3D Euler transformation algorithm and cropping at fixed indices. Following mouse separation, a 3D nnUNet architecture is used to perform semantic segmentation of regions of interest (ROI) on CT for bi-hemispheric subcutaneous tumors, lungs, liver, kidneys, spleen, and the bladder. nnUNet was trained on PET\/CT of 311 mice consisting of a mixture of na&#239;ve and tumor-bearing animals subcutaneously implanted with H1299 cells using a five-fold cross-validation strategy with 1000 epochs per fold. Model performance was evaluated by comparing the network prediction to the reference manually annotated masks using the Dice coefficient. PET uptake is reported as percent injected dose per milliliter (%ID\/mL) or standardized uptake value (SUV). Segmentation performance results for the hold-out set identified mean Dice scores greater than 0.80 for all ROIs, reflecting the similarity between model predictions and human annotations. The automated pipeline reduced the analysis time from 5.5-6 hours per mouse when using traditional manual\/semi-automatic approaches to approximately 15 minutes. In summary, we developed a fully automated DL-based PET\/CT quantification pipeline for pre-clinical mouse studies that provides accurate ROI segmentation and PET uptake quantification, significantly increasing experimental throughput and reducing inter-user variability. Further improvements to model inference include loss functions weighted for poor performing ROIs and addition of lung nodule segmentation for eventual translation to humans as an accompaniment to Earli&#8217;s theranostic programs.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Image analysis,Positron emission tomography (PET),Lung cancer,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>H.-Y. Lee<\/b>, M. Goryawala, T. Sproul, M. Louie, D. Suhy; <br\/>Earli Inc., Redwood City, CA","CSlideId":"","ControlKey":"d068fc6c-813a-482b-9da8-082938ea7e83","ControlNumber":"6176","DisclosureBlock":"&nbsp;<b>H. Lee, <\/b> None..<br><b>M. Goryawala, <\/b> None..<br><b>T. Sproul, <\/b> None..<br><b>M. Louie, <\/b> None..<br><b>D. Suhy, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9386","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"21","PosterboardNumber":"21","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3529","PresenterBiography":null,"PresenterDisplayName":"Hung-Yu Henry Lee, MS","PresenterKey":"802de40b-3fdc-4870-ad89-23e8397f5234","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3529. Leveraging deep learning for fully automated analysis of pre-clinical mouse positron emission tomography","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Leveraging deep learning for fully automated analysis of pre-clinical mouse positron emission tomography","Topics":null,"cSlideId":""},{"Abstract":"<b>Background:<\/b> Multiomics data is critical to obtain a near comprehensive picture of disease progression and drug response. In addition, the generation of response and survival biomarkers, and the segmentation of patients into subtypes with distinct, actionable &#8216;omic signatures and survival trajectories, is vital for personalised medicine research and successful trial design. However, as the volume and diversity of data increases, so too does the challenge of effective multiomic data integration. Knowledge graphs (KGs) can capture heterogeneous data and relationships between entities in a flexible and scalable data structure, making them suitable for this domain. We have developed PRESS<i>net<\/i>, a framework for building Patient KGs and analysing clinical data for novel patient stratification hypotheses and clinical biomarker discovery.<br \/><b>Methods: <\/b>PRESS<i>net<\/i> is an end-to-end framework that turns raw patient data into graph-derived insights. Firstly, the user chooses which modality files to include, what assumptions to make about data processing, and which graph algorithms to use. PRESS<i>net<\/i> then automatedly creates a patient KG of the input data, where nodes represent patients and their associated features. In addition, biomedical prior knowledge, for example in the form of gene-pathway or gene-gene relationship data, is also integrated with the graphs. Insights are generated from the KG via community detection, graph embedding generation, and graph neural networks; these generate hypotheses for novel patient subtypes or biomarkers for clinical outcomes. As graph algorithms capture interrelationships between nodes, PRESS<i>net<\/i> offers biomarkers that are composite, i.e. that can contain features from multiple &#8216;omics and clinical features.<br \/><b>Results: <\/b>We applied PRESS<i>net<\/i> to the MSK 2022<sup>1<\/sup> cohort of IO-treated LUAD patients, and it uncovered prognostic composite biomarkers that stratified biomarker-positive patients from the whole cohort with a p value &#60; 0.001 (95% CI) for OS, including known markers of poor prognosis such as STK11, RBM10, KRAS and KEAP1 mutations, and high neutrophil\/lymphocyte ratio. We also generated embeddings of patients in the cohort and predicted survived\/deceased status with an AUC of 0.82, outperforming published state-of-the-art.<br \/><b>Conclusions: <\/b>We have successfully developed a generalisable framework for generating insights from patient data using state-of-the art knowledge graph data science. PRESS<i>net<\/i> can generate novel stratification and biomarker hypotheses that can potentially inform the next generation of IO targets and clinical biomarkers.<br \/>Footnotes<sup>1<\/sup> Vanguri et al., &#8220;Multimodal integration of radiology, pathology and genomics for prediction of response to PD-(L)1 blockade in patients with non-small cell lung cancer&#8221;, Nat Cancer. 2022","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Biomarkers,Bioinformatics,NSCLC,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>K. C. Bulusu<\/b><sup>1<\/sup>, J. Cohen-Setton<sup>1<\/sup>, I. Kagiampakis<sup>2<\/sup>, M. Goncalves<sup>1<\/sup>, G. Edwards<sup>1<\/sup>, S. Jayabalan<sup>3<\/sup>, S. Shikare<sup>1<\/sup>, K. Tsang<sup>1<\/sup>, B. Sidders<sup>1<\/sup>, E. Jacob<sup>3<\/sup>; <br\/><sup>1<\/sup>AstraZeneca UK, Cambridge, United Kingdom, <sup>2<\/sup>AstraZeneca US, San Francisco, CA, <sup>3<\/sup>AstraZeneca US, Waltham, MA","CSlideId":"","ControlKey":"e6f94693-4fe7-4506-bb86-66bb5fb8255d","ControlNumber":"6899","DisclosureBlock":"<b>&nbsp;K. C. Bulusu, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>J. Cohen-Setton, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>I. Kagiampakis, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>M. Goncalves, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>G. Edwards, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>S. Jayabalan, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>S. Shikare, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>K. Tsang, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>B. Sidders, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock. <br><b>E. Jacob, <\/b> <br><b>AstraZeneca<\/b> Employment, Stock.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9388","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"22","PosterboardNumber":"23","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3531","PresenterBiography":null,"PresenterDisplayName":"Krishna Bulusu","PresenterKey":"3e07c722-695a-47f3-b43f-c48901c5afe2","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3531. PRESS<i>NET<\/i>: Patient stratification and biomarker discovery using multi-modal knowledge graph framework","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"PRESS<i>NET<\/i>: Patient stratification and biomarker discovery using multi-modal knowledge graph framework","Topics":null,"cSlideId":""},{"Abstract":"<b>Purpose: <\/b>In the realm of cancer treatment and research, the analysis of genomic data stands as a cornerstone for diagnosis and therapy. Recognizing this, our study embarks on an ambitious journey to revolutionize how we interpret such data. By converting complex genomic data into a two-dimensional (2D) image format leveraging feature correlations, we pave the way for more profound insights and applications in clinical decision-making. This innovative approach utilizes 2D convolutional neural networks (CNNs) to analyze these structured images, promising a leap forward in the accuracy and utility of such data.<br \/><b>Methodology: <\/b>The core of our method involves a novel transformation of tabular genomic data into an image format. We start with m patient samples, each characterized by n genes, and calculate a pairwise correlation matrix to capture the intricate relationships between these genes. Concurrently, we generate an Euclidean distance matrix that represents the distances between n points in a 2D grid. The next step involves the optimization of the Gromov-Wasserstein discrepancy to align these two matrices, resulting in a transformation matrix, T. When applied to the tabular data, T transforms it into m distinct, informative images. These images are then processed using a 10-layer CNN, comprising a convolutional layer (3x3 kernel), three dense layers, two relu layers, and a dropout layer.<br \/><b>Data Sources: <\/b>We created images, termed 'genomaps', from genomic data collected from three diverse patient groups: 130 individuals (cancerous and normal) from Stanford Hospital, 230 breast cancer patients from The Cancer Genome Atlas (TCGA), and a larger group of 1572 patients from the Memorial Sloan Kettering (MSK) Cancer Center. The created genomaps are visually interpretable, offering clear differentiation between cancerous and non-cancerous samples, which is pivotal for accurate analysis.<br \/><b>Outcomes: <\/b>Our method demonstrates a remarkable 8% improvement in survival prediction accuracy in comparison to the existing methods. The employment of DeepSHAP in our analysis has allowed us to identify critical genes with greater precision than conventional methods. The p53 gene family, notably TP53 and TP63, was identified as significantly mutated in over 50% of all cancer types analyzed. Another critical discovery was the ERBB gene family, encompassing EGFR, ERBB2, ERBB3, ERBB4, which plays a dual role in tumor proliferation and influencing the immune response against tumors, a factor critical for immunotherapy strategies.<br \/><b>Conclusion: <\/b>This research introduces a transformative approach to represent genomic data, utilizing 2D CNNs for in-depth analysis. It sets a new benchmark in classification and regression accuracy, offering a more interpretable pathway for biomarker discovery, significantly contributing to the field of personalized medicine and cancer research.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Genomics,Deep learning,Cancer genomics,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>M. Islam<\/b>, L. Xing; <br\/>Stanford University School of Medicine, Palo Alto, CA","CSlideId":"","ControlKey":"4fe6f178-46cd-4d33-82a0-9837e83adfc7","ControlNumber":"7070","DisclosureBlock":"&nbsp;<b>M. Islam, <\/b> None..<br><b>L. Xing, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9389","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"23","PosterboardNumber":"24","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3532","PresenterBiography":null,"PresenterDisplayName":"Md Tauhidul Islam","PresenterKey":"7d93190f-1d05-430d-88c3-9eb5bedcaafd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3532. Transforming genomic data into images for enhanced deep learning in precision oncology","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Transforming genomic data into images for enhanced deep learning in precision oncology","Topics":null,"cSlideId":""},{"Abstract":"This study focuses on the integration of Artificial Intelligence (AI) with Spatially Resolved Laser-Activated Cell Sorting (SLACS) for enhanced pathological analysis and biomarker discovery. The primary approach involves using AI to automatically analyze slide images, identifying critical areas associated with diseases such as cancer or cells emitting specific signals. AI algorithms efficiently segment these significant regions or cellular groups, facilitating targeted analysis.<br \/>Following the AI-driven segmentation, SLACS comes into play, isolating the identified cells from the slide for further examination. This precise sorting allows for the focused study of cells relevant to disease processes, enhancing the efficiency and accuracy of pathological analysis.<br \/>The separated samples obtained through SLACS are then subjected to detailed analysis. This step is crucial for understanding the cellular mechanisms at play in disease states and for the identification of potential biomarkers. These biomarkers are vital for developing targeted therapeutic strategies and advancing personalized medicine.<br \/>By combining AI's advanced image processing and pattern recognition capabilities with the precision of SLACS, this integrated approach significantly improves the identification and analysis of disease-related cellular characteristics. It streamlines the process of isolating and studying specific cell populations, contributing to a deeper understanding of disease mechanisms and progression.<br \/>In conclusion, the synergistic application of AI and SLACS represents a significant advancement in pathological research and biomarker discovery. This methodology not only enhances the accuracy of disease marker identification but also opens new avenues for research and clinical application.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Cancer markers,Biomarkers,Breast cancer,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>H. Jang<\/b><sup>1<\/sup>, A. C. Lee<sup>2<\/sup>, S. Lee<sup>2<\/sup>, S. Kwon<sup>1<\/sup>; <br\/><sup>1<\/sup>Seoul National University, Seoul, Korea, Republic of, <sup>2<\/sup>Meteor Biotech, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"580b67b4-1aac-408d-8e38-ccfbb99e21a8","ControlNumber":"7119","DisclosureBlock":"&nbsp;<b>H. Jang, <\/b> None..<br><b>A. C. Lee, <\/b> None..<br><b>S. Lee, <\/b> None..<br><b>S. Kwon, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9390","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"24","PosterboardNumber":"25","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3533","PresenterBiography":null,"PresenterDisplayName":"Haewook Jang","PresenterKey":"cd95dc09-65b7-4489-bddd-53a269b2bec1","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3533. Spatially Resolved Laser-Activated Cell Sorting (SLACS) and AI integration for enhanced pathological analysis and biomarker discovery","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Spatially Resolved Laser-Activated Cell Sorting (SLACS) and AI integration for enhanced pathological analysis and biomarker discovery","Topics":null,"cSlideId":""},{"Abstract":"<b>INTRODUCTION: <\/b>Our understanding of gene properties has advanced through representation learning such as Alpha fold. Representation learning involves encoding the relationships between genes by embedding them into a numerical space. These embeddings, which capture complex genetic interactions and characteristics, can then be leveraged by machine learning models to predict various gene properties. Current embeddings derive from transcriptome or sequence data. Over the past 150 years, numerous experimental assays have uncovered gene functions and interactions- comprehensive knowledge documented in the literature but not always evident in transcriptome or sequence data. It has been posited that leveraging this knowledge to create gene embeddings; however, could result in machine learning models biased towards well-studied genes.<br \/><b>METHODS AND RESULTS: <\/b>We tested this hypothesis by developing a novel knowledge-embedding framework, GeneLLM. During training, GeneLLM learns to comprehend summaries of every gene- a compressed form of published knowledge- using Large Language Models (LLMs), fine-tuned for downstream tasks mapping cellular properties and biochemical processes. Despite the expected bias towards well-known genes, GeneLLM surprisingly showed high predictive power for an array of gene properties. Compared to baseline models, GeneLLM boosted an increase in performance of 20.3% correlation in gene conservation across species, 8.6% and 57.2% prediction accuracy in subcellular localization and gene ontology respectively. GeneLLM also showed competitive results on solubility prediction with 0.91 accuracy and a correlation of 0.71 for tissue-specific expression levels for 1001 cell lines. We also showed that the bias toward well-known genes could be mitigated by combining GeneLLM representation with transcriptome or sequence-based embedding. The combined embeddings exhibited superior performance to their individual components which suggests that GeneLLM extracts views complementary to existing embedding methods.<br \/><b>CONCLUSION: <\/b>The GeneLLM framework demonstrates the ability of LLMs to extract information from the rich knowledge available about the nexus of genes and their cellular traits. It also illustrates how bias in knowledge representation is complementary to other transcriptome and sequence-based information. This ability of GeneLLM to advance our understanding of genes, their roles in cellular processes, and their impact on oncogenesis, as well as in response and resistance mechanisms, highlights its potential in cancer research.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>A. Jararweh<\/b>, K. Virupakshappa, O. S. Macaulay, A. Segura, O. M. Oyebamiji, Y. Hu, A. D. Sahu; <br\/>University of New Mexico, Albuquerque, NM","CSlideId":"","ControlKey":"b925b37e-ee05-4d0a-9429-71e19f2955e7","ControlNumber":"7523","DisclosureBlock":"&nbsp;<b>A. Jararweh, <\/b> None..<br><b>K. Virupakshappa, <\/b> None..<br><b>O. S. Macaulay, <\/b> None..<br><b>A. Segura, <\/b> None..<br><b>O. M. Oyebamiji, <\/b> None..<br><b>Y. Hu, <\/b> None..<br><b>A. D. Sahu, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9391","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"25","PosterboardNumber":"26","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3534","PresenterBiography":null,"PresenterDisplayName":"Ala Jararweh, BS","PresenterKey":"c833d200-cca8-48db-b920-cec248726d71","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3534. GeneLLM: Unveiling gene functions through literature-driven transformer embeddings","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"GeneLLM: Unveiling gene functions through literature-driven transformer embeddings","Topics":null,"cSlideId":""},{"Abstract":"We developed 42 machine learning models using Knowledge Graphs (KGML), informed by data from Pharos (1), based on major resources like DepMap (2), Reactome (3), and STRING (4). Focused on 41 blood cancers, we utilized cancer-specific positive genes and 440 shared negative genes, using metapath and XGBoost (5).<br \/>Analysis of the top 500 genes from each model revealed 3,842 genes strongly linked to cancers, with 519 classified as &#8220;Tchem,&#8221;i.e., small molecule modulators are known (6). We focused on Tchem proteins given the notion that small molecules perturbing these proteins are already known, which accelerates drug discovery. A separate, 1SVM (one-class support vector machine) model was built using mode-of-action drug targets (6) (Tclin, N = 704) as input. This 42<sup>nd<\/sup> model evaluates the likelihood that a gene shares the characteristics of Tclin targets (&#8220;Tclin-like&#8221;). Of the 519 Tchem genes, 132 have &#8220;Tclin-like&#8221; probability above 50%. The top five &#8220;Tclin-like&#8221; genes are GAPDH, AKT1, HRAS, TLR4 and TP53, respectively; their role in cancer is well studied.<br \/>Our focus shifted to 19 genes that have limited or no known cancer associations, as evaluated by the DISEASES platform (7) - see Table 1. Three genes (LPAR5, GPR18 and FCER2) are associated with primary bone diffuse large B cell lymphoma, and 2 (ADCY1 and PLD1) with B cell prolymphocytic leukemia. Additional studies may elucidate their role in these malignancies. Five genes (IRAK3, EPHB1, ITPKB, ACVR2B and CAMK2D) are predicted to be relevant in 10 or more blood cancers. Machine learning may uncover overlooked, but potentially promising drug targets for leukemias, lymphomas and myelomas.<br \/><b>References<\/b><b><\/b> 1. Kelleher KJ, et al. <i>Nucl<\/i><i> Acids Res.<\/i> 2023; 51:D1405-16.2. Tsherniak A, et al. <i>Cell<\/i>. 2017; 170:564-76.e16.3. Gillespie M, et al. <i>Nucl<\/i><i> Acids Res<\/i>. 2022; 50:D687-92.4. Szklarczyk D, et al. <i>Nucl Acids Res.<\/i> 2023; 51:D638-46.5. Binder J, et al. <i>Commun Biol.<\/i> 2022; 5:125.6. Oprea TI, et al. <i>Nat Rev Drug Discov.<\/i> 2018; 17:317-32.7. Grissa D, et al. <i>Database.<\/i> 2022; 2022:baac019.<br \/><table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{303ADFA1-D061-4351-B229-EC1278C6566F}\"><caption>Table 1: &#8220;Tclin-like&#8221; targets lacking known cancer associations.<\/caption><tr><td rowspan=\"1\" colspan=\"1\"><b>Gene<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>41 Cancer&nbsp;<\/b><b><\/b><b>counts<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Disease names<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">LPAR5<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">primary bone diffuse large B cell lymphoma<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">ADCY1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">B cell prolymphocytic leukaemia<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">ITPKB<\/td><td rowspan=\"1\" colspan=\"1\">15<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">PLD1<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">B cell prolymphocytic leukaemia<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">PRKCE<\/td><td rowspan=\"1\" colspan=\"1\">2<\/td><td rowspan=\"1\" colspan=\"1\">hepatosplenic T cell lymphoma; acute leukaemia of ambiguous lineage<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">EPHB1<\/td><td rowspan=\"1\" colspan=\"1\">17<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">GPR18<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">primary bone diffuse large B cell lymphoma<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">FRK<\/td><td rowspan=\"1\" colspan=\"1\">3<\/td><td rowspan=\"1\" colspan=\"1\">chronic myeloid leukaemia; acute myeloid leukaemia therapy related; NK cell leukaemia<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">CAMK2D<\/td><td rowspan=\"1\" colspan=\"1\">13<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">IRAK3<\/td><td rowspan=\"1\" colspan=\"1\">20<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">TRPV4<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">primary central nervous system lymphoma<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">ACVR2B<\/td><td rowspan=\"1\" colspan=\"1\">14<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">TRPC6<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">Hodgkin lymphoma<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">FCER2<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">primary bone diffuse large B cell lymphoma<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">GRM8<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">acute myeloid leukaemia therapy related<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">CAMK2A<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">hepatosplenic T cell lymphoma<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">BLK<\/td><td rowspan=\"1\" colspan=\"1\">4<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">ADORA3<\/td><td rowspan=\"1\" colspan=\"1\">1<\/td><td rowspan=\"1\" colspan=\"1\">acute leukaemic transformation of myeloproliferative neoplasm<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">PIM1<\/td><td rowspan=\"1\" colspan=\"1\">8<\/td><td rowspan=\"1\" colspan=\"1\"><\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Leukemias,Lymphoma,Target discovery,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"M. Quazi<sup>1<\/sup>, S. Sirimulla<sup>1<\/sup>, C. G. Bologa<sup>2<\/sup>, A. Pushechnikov<sup>1<\/sup>, N. Savchuk<sup>1<\/sup>, <b>T. I. Oprea<\/b><sup>1<\/sup>; <br\/><sup>1<\/sup>Expert Systems, Inc., San Diego, CA, <sup>2<\/sup>University of New Mexico School of Medicine, Albuquerque, NM","CSlideId":"","ControlKey":"59687364-a9a3-4af2-abd1-651015f8f07a","ControlNumber":"7888","DisclosureBlock":"<b>&nbsp;M. Quazi, <\/b> <br><b>Roivant Sciences<\/b> Employment, Stock. <br><b>Expert Systems Inc<\/b> Employment. <br><b>S. Sirimulla, <\/b> <br><b>Roivant Sciences Inc<\/b> Employment, Stock. <br><b>Expert Systems Inc.<\/b> Employment. <br><b>C. G. Bologa, <\/b> <br><b>Roivant Sciences Inc<\/b> Employment, Stock. <br><b>A. Pushechnikov, <\/b> <br><b>Expert Systems Inc<\/b> Stock. <br><b>Torrey Pines Investment<\/b> Employment. <br><b>N. Savchuk, <\/b> <br><b>Expert Systems Inc<\/b> Other Business Ownership. <br><b>Torrey Pines Investment<\/b> Employment, Other Business Ownership. <br><b>T. I. Oprea, <\/b> <br><b>Roivant Sciences Inc<\/b> Employment, Stock. <br><b>InSilico Medicine<\/b> Stock Option. <br><b>Expert Systems Inc<\/b> Employment.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9392","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"26","PosterboardNumber":"27","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3535","PresenterBiography":null,"PresenterDisplayName":"Tudor Oprea, MD,PhD","PresenterKey":"78f894d1-ccb5-4cef-8b8b-e04b9bdfd7b6","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3535. Seeking novel therapeutic targets in oncology using machine learning","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Seeking novel therapeutic targets in oncology using machine learning","Topics":null,"cSlideId":""},{"Abstract":"\u0009Variants of uncertain significance constitute the vast majority of missense variants, hampering the utility of genetic testing, despite its remarkable impacts on clinical diagnosis and decision-making. Although the sequencing and interpretation of genetic variants have been drastically improved in recent years, only about 2% of novel missense variants are currently clinically actionable. Therefore, a robust and scalable pipeline is desperately needed to provide functional evidence critical for variant interpretation. In this work, we demonstrate Paracell, a deep learning-based phenotypic profiling pipeline that leverages subcellular segmentation, high-dimensional single-cell phenotyping, and machine learning to classify the functional impact of variants. Paracell captures heterogeneity in cellular phenotypes and protein colocalization between variants and their signaling partners, as well as subcellular markers, and enables analysis at a single-cell resolution. Using a classification model trained on single-cell features extracted by Paracell, we were able to accurately classify cells from loss-of-function (LoF) variants based on their impact. After aggregating cellular profiles on a variant level, our pipeline was able to distinguish LoF variants from functional ones with high sensitivity and specificity. Our work demonstrates that Paracell is a robust and scalable method that can sensitively detect differences in single-cell phenotypic profiles. The systematic application of this pipeline will provide valuable functional evidence for variant interpretation, enhancing their clinical utility and accelerating personalized cancer care.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"High-content screening,Single cell,Deep learning,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>D. L. Nguyen<\/b><sup>1<\/sup>, J. T. Chao<sup>2<\/sup>; <br\/><sup>1<\/sup>Queen's University, Kingston, ON, Canada, <sup>2<\/sup>Sunnybrook Research Institute, Toronto, ON, Canada","CSlideId":"","ControlKey":"9e4dadbc-db0c-4c4e-8ba6-3e20d539aaa0","ControlNumber":"8030","DisclosureBlock":"&nbsp;<b>D. L. Nguyen, <\/b> None..<br><b>J. T. Chao, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9393","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"27","PosterboardNumber":"28","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3536","PresenterBiography":"","PresenterDisplayName":"David Nguyen, No Degree","PresenterKey":"782e3275-ad08-421d-be2d-c8f097d3e5e0","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3536. Paracell: A high throughput, deep learning-based pipeline for single-cell phenotypic profiling","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Paracell: A high throughput, deep learning-based pipeline for single-cell phenotypic profiling","Topics":null,"cSlideId":""},{"Abstract":"Accurate prediction of drug response using machine learning (ML) remains a significant challenge in drug development as well as in personalized cancer therapy. Furthermore, there is a scarcity of rigorous external validation studies for evaluating drug response prediction models. Even when available, such validations are often confined to in-vitro studies. Orthotopic patient-derived xenograft (O-PDX) mice serve as essential preclinical models that closely replicate the human tumor microenvironment and assess the therapeutic response to cancer treatments. We present CertisAI<sup>TM<\/sup>, a novel ensemble of machine learning models that have been trained on a vast array of experimental high-throughput screenings of both monotherapies and combination therapies, incorporating over 4500 investigational and FDA-approved drugs across 10 major cancer indications. The results of our ML drug response prediction models show an average R<sup>2<\/sup> of 0.75 and RMSE of 0.62 (across internal 5-fold cross-validation) for all 10 cancer prediction models. Our evaluation of CertisAI's drug response predictions within O-PDX pharmacology studies has shown a notable overall correlation between actual observed tumor growth inhibition (TGI) and predicted TGI, with an r value of 0.45 across seven indications. The most accurate prediction model achieved an r value of 0.7 for colorectal cancer, encompassing 37 treatments in 6 O-PDX studies. Altogether, these results highlight CertisAI&#8217;s potential in enhancing pre-clinical model selection as well as personalized treatment strategies in oncology.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null},{"Icon":null,"Label":"View Video","SubType":null,"Type":"ViewPlayer","Url":null},{"Icon":null,"Label":"Rating","SubType":null,"Type":"Rating","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Precision medicine,Predictive biomarkers,Drug sensitivity,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":[],"AllowAttendeeRating":"False","AttendeeRatingAvg":"0","AttendeeRatingCount":"0","AuthorBlock":"<b>Y.-H. Chien<\/b>, R. Pippa, W. Andrews, J. Rodriguez, K. Buck, D. Gorospe, E. Valencia, B. Carapia, E. Eastwood, J. Sperry, J. Nakashima, L. Do; <br\/>Certis Oncology Solutions, San Diego, CA","CSlideId":"","ControlKey":"09fd235f-00fc-4dbd-85b5-f2f0af985cfb","ControlNumber":"8353","DisclosureBlock":"&nbsp;<b>Y. Chien, <\/b> None..<br><b>R. Pippa, <\/b> None..<br><b>W. Andrews, <\/b> None..<br><b>J. Rodriguez, <\/b> None..<br><b>K. Buck, <\/b> None..<br><b>D. Gorospe, <\/b> None..<br><b>E. Valencia, <\/b> None..<br><b>B. Carapia, <\/b> None..<br><b>E. Eastwood, <\/b> None..<br><b>J. Sperry, <\/b> None..<br><b>J. Nakashima, <\/b> None..<br><b>L. Do, <\/b> None.","End":"4\/8\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9394","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":"None","OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":null,"PositionInSession":"28","PosterboardNumber":"29","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"3537","PresenterBiography":null,"PresenterDisplayName":"YUAN-HUNG Chien","PresenterKey":"f1e469c9-2654-40ca-929a-405113293d19","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"3537. Assessing machine learning models of drug response predictions using orthotopic patient-derived xenograft","SearchResultFooter":"","SearchResultHeader":"Apr  8 2024  1:30PM","SessionId":"194","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 2","ShowChatLink":"false","Start":"4\/8\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Assessing machine learning models of drug response predictions using orthotopic patient-derived xenograft","Topics":null,"cSlideId":""}]