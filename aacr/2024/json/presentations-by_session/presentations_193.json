[{"Abstract":"Precision in diagnosis of diverse central nervous system (CNS) tumor types is crucial for optimal patient treatment. DNA methylation profiles, which capture the methylation status of thousands of individual CpG sites, are data-driven means to enhance diagnostic accuracy, but this technique is expensive, time-consuming, and not yet routinely available. To address this, we developed DEPLOY, a deep-learning model that predicts 10 major categories of CNS tumors from histopathology. DEPLOY integrates three distinct components: the first classifies CNS tumors directly from histopathology slide images (&#8216;direct model&#8217;); the second initially generates predictions for DNA methylation beta values, which are subsequently used for tumor classification (&#8216;indirect model&#8217;); and the third classifies tumor types directly from routinely available patient demographics. First, we find that DEPLOY accurately predicted beta values from histopathology images, suggesting that application of inferred methylation data is a promising approach for deep learning histopathology-based classifiers. Using a 10-class model trained on an internal dataset, we apply this model on two independent external test datasets of 1,522 and 348 cases, achieving top-1 accuracies of 96% and 94%, respectively on samples which are predicted with high confidence. Taken together, DEPLOY could assist pathologists in diagnosing CNS tumors, in an equitable very low-cost manner, within a clinically relevant short time frame.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Histopathology,Brain tumors,Diagnosis,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>E. D. Shulman<\/b><sup>1<\/sup>, D.-T. Hoang<sup>2<\/sup>, R. Turakulov<sup>1<\/sup>, Z. Abdullaev<sup>1<\/sup>, O. Singh<sup>1<\/sup>, E. M. Campagnolo<sup>1<\/sup>, E. A. Stone<sup>2<\/sup>, M. P. Nasrallah<sup>3<\/sup>, E. Ruppin<sup>1<\/sup>, K. Aldape<sup>1<\/sup>; <br\/><sup>1<\/sup>NIH-NCI, Bethesda, MD, <sup>2<\/sup>Australian National University, Canberra, Australia, <sup>3<\/sup>Perelman School of Medicine at the University of Pennsylvania, Philadelphia, PA","CSlideId":"","ControlKey":"13aae49c-731f-4f2d-8427-3497a0c8fbba","ControlNumber":"843","DisclosureBlock":"<b>&nbsp;E. D. Shulman, <\/b> <br><b>Pangea Biomed<\/b> Employment, I was working for Pangea Biomed till October 2021. I am not working for them or any financial relationships with any ineligible companies scince then..<br><b>D. Hoang, <\/b> None..<br><b>R. Turakulov, <\/b> None..<br><b>Z. Abdullaev, <\/b> None..<br><b>O. Singh, <\/b> None..<br><b>E. M. Campagnolo, <\/b> None..<br><b>E. A. Stone, <\/b> None..<br><b>M. P. Nasrallah, <\/b> None..<br><b>E. Ruppin, <\/b> None..<br><b>K. Aldape, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9337","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"1","PosterboardNumber":"1","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"886","PresenterBiography":null,"PresenterDisplayName":"Eldad Shulman, BS;MA;MS;PhD","PresenterKey":"5d872eba-8b0c-45bf-9243-5e3d9381c85b","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"886. Integrated deep learning model for predicting DNA methylation and tumor types from histopathology in central nervous system tumors","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Integrated deep learning model for predicting DNA methylation and tumor types from histopathology in central nervous system tumors","Topics":null,"cSlideId":""},{"Abstract":"Segmentation of lung tumors is an important step in the planning of clinical treatment and operative procedures. Automatic segmentation of advanced lung tumors is challenging due to local invasion and heterogeneous metastasis. Fully automatic deep learning models often fail to accurately delineate advanced disease boundaries and do not allow the user to provide hints to improve segmentation performance. In contrast, interactive segmentation accepts user inputs and is an efficient way to segment lesions while reducing radiologist effort.<br \/>This paper describes an interactive segmentation approach for lung lesion segmentation in CT scans. Our pipeline is built atop the SwinUNETR neural network architecture and can be expanded to support alternate models. The backbone model accepts radiologists' hints in the form of mouse clicks that indicate whether a location on the scan corresponds to a lesion. Our approach has the following novel contributions: (1) Context-aware encoding of guidance clicks by combining geodesic and Gaussian smoothing, resulting in improved segmentation of lesion boundaries. (2) An iterative prompting strategy to achieve higher accuracy with fewer clicks at inference time. (3) Guidance-aware Conditional Random Fields to refine the produced segmentation masks. (4) Volume cropping around guidance clicks at inference to improve segmentation precision and inference speed. (5) Linearly scaling our approach on multiple GPUs, to improve inference speed.<br \/>On a public non-small cell lung cancer dataset predominantly containing advanced stage cancers (68\\% stage III, and 27\\% stage IV), our interactive approach delivers a Dice score of 0.74 with a single click, a 21\\% improvement from the fully automatic approach (Dice Score = 0.61), and a Dice score of 0.81 with 5 clicks, which is a 33\\% improvement. Inference speed is an important metric for an interactive pipeline. On a typical 350 $\\times$ 350 $\\times$ 150 voxel chest CT scan volume, our interactive approach infers 5 times faster than the original fully automated approach on a single GPU. After scaling to 4 GPUs, we infer in only 0.5 seconds; 20 times faster than the original approach. Qualitative evaluation from three independent radiologists indicates that our interactive pipeline significantly improved their standard clinical segmentation experience.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Lung cancer: non-small cell,,Deep learning,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>M. Patwari<\/b><sup>1<\/sup>, Y. Wei<sup>1<\/sup>, M. Xu<sup>1<\/sup>, Z. Zhang<sup>2<\/sup>, K. Sidiropoulos<sup>1<\/sup>, B. Selvaraj<sup>3<\/sup>, G. Hughes<sup>1<\/sup>, N. Garibli<sup>1<\/sup>, K. Ojiako<sup>1<\/sup>, M. Lella<sup>1<\/sup>, L. Fedden<sup>1<\/sup>, J. Parkin<sup>1<\/sup>, M. Parker<sup>1<\/sup>, S. Patel<sup>1<\/sup>, Q. Li<sup>4<\/sup>, K. Patwardhan<sup>4<\/sup>; <br\/><sup>1<\/sup>ASTRAZENECA UK LIMITED, Cambridge, United Kingdom, <sup>2<\/sup>ASTRAZENECA, Gaithersburg, MD, <sup>3<\/sup>ASTRAZENECA AB, Gothenburg, Sweden, <sup>4<\/sup>ASTRAZENECA, Waltham, MA","CSlideId":"","ControlKey":"a9204c44-a87c-45a4-8db3-088e26996c6d","ControlNumber":"1303","DisclosureBlock":"<b>&nbsp;M. Patwari, <\/b> <br><b>AstraZeneca plc<\/b> Employment. <br><b>Y. Wei, <\/b> <br><b>AstraZeneca plc<\/b> Employment. <br><b>M. Xu, <\/b> <br><b>AstraZeneca plc<\/b> Employment. <br><b>Z. Zhang, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>K. Sidiropoulos, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>B. Selvaraj, <\/b> <br><b>AstraZeneca AB<\/b> Employment. <br><b>G. Hughes, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>N. Garibli, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>K. Ojiako, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>M. Lella, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>L. Fedden, <\/b> <br><b>AstraZeneca plc<\/b> Employment. <br><b>J. Parkin, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>M. Parker, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>S. Patel, <\/b> <br><b>AstraZeneca plc<\/b> Independent Contractor. <br><b>Q. Li, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>K. Patwardhan, <\/b> <br><b>AstraZeneca<\/b> Employment.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9338","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"2","PosterboardNumber":"2","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"887","PresenterBiography":null,"PresenterDisplayName":"Mayank Patwari","PresenterKey":"e40b6ebc-db27-4efa-a2d7-dff4833f1137","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"887. Fast, interactive, AI-assisted 3D lung tumour segmentation","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Fast, interactive, AI-assisted 3D lung tumour segmentation","Topics":null,"cSlideId":""},{"Abstract":"Despite advancements in deep learning for histopathology, integrating these insights with multi-omics data to uncover clinically relevant omics pathway-level signatures remains a challenge. Our study addresses this gap by applying unsupervised learning techniques on pan-cancer multi-omics data, leveraging 3,080 Hematoxylin and Eosin (H&#38;E) images from 1,010 patients in Clinical Proteomic Tumor Analysis Consortium (CPTAC) to uncover omics pathway-level signatures that drive discernable morphology phenotypes at the tissue level. First, imaging models were trained to predict clinical and mutation outcomes, and thereafter, integrated with transcriptomic and proteomic expression data using sparse canonical correlation analysis. Our findings reveal that images of TP53 mutated samples exhibited increased nuclear size and dense lymphoplasmacytic infiltration. These morphological changes correlated with neutrophil and macrophage signaling at the proteomic level, and IL-1 mediated signaling at the transcriptomic level, highlighting the complementary perspectives different omics can provide.<br \/>To further elucidate immune interactions, we applied multi-omics deconvolution to identify 7 immune subtypes, characterizing each with gene set enrichment, germline DNA variations, and kinase activations. We show that imaging models trained to predict these subtypes differentiate tissue morphologies corresponding to immune enrichment (AUROC: 0.84). To further confirm the robustness of our approach, we trained models to predict co-regulated proteomic modules clustered by independent component analysis. We demonstrate a signature in pan-squamous tumors, consisting of T cell markers and interferon-gamma response proteins like CD4, CD48, and GBP5, which imaging models can successfully predict from histopathology. Manual review from pathologists confirmed lymphocytic T-cell density as a differentiator in samples with the highest and lowest T-cell signaling.<br \/>Together, these approaches demonstrate that genomic characteristics discovered via unbiased mining of pan-cancer multi-omics data manifest as quantitative imaging phenotypes. These results underscore the potential of multi-omics and digital pathology to integratively uncover and confirm new cancer biology. Our ongoing work will explore predicting drug response and survival from morphology patterns related to multi-omics signatures.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Imaging,Machine learning,Histopathology,Multiomics,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>J. Wang<\/b>, R. Hong, J. Tan, W. Liu, D. Feny&#559;; <br\/>NYU Grossman School of Medicine, New York, NY","CSlideId":"","ControlKey":"00249c40-a0e3-4ef5-8b15-b1c004fcc2b9","ControlNumber":"1328","DisclosureBlock":"&nbsp;<b>J. Wang, <\/b> None..<br><b>R. Hong, <\/b> None..<br><b>J. Tan, <\/b> None..<br><b>W. Liu, <\/b> None..<br><b>D. Feny&#559;, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9339","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"3","PosterboardNumber":"3","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"888","PresenterBiography":null,"PresenterDisplayName":"Joshua Wang, BS","PresenterKey":"0215562f-dbf3-43ef-9c01-7a880152f79e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"888. Uncovering clinically relevant omics signatures from pan-cancer imaging and multi-omics data integration","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Uncovering clinically relevant omics signatures from pan-cancer imaging and multi-omics data integration","Topics":null,"cSlideId":""},{"Abstract":"Targeted DNA sequencing of cancer-associated genes has been widely adopted clinically. In addition, the increasing availability of targeted and whole-exome\/genome sequencing (WES\/WGS)-derived big data suggests avenues of computationally enhancing power of targeted assays via machine learning. We directly compared targeted (MSK-IMPACT) and WES in a cohort of 1,483 cancer patients using the same DNA libraries. We found high sensitivity and specificity of mutation detection by WES for overlapping genes. Comparatively higher estimates of tumor mutation burden by MSK-IMPACT arose from enrichment of oncogenic mutations in the targeted gene set. WES had minimal value in identifying actionable alterations beyond those from MSK-IMPACT, whereas RNA-sequencing identified additional targetable fusions that led to durable responses. We developed a deep learning-based algorithm (DeepSig) that enhances power of mutational signature detection, enabling detection of a select group of signatures with mutation counts of ~5 or less. Hypermutation-associated signatures, including POLE, temozolomide, and mismatch repair deficiency could be detected robustly using targeted sequencing data. In summary, WES had limited clinical value over targeted sequencing panels and future clinical diagnostic development should focus on transcriptome and WGS that can detect additional signatures and gene fusions.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Targeted sequencing,Whole exome sequencing,Precision medicine,Deep learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>H. Woo<\/b>, S. S. Chavan, A. J. Hanrahan, A. L. Richards, A. Noronha, A. Zehir, A. Drilon, M. F. Berger, D. B. Solit, M. T. A. Donoghue; <br\/>Memorial Sloan Kettering Cancer Center, New York, NY","CSlideId":"","ControlKey":"aa16553b-ae64-4279-b25c-b29ec553c9c4","ControlNumber":"1466","DisclosureBlock":"&nbsp;<b>H. Woo, <\/b> None..<br><b>S. S. Chavan, <\/b> None..<br><b>A. J. Hanrahan, <\/b> None..<br><b>A. L. Richards, <\/b> None..<br><b>A. Noronha, <\/b> None..<br><b>A. Zehir, <\/b> None..<br><b>A. Drilon, <\/b> None..<br><b>M. F. Berger, <\/b> None..<br><b>D. B. Solit, <\/b> None..<br><b>M. T. A. Donoghue, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9340","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"4","PosterboardNumber":"4","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"889","PresenterBiography":null,"PresenterDisplayName":"Jun Woo, PhD","PresenterKey":"effe9f86-2e43-436f-812a-4fe39093591b","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"889. Machine learning-enhanced targeted versus whole-exome sequencing as a guide to cancer care","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Machine learning-enhanced targeted versus whole-exome sequencing as a guide to cancer care","Topics":null,"cSlideId":""},{"Abstract":"In early-stage hormone receptor-positive breast cancer, genomic risk scores identify patients who stand to benefit from up-front chemotherapy but introduce financial and logistical hurdles to care. We assembled a cohort of 5,244 patients with 11,671 corresponding whole-side images of breast tumors stained with hematoxylin and eosin. We developed a multimodal machine learning model to infer risk of distal metastatic recurrence from routine clinical data. Specifically, the model interprets text from the pathologist&#8217;s report using a large language model and uses self-supervised vision transformers to interpret the corresponding whole-slide image. Tensor fusion joins the modalities to infer Genomic Health&#8217;s Oncotype DX recurrence score. Inferred recurrence score from the multimodal model correlated with measured score with a concordance correlation coefficient of 0.64 (95% C.I. 0.59 - 0.69) in the withheld test set, compared to 0.55 (95% C.I. 0.49 - 0.61) and 0.56 (95% C.I. 0.52 - 0.60) for the linguistic and visual unimodal models, respectively. The multimodal model attains an area under the precision-recall curve (AUPRC) of 0.69 (AUROC=0.88) for identifying high-risk disease in the full-information setting (when images and pathology reports with quantitative hormone receptor status and grade are available) in a withheld test set, compared to AUPRC of 0.61 and 0.66 for the linguistic and visual models, respectively. By comparison, in the same full-information setting, the clinical nomogram introduced by Orucevic et al. in 2019 achieves an AUPRC of 0.48. We suggest the operating point at which precision is 94.4% and recall is 33.3%. Digitized whole-slide images of routine breast biopsies and their associated synoptic pathology reports contain much of the information necessary to stratify patients by risk of distal metastatic recurrence, when modeled appropriately. Our model could enable hospitals to rapidly triage the need for genomic risk testing, possibly precluding one third of orders without loss of accuracy. This helps allocate scarce resources for genomic tests and valuable weeks prior to beginning therapy while maintaining the standard of precision oncology.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Breast cancer,Machine learning,Biomarkers,Deep learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>K. M. Boehm<\/b>, A. Marra, J. S. Reis-Filho, S. Chandarlapaty, F. Pareja, S. P. Shah; <br\/>Memorial Sloan Kettering Cancer Center, New York, NY","CSlideId":"","ControlKey":"13fb1616-fd2b-4e06-ba2c-ab6288e95f0c","ControlNumber":"2285","DisclosureBlock":"&nbsp;<b>K. M. Boehm, <\/b> None..<br><b>A. Marra, <\/b> None.&nbsp;<br><b>J. S. Reis-Filho, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>Goldman Sachs<\/b> Other, Consultant. <br><b>Eli Lilly<\/b> Other, Consultant. <br><b>Saga Diagnostics<\/b> Other, Consultant. <br><b>Repare Therapeutics<\/b> Stock, Other, Advisory board, consultant. <br><b>Paige.AI<\/b> Stock Option, Other, Advisory board, consultant. <br><b>Personalis<\/b> Other, Advisory board. <br><b>Roche Tissue Diagnostics<\/b> Other, Advisory board. <br><b>Bain Capital<\/b> Other, Advisory board. <br><b>Daiichi Sankyo<\/b> Other, Advisory board. <br><b>Merck<\/b> Other, Advisory board. <br><b>MultiplexDX<\/b> Other, Advisory board. <br><b>Odyssey Bio<\/b> Other, Board of directors. <br><b>Grupo Oncoclinicas<\/b> Other, Board of directors. <br><b>S. Chandarlapaty, <\/b> <br><b>Boxer Capital, LLC<\/b> Other, Professional services. <br><b>Eli Lilly and Company<\/b> Other, Professional services. <br><b>Encore Medical Education<\/b> Other, Professional services. <br><b>Genesis Therapeutics<\/b> Other, Professional services. <br><b>Gerson Lehrman Group<\/b> Other, Professional services. <br><b>Novartis<\/b> Other, Professional services. <br><b>Nuvalent, Inc.<\/b> Other, Professional services. <br><b>Prelude Therapeutics<\/b> Other, Professional services. <br><b>SAGA Diagnostics<\/b> Other, Professional services. <br><b>Odyssey Biosciences<\/b> Other Intellectual Property, Other, Equity. <br><b>Totus Medicines Inc<\/b> Other, Equity. <br><b>eFFECTOR Therapeutics<\/b> Other, Equity and professional services. <br><b>F. Pareja, <\/b> <br><b>MultiplexDx<\/b> Other, Advisory board. <br><b>AstraZeneca<\/b> Other, Advisory board. <br><b>S. P. Shah, <\/b> <br><b>AstraZeneca<\/b> Other, Professional services. <br><b>Imagia Canexia Health Inc.<\/b> Other, Equity.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9341","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"5","PosterboardNumber":"5","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"890","PresenterBiography":null,"PresenterDisplayName":"Kevin Boehm, PhD,MD","PresenterKey":"39f655fc-442c-47e6-acaa-0dc9806a7f31","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"890. Multimodal modeling of digitized histopathology slides improves risk stratification in hormone receptor-positive breast cancer patients","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Multimodal modeling of digitized histopathology slides improves risk stratification in hormone receptor-positive breast cancer patients","Topics":null,"cSlideId":""},{"Abstract":"Colorectal cancer (CRC) is one of the most prevalent and lethal malignancies globally with up to 50 % of patients eventually progressing to metastatic disease. The mitogen-activated-protein kinase (MAPK) pathway emerges as a key player, being one of the most frequently mutated signaling pathways in the oncogenesis of CRC. However, given the numerous genomic aberrations and tumor heterogeneity in CRC, patients may benefit from combinatorial therapies, particularly those who have inoperable or metastatic tumors. In the present study, we investigated the feasibility of combining two platforms, patient-derived 3D (PD3D<sup>&#174;<\/sup>) models with Optim.AI&#8482;, to identify more effective cancer therapies. PD3D<sup>&#174;<\/sup> models can robustly retain the genotypic and histopathologic features of the primary patient tumor, model tumor heterogeneity and were shown to predict a patient&#8217;s drug response. Optim.AI&#8482; is a hybrid computational-experimental platform that uses small data sets to rationally converge to optimal drug combinations within a defined drug search space. By mapping experimental data points to a second-order quadratic function, Optim.AI&#8482; can predict every possible 531k data points and thus the cell-killing efficacy for all other possible combinations without testing each individual drug-dose combination. Two CRC PD3D<sup>&#174;<\/sup> models with different mutation profiles were tested with 155 different combinations of 12 drugs at variant concentrations. The post-treatment cell viability was measured and used for Optim.AI&#8482; analysis to evaluate and compare the best therapies. Optim.AI&#8482; analysis revealed differential drug sensitivity between tested CRC PD3Ds<sup>&#174;<\/sup>. The top-ranked drug combinations included SN-38, active compound of commonly used chemotherapeutic irinotecan, paired with MEK-inhibitors trametinib or cobimetinib which we could confirm with both platforms. With this study, we successfully demonstrated the feasibility, the robustness, and the efficiency of combining PD3Ds<sup>&#174;<\/sup> and Optim.AI&#8482; in identifying effective drug combination therapies, here for CRC, within one month. This combined technology provides precise insights into tumor treatability and its functional causes of treatment outcomes, leading to new treatment combinations and accelerating the development of new cancer drugs in a time- and cost-effective manner.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Colorectal cancer,Organoids,Drug sensitivity,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"Ulrike Pfohl<sup>1<\/sup>, Masturah Mohd Abdul Rashid<sup>2<\/sup>, <b>Jhin Jieh Lim<\/b><sup>2<\/sup>, Juergen Loskutov<sup>1<\/sup>, Lena Wedeken<sup>1<\/sup>, Edward Kai-Hua Chow<sup>3<\/sup>, Hugo Saavedra<sup>2<\/sup>, Christoph Reinhard<sup>1<\/sup>, Christian  R.   A.  Regenbrecht<sup>4<\/sup><br><br\/><sup>1<\/sup>CELLphenomics GmbH, Berlin, Germany,<sup>2<\/sup>KYAN Therapeutics, Singapore, Singapore,<sup>3<\/sup>Cancer Science Institute of Singapore, Singapore, Singapore,<sup>4<\/sup>ASC Oncology GmbH, Berlin, Germany","CSlideId":"","ControlKey":"707619fb-9db6-4d2a-9f1d-e5a8e72e9baf","ControlNumber":"3169","DisclosureBlock":"&nbsp;<b>U. Pfohl, <\/b> None..<br><b>M. Rashid, <\/b> None..<br><b>J. Lim, <\/b> None..<br><b>J. Loskutov, <\/b> None..<br><b>L. Wedeken, <\/b> None..<br><b>E. Chow, <\/b> None..<br><b>H. Saavedra, <\/b> None..<br><b>C. Reinhard, <\/b> None..<br><b>C. R. A. Regenbrecht, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9342","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"6","PosterboardNumber":"6","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"891","PresenterBiography":null,"PresenterDisplayName":"Jhin Jieh Lim, PhD","PresenterKey":"b0ce3206-321b-4319-8460-ea82c61e1930","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"891. Turning data into information: Using PD3D<sup>&#174;<\/sup> models to guide colorectal cancer therapy by Optim.AI<sup>TM<\/sup>","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Turning data into information: Using PD3D<sup>&#174;<\/sup> models to guide colorectal cancer therapy by Optim.AI<sup>TM<\/sup>","Topics":null,"cSlideId":""},{"Abstract":"Multiplexed immunofluorescence (mIF) microscopy reveals the spatial architecture of cancer tissue and its microenvironment that is not being fully explored with existing analysis methods. Most analysis approaches for mIF microscopy data focus on single-cell or region classification and rely on supervised machine learning. In this work, we present a self-supervised spatial profiling method for mIF images that takes local and global associations into account, and apply this method to profile cancer-associated fibroblasts (CAFs) in a pan-cancer dataset.<br \/>We studied a 2-stage self-supervised training scheme to learn the representations of mIF tissue microarray (TMA) images in local and global scales (cellular and long-range associations). During the 1st self-supervised training stage, a Vision Transformer learns the local-scale representations by using small patches from TMA images. Then, the local representations are used as input to the 2nd stage where a similar self-supervised learning strategy is used to learn global patterns in the TMA images.<br \/>We applied the method to profile multiple cohorts from three different solid tumors: prostate, renal, and lung cancer. In total, these cohorts include more than 5,000 TMA cores from over 1,750 patients extracted from the tumor center, tumor edge, and adjacent benign areas. The samples were stained with a CAF panel including FAP, aSMA, PDGFRB, pSTAT3\/PDGFRA, nuclear and epithelial markers, and imaged with cyclic mIF microscopy.<br \/>Samples were studied at the patch-level and TMA core-level. Small patches enable further analysis of associations in the local environment, whereas the core-level enables associations with patient clinical information. Clustering of patch-level (1st stage) and core-level (2nd stage) representations showed independently that self-supervised learning is capable of learning the representations of the mIF images. We were able to identify regions and cases with high pTNM staging from the prostate cancer samples and similar histological subtypes from renal cancer samples. We further validated the clustering using k-NN classification that showed high classification accuracy in all cohorts. Moreover, we developed a stopping criteria for the final model selection that balances between the similarities of samples and patches inside of samples to prevent overfitting.<br \/>Our study shows that self-supervised learning enables unbiased discoveries from large-scale mIF microscopy imaging datasets. The developed method uncovers associations between imaging data and clinical information and highlights directly the patterns that are most meaningful for these associations.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Tumor microenvironment,Imaging,Deep learning,Image analysis,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"Gantugs Atarsaikhan<sup>1<\/sup>, Isabel Mogollon<sup>1<\/sup>, Katja Välimäki<sup>1<\/sup>, Tuomas Mirtti<sup>2<\/sup>, Teijo Pellinen<sup>1<\/sup>, <b>Lassi Paavolainen<\/b><sup>1<\/sup><br><br\/><sup>1<\/sup>Institute for Molecular Medicine Finland (FIMM), University of Helsinki, Helsinki, Finland,<sup>2<\/sup>University of Helsinki, Helsinki, Finland","CSlideId":"","ControlKey":"34159cff-b880-4313-8deb-bbedad4488a0","ControlNumber":"3510","DisclosureBlock":"&nbsp;<b>G. Atarsaikhan, <\/b> None..<br><b>I. Mogollon, <\/b> None..<br><b>K. Välimäki, <\/b> None.&nbsp;<br><b>T. Mirtti, <\/b> <br><b>Aiforia Technologies Plc<\/b> Independent Contractor.<br><b>T. Pellinen, <\/b> None.&nbsp;<br><b>L. Paavolainen, <\/b> <br><b>Orion Pharma Oyj<\/b> Grant\/Contract. <br><b>Astrid Pharma Corp.<\/b> Travel.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9343","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"7","PosterboardNumber":"7","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"892","PresenterBiography":null,"PresenterDisplayName":"Lassi Paavolainen, PhD","PresenterKey":"f55b1065-7863-435b-84aa-629f120a4a23","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"892. Pan-cancer tumor microenvironment profiling with multiplexed immunofluorescence microscopy and self-supervised learning","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Pan-cancer tumor microenvironment profiling with multiplexed immunofluorescence microscopy and self-supervised learning","Topics":null,"cSlideId":""},{"Abstract":"High-grade serous ovarian cancer (HGSOC) is one of the most lethal gynecological malignancies. Lack of common targetable oncogenic mutations has complicated the development of directed therapies to combat emerging resistance. This malignancy is mainly characterized by the mutation of gene TP53, which promotes genome instability for the emergence of extensive copy number variations (CNVs). However its impact on gene expression at the single-cell level is not well understood. In this study, we aim to investigate the effect of CNVs on transcriptomic signatures by taking advantage of variational autoencoders (VAE) ability for dimensionality reduction, unsupervised learning and feature extraction. The use of VAEs is becoming more popular for the analysis of scRNAseq data, and scVI is one of the most versatile VAE applications performing wide variety of tasks. Here, we used single-cell RNA sequencing (scRNA-seq) data from 90 longitudinal samples of 64 HGSOC patients and inferred CNVs in each cell using inferCNV, an established computational pipeline. Then, we modified scVI algorithm to allow the VAE to reconstruct CNVs from a latent space originated from gene expression profiles and viceversa. Our models were capable of reconstructing CNV profiles accurately from expression data and also remove batch effect. From these models we could observe how, after the integration of genomic information, the latent clusters produced from the transcriptomic space were influenced by the amplifications or deletions of certain genomic regions. Moreover, some of these clusters were characterized by the alteration of important oncogenes in HGSOC, such as KRAS and CCNE1, and allowed us to focus on the transcriptomic consequences of their amplifications. With the results from the approach presented here, we gained a more comprehensive picture of the impact of genomic alterations on HGSOC. As future work, we plan to validate of this results on external cohorts and link the identified signatures to clinically relevant features such as prognosis or chemotherapy response.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Ovarian cancer,Copy number alterations,Machine learning,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>M. Marin Falco<\/b><sup>1<\/sup>, T. Närhi<sup>1<\/sup>, E. P. Erkan<sup>2<\/sup>, J. Hynninen<sup>3<\/sup>, A. Vähärautio<sup>1<\/sup>; <br\/><sup>1<\/sup>University of Helsinki, Helsinki, Finland, <sup>2<\/sup>Tampere University, Tampere, Finland, <sup>3<\/sup>University of Turku and Turku University Hospital, Turku, Finland","CSlideId":"","ControlKey":"824251e7-fdb1-4a84-b6a7-1c7a0c2cba46","ControlNumber":"4526","DisclosureBlock":"&nbsp;<b>M. Marin Falco, <\/b> None..<br><b>T. Närhi, <\/b> None..<br><b>E. P. Erkan, <\/b> None..<br><b>J. Hynninen, <\/b> None..<br><b>A. Vähärautio, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9344","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"8","PosterboardNumber":"8","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"893","PresenterBiography":null,"PresenterDisplayName":"Matias Marin Falco, MD","PresenterKey":"8eac8a71-5662-4090-95cb-9c953a2ae76f","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"893. Studying the impact of CNVs on expression at single-cell resolution in HGSOC using autoencoders","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Studying the impact of CNVs on expression at single-cell resolution in HGSOC using autoencoders","Topics":null,"cSlideId":""},{"Abstract":"<b>Background<\/b>: Neoadjuvant Cabozantinib targeted therapy (nCabo) has been shown to facilitate tumor size reduction in patients with renal cell carcinoma (RCC). However, there is unmet clinical need to identify pre-treatment markers predictive of response to nCabo to limit financial, dose-related toxicity. We investigated computationally derived radiomic signatures from baseline magnetic resonance imaging (MRI) for their association with response to tumor shrinkage following nCabo.<b>Methods<\/b> Seventeen patients with non-metastatic, clinical stage &#8805;T3, biopsy-confirmed clear cell RCC were enrolled in a phase II clinical trial (NCT04022343) examining primary tumor response to nCabo. Patients underwent 3 Tesla MRI at baseline, 6 and 12 weeks. Partial response (PR) or stable disease (SD) was determined per Response Evaluation Criteria in Solid Tumors at 12 weeks. Tumor regions of interest (ROI) were delineated on axial, arterial phase T1-weighted (T1W) series under the guidance of expert radiologist. T1W were normalized with respect to enhancement in cortex region of kidney. 75 radiomic features quantifying texture heterogeneity were derived from tumor ROI on a per-voxel basis at baseline. Wilcoxon ranksum test was used to evaluate significant differences in radiomics between patient groups PR and SD. <b>Results<\/b>: Following nCabo, 6\/17 patients experienced PR. 22 radiomic features from T1W quantifying intensity based heterogeneity showed significant differences between patients with SD and PR after nCabo (p&#60;0.05; top 3 in <b>Table<\/b>). None of the clinical variables showed significant differences between SD and PR. <b>Conclusion<\/b>: In this proof-of-concept preliminary study, we observed that radiomics at baseline MRI may allow for identifying RCC patients who would favorably respond to nCabo in terms of tumor shrinkage. Future studies will include analysis on longitudinal data, correlation against survival on large-scale datasets.<table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{B6E1F7C9-B864-4C7E-8EFD-F052E18F5D54}\"><caption>Association between tumor shrinkage following nCabo and radiomic features, clinical variables<\/caption><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"2\"><b>Stable Disease (N=6)<\/b><\/td><td rowspan=\"1\" colspan=\"2\"><b>Partial Response (N=11)<\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><b>Category<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>Feature<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>P-value<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>median <\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>IQR<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>median<\/b><\/td><td rowspan=\"1\" colspan=\"1\"><b>IQR <\/b><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Radiomic<\/td><td rowspan=\"1\" colspan=\"1\">Haralick<\/td><td rowspan=\"1\" colspan=\"1\"><b>0.01<\/b><\/td><td rowspan=\"1\" colspan=\"1\">1.50<\/td><td rowspan=\"1\" colspan=\"1\">0.51<\/td><td rowspan=\"1\" colspan=\"1\">2.31<\/td><td rowspan=\"1\" colspan=\"1\">0.51<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">Gradient Filter<\/td><td rowspan=\"1\" colspan=\"1\"><b>0.02<\/b><\/td><td rowspan=\"1\" colspan=\"1\">88.06<\/td><td rowspan=\"1\" colspan=\"1\">107.28<\/td><td rowspan=\"1\" colspan=\"1\">289.58<\/td><td rowspan=\"1\" colspan=\"1\">107.28<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">CoLlAGe<\/td><td rowspan=\"1\" colspan=\"1\"><b>0.03<\/b><\/td><td rowspan=\"1\" colspan=\"1\">224.28<\/td><td rowspan=\"1\" colspan=\"1\">10.73<\/td><td rowspan=\"1\" colspan=\"1\">210.50<\/td><td rowspan=\"1\" colspan=\"1\">10.73<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\">Clinical<\/td><td rowspan=\"1\" colspan=\"1\">Age<\/td><td rowspan=\"1\" colspan=\"1\">0.12<\/td><td rowspan=\"1\" colspan=\"1\">56.00<\/td><td rowspan=\"1\" colspan=\"1\">14.00<\/td><td rowspan=\"1\" colspan=\"1\">52.50<\/td><td rowspan=\"1\" colspan=\"1\">14.00<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">BMI<\/td><td rowspan=\"1\" colspan=\"1\">0.48<\/td><td rowspan=\"1\" colspan=\"1\">29.90<\/td><td rowspan=\"1\" colspan=\"1\">8.50<\/td><td rowspan=\"1\" colspan=\"1\">27.30<\/td><td rowspan=\"1\" colspan=\"1\">8.50<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">modified Glasgow Prognostic Score<\/td><td rowspan=\"1\" colspan=\"1\">0.21<\/td><td rowspan=\"1\" colspan=\"1\">1.00<\/td><td rowspan=\"1\" colspan=\"1\">1.00<\/td><td rowspan=\"1\" colspan=\"1\">0.00<\/td><td rowspan=\"1\" colspan=\"1\">1.00<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">Baseline Tumor Size (cm)<\/td><td rowspan=\"1\" colspan=\"1\">0.48<\/td><td rowspan=\"1\" colspan=\"1\">9.50<\/td><td rowspan=\"1\" colspan=\"1\">5.15<\/td><td rowspan=\"1\" colspan=\"1\">9.50<\/td><td rowspan=\"1\" colspan=\"1\">5.15<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">ECOG PS at presentation<\/td><td rowspan=\"1\" colspan=\"1\">0.23<\/td><td rowspan=\"1\" colspan=\"1\">0.00<\/td><td rowspan=\"1\" colspan=\"1\">1.00<\/td><td rowspan=\"1\" colspan=\"1\">0.00<\/td><td rowspan=\"1\" colspan=\"1\">1.00<\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><\/td><td rowspan=\"1\" colspan=\"1\">Charlson Comorbidity Index<\/td><td rowspan=\"1\" colspan=\"1\">0.72<\/td><td rowspan=\"1\" colspan=\"1\">6.00<\/td><td rowspan=\"1\" colspan=\"1\">6.00<\/td><td rowspan=\"1\" colspan=\"1\">4.00<\/td><td rowspan=\"1\" colspan=\"1\">6.00<\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Kidney cancer,Magnetic resonance imaging,Machine learning,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"L. LI<sup>1<\/sup>, E. Nicaise<sup>2<\/sup>, B. Schmeusser<sup>2<\/sup>, A. Midya<sup>1<\/sup>, A. Davarpanahfakhr<sup>1<\/sup>, A. Madabhushi<sup>1<\/sup>, M. Bilen<sup>1<\/sup>, V. Master<sup>2<\/sup>, <b>R. Shiradkar<\/b><sup>1<\/sup>; <br\/><sup>1<\/sup>Emory University, Atlanta, GA, <sup>2<\/sup>Emory University School of Medicine, Atlanta, GA","CSlideId":"","ControlKey":"2f6b630b-80d4-43df-98df-fd194bf838c6","ControlNumber":"4932","DisclosureBlock":"&nbsp;<b>L. Li, <\/b> None..<br><b>E. Nicaise, <\/b> None..<br><b>B. Schmeusser, <\/b> None..<br><b>A. Midya, <\/b> None..<br><b>A. Davarpanahfakhr, <\/b> None.&nbsp;<br><b>A. Madabhushi, <\/b> <br><b>Picture Health<\/b> Stock, Patent, Other, Advisory board. <br><b>Elucid Bioimaging<\/b> Stock, Patent. <br><b>Inspirata Inc<\/b> Stock, Grant\/Contract. <br><b>Aiforia Inc<\/b> Other, Advisory board. <br><b>SimBioSys<\/b> Other, Advisory board. <br><b>AstraZeneca<\/b> Other, sponsored research agreements. <br><b>Boehringer-Ingelheim<\/b> Other, sponsored research agreements. <br><b>Eli-Lilly<\/b> Other, sponsored research agreements. <br><b>Bristol Myers-Squibb<\/b> Other, sponsored research agreements.<br><b>M. Bilen, <\/b> None..<br><b>V. Master, <\/b> None..<br><b>R. Shiradkar, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9345","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"9","PosterboardNumber":"9","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"894","PresenterBiography":null,"PresenterDisplayName":"Rakesh Shiradkar, PhD","PresenterKey":"dbd841aa-0063-4205-948c-d4fcabc49f3d","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"894. Radiomics at baseline MRI are associated with tumor shrinkage in patients with unresectable renal cell carcinoma treated with neo-adjuvant Cabozantinib","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Radiomics at baseline MRI are associated with tumor shrinkage in patients with unresectable renal cell carcinoma treated with neo-adjuvant Cabozantinib","Topics":null,"cSlideId":""},{"Abstract":"Metastases are the primary cause of cancer-related death, and improving the means of predicting and targeting their development is one of the major goals in cancer research. While surgical resection and neo-adjuvant therapy can cure well-confined primary tumors, our ability to effectively treat cancer is largely dependent on our capacity to interdict the process of metastasis. The recent accumulation of &#8216;omics data from metastatic tumors provides an unprecedented opportunity to develop machine learning models to predict the molecular changes during metastasis and explore the patterns of metastasis formation. With this in mind, we developed <i>MetMapper<\/i>, a deep learning model trained on primary and metastatic tumors from &#62; 13 000 patients integrating data from 11 published data resources. MetMapper can predict the transcriptomic changes of a primary tumor when it metastasizes to different distant organs. The results were extensively validated using transcriptomics data from matched primary and metastatic tumor biopsies extracted from the same patients. Furthermore, MetMapper&#8217;s predictions revealed that the non-random patterns of cancer metastases can be partly explained by the degree of transcriptome reprogramming needed during metastasis: primary tumors tend to metastasize to organs that require minimal changes to their transcriptomes. Using MetMapper, we derived a metastatic potential score for patient tumors and demonstrate that this score can be used to stratify patients into high and low survival groups across different indications. The predicted metastatic potential of patient tumors significantly correlates with experimentally characterized metastatic potential of cancer cell lines. Additionally, by performing <i>in-silico<\/i> perturbations of genes and oncogenic pathways that can alter the metastatic potential of patient tumors, we identified genomic features that are highly associated with metastases to specific organs, some of which were reported by existing pan-cancer clinical sequencing studies. Our results demonstrate the utility of MetMapper as a novel AI-powered methodology for investigating mechanisms and patterns of metastatic dissemination, as well as forecasting metastatic outcomes of patient tumors.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Metastasis,Predictive biomarkers,Genomics,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"G. Li<sup>1<\/sup>, E. Béal<sup>1<\/sup>, D. Sumner<sup>1<\/sup>, G. G. Galli<sup>1<\/sup>, V. Cremasco<sup>2<\/sup>, J. M. Korn<sup>2<\/sup>, F. Dondelinger<sup>1<\/sup>, <b>D. Ruddy<\/b><sup>2<\/sup>, A. Kauffmann<sup>1<\/sup>, S. Dimitrieva<sup>1<\/sup>; <br\/><sup>1<\/sup>Novartis, Basel, Switzerland, <sup>2<\/sup>Novartis, Cambridge, MA","CSlideId":"","ControlKey":"81d36a0e-811f-4f04-adf4-4dd063b17134","ControlNumber":"5684","DisclosureBlock":"<b>&nbsp;G. Li, <\/b> <br><b>Novartis<\/b> Employment. <br><b>E. Béal, <\/b> <br><b>Novartis<\/b> Employment. <br><b>D. Sumner, <\/b> <br><b>Novartis<\/b> Employment. <br><b>G. G. Galli, <\/b> <br><b>Novartis<\/b> Employment, Stock. <br><b>V. Cremasco, <\/b> <br><b>Novartis<\/b> Employment, Stock. <br><b>J. M. Korn, <\/b> <br><b>Novartis<\/b> Employment, Stock. <br><b>F. Dondelinger, <\/b> <br><b>Novartis<\/b> Employment. <br><b>D. Ruddy, <\/b> <br><b>Novartis<\/b> Employment, Stock. <br><b>A. Kauffmann, <\/b> <br><b>Novartis<\/b> Employment, Stock. <br><b>S. Dimitrieva, <\/b> <br><b>Novartis<\/b> Employment, Stock.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9347","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"10","PosterboardNumber":"11","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"896","PresenterBiography":null,"PresenterDisplayName":"David Ruddy, BS","PresenterKey":"d9b16388-0936-4696-b189-0076e30969ce","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"896. Predicting metastatic transcriptomes of patient tumors with deep learning","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Predicting metastatic transcriptomes of patient tumors with deep learning","Topics":null,"cSlideId":""},{"Abstract":"Synthetic lethality refers to the concept that simultaneous perturbation of gene pairs leads to cell death but individual perturbation does not. Synthetically lethal gene pairs (SL pairs) provide a potential avenue for selective targeting of cancer cells based on underlying genetic vulnerabilities. The rise of large scale gene perturbation screens such as the Cancer Dependency Map (DepMap) offers the opportunity to identify SL pairs automatically using machine learning. Yet, a key difficulty in using machine learning models for this task is the lack of labeled data in the form of known SL pairs. Thus, prior approaches framed SL pair identification as a feature learning problem where the goal is to identify the genomic features most influential for predicting low cellular viability under a gene knockout. These prior approaches have primarily utilized random forests since these machine learning models are one of the only nonlinear models for which feature importances are provided explicitly. On the other hand, if we could identify features learned by state-of-the-art models on screening tasks such as kernel machines, we would be better powered in finding SL pairs. In this work, we present a computationally efficient and effective pipeline for SL pair screening built on a recently developed class of feature learning kernel machines known as Recursive Feature Machines (RFMs). We show that our pipeline more accurately recovers experimentally verified SL pairs than prior work including the best model from the DepMap portal and previous random forest based approaches (see the table below). Moreover, our pipeline identifies several new candidate SL pairs for further analysis, opening new avenues for targeting genetic vulnerabilities in cancer.<br \/><table border=\"1\"  cellpadding=\"1\" class=\"DisplayTable\" id=\"{79842AC0-D1DF-46EB-8579-D8E02DC9DD2F}\"><caption>Rank of verified SL pairs across unsupervised methods (lower is better with a minimum value of 1).<\/caption><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">Experimentally Verified SL <\/span><span style=\"font-size:12.0pt;font-family:Calibri; mso-ascii-font-family:Calibri;mso-fareast-font-family:+mn-ea;mso-bidi-font-family: +mn-cs;mso-fareast-theme-font:minor-fareast;mso-bidi-theme-font:minor-bidi; color:black;mso-font-kerning:12.0pt;language:en-US;font-weight:normal; font-style:normal;mso-style-textfill-type:solid;mso-style-textfill-fill-color: black;mso-style-textfill-fill-alpha:100.0%\">Pairs<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">Pearson Correlation<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><span style=\"font-size:12.0pt;font-family:Calibri; mso-ascii-font-family:Calibri;mso-fareast-font-family:+mn-ea;mso-bidi-font-family: +mn-cs;mso-fareast-theme-font:minor-fareast;mso-bidi-theme-font:minor-bidi; color:black;mso-font-kerning:12.0pt;language:en-US;font-weight:normal; font-style:normal;mso-style-textfill-type:solid;mso-style-textfill-fill-color: black;mso-style-textfill-fill-alpha:100.0%\">PARIS<\/span><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-ascii-theme-font: minor-latin;mso-fareast-theme-font:minor-fareast;mso-bidi-theme-font:minor-bidi; color:black;mso-color-index:1;mso-font-kerning:12.0pt;language:en-US; mso-style-textfill-type:solid;mso-style-textfill-fill-themecolor:text1; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">DepMap<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">RFMs (<\/span><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family: Calibri;mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">Ours)<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">SMARCA2\/SMARCA4<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">ARID1A\/ARID1B<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">STAG1\/STAG2<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">CREBBP\/EP300<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">VPS4A\/VPS4B<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size: 12pt; font-family: Calibri; color: black; font-style: normal;\">7<br><\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">&gt; 10<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-ascii-theme-font: minor-latin;mso-fareast-theme-font:minor-fareast;mso-bidi-theme-font:minor-bidi; color:black;mso-color-index:1;mso-font-kerning:12.0pt;language:en-US; mso-style-textfill-type:solid;mso-style-textfill-fill-themecolor:text1; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">5<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">DDX17\/DDX5<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\">4<\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">ENO1\/ENO2<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">&gt; 10<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">SMARCC1\/SMARCC2<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">&gt; 10<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">UBB\/UBC<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">&gt; 10<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">&gt; 10<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">MAGOH\/MAGOHB<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><tr><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:normal;font-style:normal;mso-style-textfill-type: solid;mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">FAM50A\/FAM50B<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><td rowspan=\"1\" colspan=\"1\"><p style=\"language:en-US;margin-top:0pt;margin-bottom:0pt;margin-left:0in; text-align:center;direction:ltr;unicode-bidi:embed;vertical-align:top; mso-line-break-override:none;word-break:normal;punctuation-wrap:hanging\"><span style=\"font-size:12.0pt;font-family:Calibri;mso-ascii-font-family:Calibri; mso-fareast-font-family:+mn-ea;mso-bidi-font-family:+mn-cs;mso-fareast-theme-font: minor-fareast;mso-bidi-theme-font:minor-bidi;color:black;mso-font-kerning:12.0pt; language:en-US;font-weight:bold;font-style:normal;mso-style-textfill-type:solid; mso-style-textfill-fill-color:black;mso-style-textfill-fill-alpha:100.0%\">1<\/span><\/p><\/td><\/tr><\/table>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Synthetic lethality,Genomics,Mutations,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>Adityanarayanan Radhakrishnan<\/b><sup>1<\/sup>, Cathy Cai<sup>2<\/sup>, Barbara  A.  Weir<sup>3<\/sup>, Christopher Moy<sup>4<\/sup>, Caroline Uhler<sup>2<\/sup><br><br\/><sup>1<\/sup>Harvard University \/ Broad Institute of MIT and Harvard, Cambridge, MA,<sup>2<\/sup>Massachusetts Institute of Technology \/ Broad Institute of MIT and Harvard, Cambridge, MA,<sup>3<\/sup>Johnson and Johnson Innovative Medicine, Cambridge, MA,<sup>4<\/sup>Johnson and Johnson Innovative Medicine, Spring House, PA","CSlideId":"","ControlKey":"dc691ab2-3bbe-4141-b251-fa09a03309ec","ControlNumber":"5795","DisclosureBlock":"&nbsp;<b>A. Radhakrishnan, <\/b> None..<br><b>C. Cai, <\/b> None.&nbsp;<br><b>B. A. Weir, <\/b> <br><b>Johnson and Johnson<\/b> Employment, Stock. <br><b>C. Moy, <\/b> <br><b>Johnson and Johnson<\/b> Employment, Stock. <br><b>C. Uhler, <\/b> <br><b>Janssen Pharmaceuticals<\/b> Grant\/Contract.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9348","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"11","PosterboardNumber":"12","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"897","PresenterBiography":null,"PresenterDisplayName":"Adityanarayanan Radhakrishnan","PresenterKey":"bf2aa9cd-de18-4db8-a87c-2d373cdd2412","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"897. Synthetic lethality screening with Recursive Feature Machines","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Synthetic lethality screening with Recursive Feature Machines","Topics":null,"cSlideId":""},{"Abstract":"Purpose: The spatial distribution of cell types in the tumor microenvironment (TME) is associated with functional status of tumor immunology and eventually affects the response to immuno-oncology treatment. We have developed a deep learning model that was trained by integrating H&#38;E images of lung adenocarcinoma with spatial transcriptomic data. We applied this model to predict various cell types within the TME using only hematoxylin and eosin (H&#38;E) images to correlate with the PD-L1 status.<br \/>Methods: A deep learning model to predict five cell types enrichment score maps from H&#38;E images was trained by spatial transcriptomics data combined with matched H&#38;E images. The five cell types of TME included B cells, T\/NK cells, myeloid cells, fibroblasts, and epithelial cells. wAnother dataset based on tissue microarray (TMA) data of H&#38;E images of lung cancer patients (n = 94) was used to predict cell type enrichment scores associated with PD-L1 status estimated by TPS score. The cell type scores derived from the H&#38;E-stained lung cancer images were correlated with the PD-L1 status.<br \/>Results: The cell types predicted by the model using H&#38;E image patches showed a significant correlation with those determined through spatial transcriptomic data, serving as an internal validation. All cell types (B cells, T\/NK cells, myeloid cells, fibroblasts, and epithelial cells) from TMA cores showed significant differences according to the PD-L1 expression groups. The enrichment scores of B cells, T\/NK cells, myeloid cells and fibroblasts were significantly higher in the PD-L1 high group.<br \/>Conclusions: Our research introduces a deep learning model for precise cell type mapping within the tumor microenvironment and applied to H&#38;E-stained TMA cores. The relationship between PD-L1 status and the cell type enrichment scores within the tumor microenvironment, as predicted by the deep learning model analyzing H&#38;E images, demonstrates the potential for using H&#38;E-based characterization of the tumor microenvironment as a biomarker in immuno-oncology treatments.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Histopathology,Lung cancer,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>S. Cook<\/b><sup>1<\/sup>, H. Shin<sup>1<\/sup>, J. Koh<sup>2<\/sup>, H. Choi<sup>3<\/sup>, K. Na<sup>4<\/sup>; <br\/><sup>1<\/sup>Portrai, Inc., Seoul, Korea, Republic of, <sup>2<\/sup>Department of Pathology, Seoul National University Hospital, Seoul, Korea, Republic of, <sup>3<\/sup>Department of Nuclear Medicine, Seoul National University Hospital, Seoul, Korea, Republic of, <sup>4<\/sup>Department of Thoracic and Cardiovascular Surgery, Seoul National University Hospital, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"7abdf5e4-dd57-4728-9e1f-ab6983384aa1","ControlNumber":"6161","DisclosureBlock":"<b>&nbsp;S. Cook, <\/b> <br><b>Portrai, Inc.<\/b> Employment. <br><b>H. Shin, <\/b> <br><b>Portrai, Inc.<\/b> Employment.<br><b>J. Koh, <\/b> None.&nbsp;<br><b>H. Choi, <\/b> <br><b>Portrai, Inc.<\/b> Stock. <br><b>K. Na, <\/b> <br><b>Portrai, Inc.<\/b> Stock.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9349","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"12","PosterboardNumber":"13","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"898","PresenterBiography":null,"PresenterDisplayName":"Seungho Cook, MS","PresenterKey":"52e3d582-1271-4b2d-b822-a2b92fd8f7cd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"898. Deep learning-based cell types scores in tumor microenvironment estimated by H&#38;E images associated with PD-L1 status in lung adenocarcinoma","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Deep learning-based cell types scores in tumor microenvironment estimated by H&#38;E images associated with PD-L1 status in lung adenocarcinoma","Topics":null,"cSlideId":""},{"Abstract":"<b>Purpose <\/b><b><\/b>The tumor microenvironment (TME) is crucial in colorectal cancer as it influences disease progression, treatment response, and patient outcomes, providing valuable insights for personalized therapies and prognostic assessments. Here, we have developed a deep learning model by integrating hematoxylin and eosin (H&#38;E) stained images of colorectal cancer and image-based spatial transcriptomics (Xenium) to infer spatial mapping of cell types in TME only using H&#38;E images.<br \/><b>Methods <\/b>A total of 30 H&#38;E images of colorectal cancer obtained by tissue microarray were registered with image-based spatial transcriptomics data (Xenium). Utilizing a Variational Autoencoder (VAE) based model and leveraging reference single-cell data enables the acquisition of cell types for individual cells in image-based spatial transcriptomics. A convolutional neural network (CNN) model was developed using H&#38;E image as inputs to predict cell types in H&#38;E-stained tissue image patches of colorectal cancer collected from various patients. The model also estimated the cell types from H&#38;E-stained whole slide tissue image of colorectal cancer of The Cancer Genome Atlas (TCGA-COAD).<br \/><b>Results <\/b>The accuracy of the model's predictions for cell types using H&#38;E image patches was notably high and exhibited a significant concordance with the results obtained through the validation. The Intersection over Union (IoU) metric for image segmentation indicated a value of 0.66 for epithelial cells and 0.44 for TNK cells. The output of deep learning model for epithelial cells and T\/NK cells from TCGA-COAD tissue images showed a correlation with human-labeled regions of cancer epithelium and immune cells.<br \/><b>Conclusions<\/b> Leveraging image-based spatial transcriptomics, we developed a deep learning model capable of discerning various cell types within the tumor microenvironment solely from H&#38;E images. This clinically translatable approach is valuable for investigating tumor microenvironment to develop biomarkers associated with various cancer therapeutics particularly immuno-oncology drugs. This approach can yield objective deep learning-based models without human labels for characterizing the tumor microenvironment in single-cell resolution, particularly regarding spatial immune distribution.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Histopathology,Colorectal cancer,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>S. Cook<\/b><sup>1<\/sup>, D. Lee<sup>1<\/sup>, M. Lim<sup>1<\/sup>, J. Lee<sup>1<\/sup>, D. Lee<sup>1<\/sup>, H.-J. Im<sup>2<\/sup>, J.-S. Pyo<sup>3<\/sup>, K. Na<sup>4<\/sup>, H. Choi<sup>5<\/sup>; <br\/><sup>1<\/sup>Portrai, Inc., Seoul, Korea, Republic of, <sup>2<\/sup>Department of Molecular Medicine and Biopharmaceutical Sciences, Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Korea, Republic of, <sup>3<\/sup>Department of Pathology, Uijeongbu Eulji Medical Center, Eulji University School of Medicine, Gyeonggi-do, Korea, Republic of, <sup>4<\/sup>Department of Thoracic and Cardiovascular Surgery, Seoul National University Hospital, Seoul, Korea, Republic of, <sup>5<\/sup>Department of Nuclear Medicine, Seoul National University Hospital, Seoul, Korea, Republic of","CSlideId":"","ControlKey":"6f3bdc65-eee5-4e8a-bcd6-72bbf5c52135","ControlNumber":"6211","DisclosureBlock":"<b>&nbsp;S. Cook, <\/b> <br><b>Portrai, Inc.<\/b> Employment. <br><b>D. Lee, <\/b> <br><b>Portrai, Inc.<\/b> Employment. <br><b>M. Lim, <\/b> <br><b>Portrai, Inc.<\/b> Employment. <br><b>J. Lee, <\/b> <br><b>Portrai, Inc.<\/b> Employment. <br><b>D. Lee, <\/b> <br><b>Portrai, Inc.<\/b> Stock. <br><b>H. Im, <\/b> <br><b>Portrai, Inc.<\/b> Stock.<br><b>J. Pyo, <\/b> None.&nbsp;<br><b>K. Na, <\/b> <br><b>Portrai, Inc.<\/b> Stock. <br><b>H. Choi, <\/b> <br><b>Portrai, Inc.<\/b> Stock.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9350","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"13","PosterboardNumber":"14","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"899","PresenterBiography":null,"PresenterDisplayName":"Seungho Cook, MS","PresenterKey":"52e3d582-1271-4b2d-b822-a2b92fd8f7cd","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"899. Development of a deep learning model for cell type mapping in colorectal cancer using H&#38;E images leveraging image-based spatial transcriptomics data","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Development of a deep learning model for cell type mapping in colorectal cancer using H&#38;E images leveraging image-based spatial transcriptomics data","Topics":null,"cSlideId":""},{"Abstract":"<b>Background<\/b>: The backbone chemotherapy of first-line standard of care (SOC) for microsatellite stable (MSS) metastatic colorectal cancer (mCRC) combines 5-Fluorouracil to oxaliplatin and\/or irinotecan. There are no biomarkers to predict response, which is complete or long-lasting (CR\/LLR) in 20-25% of patients, while 10-15% are primary refractory. The aim of this work is to develop a predictive biomarker, based on digital pathology images, that can help stratify patients according to their risk of resistance.<br \/><b>Methods: <\/b>We trained a supervised bag-of-words artificial intelligence (AI)-based model on a cohort of response outliers mCRC patients classified as &#8220;really sensitive&#8221; (RS) if they achieved CR or LLR &#62;10 months to any SOC, or &#8220;really resistant&#8221; (RR) if progression occurred at first disease reassessment. Whole-slide Imaging (WSI) of the resected primary tumors were tiled into patches of 224x224 pixel (0.5&#956;m\/pixel). First-order and texture features were subsequently extracted from all tumoral tiles and grouped into homogenous clusters through a k-means algorithm (k=6). For each patient, the percentage of tiles belonging to each tiles&#8217; cluster was computed to represent new features (called bag of words) with whom different machine learning classifiers were trained. Main clinicopathological features were matched to treatment response by Fisher&#8217;s exact test.<br \/><b>Results<\/b>: To date, we analyzed 82 response outlier patients, of whom 35 were classified as RS and 46 RR. Of them, patients identified at Italian centers were used as construction cohort (N=47; 27 RR and 20 RS) and those identified at Spanish centers were used a validation cohort (N=35; 19 RR and 16 RS). The best result was obtained using a stepwise logistic regression, reaching a negative predictive value (NPV) of 90% (18\/20; 95% CI=70-97%) and 71% (10\/14; 95% CI=49-87%), in the construction and validation sets. No standard clinicopathological features (including stage, <i>RAS\/BRAF<\/i> status, histology and sidedness) was associated with the chance of being RR.<br \/><b>Conclusions: <\/b>We demonstrated that a pathomics signature has the potential to predict resistance to SOC in MSS mCRC. Further validation of these preliminary findings on a larger cohort of response outlier patients is ongoing.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Chemotherapy response,Biomarkers,Predictive biomarkers,Therapy resistance,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>L. Lazzari<\/b><sup>1<\/sup>, G. Mauri<sup>2<\/sup>, V. Giannini<sup>3<\/sup>, D. Cafaro<sup>4<\/sup>, G. Nicoletti<sup>5<\/sup>, C. Marchiò<sup>6<\/sup>, A. Sartore-Bianchi<sup>7<\/sup>, F. Marmorino<sup>8<\/sup>, M. Munoz<sup>9<\/sup>, N. Saoudi Gonzalez<sup>10<\/sup>, A. Puccini<sup>11<\/sup>, C. Cremolini<sup>8<\/sup>, C. Montagut<sup>12<\/sup>, E. Elez<sup>13<\/sup>, S. Sciallero<sup>11<\/sup>, E. Berrino<sup>14<\/sup>, M. Carullo<sup>8<\/sup>, P. Vitiello<sup>15<\/sup>, M. Aquilano<sup>16<\/sup>, M. Di Como<sup>16<\/sup>, E. Bonoldi<sup>16<\/sup>, S. Siena<sup>17<\/sup>, A. Bardelli<sup>18<\/sup>, D. Regge<sup>19<\/sup>, S. Marsoni<sup>1<\/sup>; <br\/><sup>1<\/sup>IFOM ETS - The AIRC Institute of Molecular Oncology, Milano, Italy, <sup>2<\/sup>Università degli Studi di Milano, Milano, Italy; IFOM ETS - The AIRC Institute of Molecular Oncology, Milan, Italy, Milano, Italy, <sup>3<\/sup>University of Turin, Turin, Italy; Radiology Unit, Candiolo Cancer Institute, FPO – IRCCS, Candiolo (TO), Italy, Torino, Italy, <sup>4<\/sup>Candiolo Cancer Institute, FPO – IRCCS, Candiolo (TO), Italy, Candiolo (TO), Italy, <sup>5<\/sup>University of Turin, Turin, Italy; Department of Electronics and Telecommunications, Polytechnic of Turin, Turin, Italy, Turin (IT), Italy, <sup>6<\/sup>Candiolo Cancer Institute, FPO-IRCCS, Candiolo (TO), Italy; Department of Medical Sciences, University of Turin, Turin, Italy, Milano, Italy, <sup>7<\/sup>Università degli Studi di Milano, Milano, Italy; Division of Clinical Research and Innovation, Grande Ospedale Metropolitano Niguarda, Milan, Italy, Milano, Italy, <sup>8<\/sup>University Hospital of Pisa, Pisa, Italy; Department of Translational Research, University of Pisa, Pisa, Italy, Pisa, Italy, <sup>9<\/sup>Hospital del Mar, Barcelona, Spain, Barcelona, Spain, <sup>10<\/sup>Vall d’Hebron University Hospital, Barcelona, Spain, Barcelona, Spain, <sup>11<\/sup>IRCCS Ospedale Policlinico San Martino, Genoa, Italy, Genova, Italy, <sup>12<\/sup>Hospital del Mar, Barcelona, Spain, Barcelona, Italy, <sup>13<\/sup>Vall d’Hebron University Hospital, Barcelona, Spain, Barcelona, Italy, <sup>14<\/sup>Candiolo Cancer Institute, FPO-IRCCS, Candiolo (TO), Italy, Turin, Italy, <sup>15<\/sup>IFOM ETS - The AIRC Institute of Molecular Oncology; University of Turin, Turin, Italy, Milano, Italy, <sup>16<\/sup>Grande Ospedale Metropolitan Niguarda, Milano, Italy, Milano, Italy, <sup>17<\/sup>Università degli Studi di Milano, Milano, Italy; Department of Hematology Oncology, and Molecular Medicine, Grande Ospedale Metropolitan Niguarda, Milano, Italy, Milano, Italy, <sup>18<\/sup>University of Torino, Torino, Italy; IFOM ETS - The AIRC Institute of Molecular Oncology, Milan, Italy, Milano, Italy, <sup>19<\/sup>University of Pisa, Pisa, Italy; Radiology Unit, Candiolo Cancer Institute, FPO – IRCCS, Candiolo (TO), Italy, Pisa, Italy","CSlideId":"","ControlKey":"f0f74ae9-afec-445a-a6cd-d9897d530dad","ControlNumber":"6306","DisclosureBlock":"&nbsp;<b>L. Lazzari, <\/b> None..<br><b>G. Mauri, <\/b> None..<br><b>V. Giannini, <\/b> None..<br><b>D. Cafaro, <\/b> None..<br><b>G. Nicoletti, <\/b> None.&nbsp;<br><b>C. Marchiò, <\/b> <br><b>Bayer<\/b> Other, Personal consultancy fee. <br><b>Roche<\/b> Other, Personal consultancy fee. <br><b>AstraZeneca<\/b> Other, Personal consultancy fee. <br><b>Daiichi Sankyo<\/b> Other, Personal consultancy fee. <br><b>A. Sartore-Bianchi, <\/b> <br><b>Amgen<\/b> Other, Advisory board. <br><b>Bayer<\/b> Other, Advisory board. <br><b>Novartis<\/b> Other, Advisory board. <br><b>Pierre Fabre<\/b> Other, Advisory board. <br><b>Servier<\/b> Other, Advisory board.<br><b>F. Marmorino, <\/b> None.&nbsp;<br><b>M. Munoz, <\/b> <br><b>Bristol-Myers Squibb<\/b> Other, Support for attending meetings or travel support. <br><b>MSD<\/b> Other, Support for attending meetings or travel support\u000d\u000aPersonal speaker honoraria. <br><b>Merck<\/b> Other, Support for attending meetings or travel support\u000d\u000aPersonal speaker honoraria. <br><b>Novartis<\/b> Other, Support for attending meetings or travel support. <br><b>Pierre Fabre<\/b> Other, Support for attending meetings or travel support. <br><b>Sanofi<\/b> Other, Support for attending meetings or travel support.<br><b>N. Saoudi Gonzalez, <\/b> None..<br><b>A. Puccini, <\/b> None.&nbsp;<br><b>C. Cremolini, <\/b> <br><b>Amgen<\/b> Other, Honoraria\u000d\u000aConsulting or advisory role. <br><b>Bayer<\/b> Other, Honoraria\u000d\u000aConsulting or advisory role\u000d\u000aResearch funding. <br><b>Merck<\/b> Other, Honoraria\u000d\u000aResearch funding. <br><b>Roche<\/b> Other, Honoraria\u000d\u000aConsulting or advisory role\u000d\u000aTravel accomodation and expenses. <br><b>Servier<\/b> Other, Honoraria\u000d\u000aSpeakers' bureau\u000d\u000aResearch funding\u000d\u000aTravel accomodation and expenses. <br><b>MSD<\/b> Other, Consulting or advisory role. <br><b>C. Montagut, <\/b> <br><b>Merck Serono<\/b> Other, Financial Interests, Personal, Advisory Board\u000d\u000aFinancial Interests, Personal, Invited Speaker. <br><b>Amgen<\/b> Other, Research grant\u000d\u000aFinancial Interests, Personal, Invited Speaker. <br><b>Roche<\/b> Financial Interests, Personal, Advisory Board. <br><b>Lilly<\/b> Other, Personal fees. <br><b>Merck-Serono<\/b> Other, Financial Interests, Institutional,\u000d\u000aCoordinating PI. <br><b>Sanofi<\/b> Other, Personal fees. <br><b>Biocartis<\/b> Other, Financial Interests, Institutional, Royalties. <br><b>Pierre Fabre<\/b> Other, Financial Interests, Personal, Invited Speaker. <br><b>Guardant Health<\/b> Other, Financial Interests, Personal, Invited Speaker. <br><b>E. Elez, <\/b> <br><b>Amgen<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Bayer<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Hoffman-La Roche<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Merck Serono<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>MSD<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Novartis<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Organon<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Pfizer<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Pierre Fabre<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Sanofi<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Seagen International GmbH<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Servier<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Takeda<\/b> Other, honoraria for advisory role, travel grants, research grants. <br><b>Amgen Inc, Array Biopharma Inc, AstraZeneca  Pharmaceuticals LP, BeiGene, Boehringer  Ingelheim, Bristol Myers Squibb, Celgene,  Debiopharm International SA, Genentech Inc, HalioDX SAS, Hoffmann-La R<\/b> Institutional financial interests, my institution received\u000d\u000ahonoraria due to my investigator contribution in clinical\u000d\u000atrials. <br><b>S. Sciallero, <\/b> <br><b>Pfizer<\/b> Other, Travel, accomodations, expenses. <br><b>Novartis-AAA<\/b> Other, Travel, accomodations, expenses. <br><b>Amgen<\/b> Other, Travel, accomodations, expenses\u000d\u000aSpeakers’ bureau\/round tables. <br><b>Ipsen<\/b> Other, Travel, accomodations, expenses. <br><b>Cellgene<\/b> Other, Travel, accomodations, expenses. <br><b>AstraZeneca<\/b> Other, Travel, accomodations, expenses\u000d\u000aSpeakers’ bureau\/round tables. <br><b>Servier<\/b> Other, Speakers’ bureau\/round tables. <br><b>Merck<\/b> Other, Speakers’ bureau\/round tables. <br><b>MSD<\/b> Other, Speakers’ bureau\/round tables.<br><b>E. Berrino, <\/b> None..<br><b>M. Carullo, <\/b> None..<br><b>P. Vitiello, <\/b> None..<br><b>M. Aquilano, <\/b> None..<br><b>M. Di Como, <\/b> None..<br><b>E. Bonoldi, <\/b> None.&nbsp;<br><b>S. Siena, <\/b> <br><b>Agenus<\/b> Other, advisory board member. <br><b>AstraZeneca<\/b> Other, advisory board member. <br><b>Bayer<\/b> Other, advisory board member. <br><b>Bristol Myers Squibb<\/b> Other, advisory board member. <br><b>CheckmAb<\/b> Other, advisory board member. <br><b>Daiichi-Sankyo<\/b> Other, advisory board member. <br><b>GlaxoSmithKline<\/b> Other, advisory board member. <br><b>MSD<\/b> Other, advisory board member. <br><b>Merck<\/b> Other, advisory board member. <br><b>Novartis<\/b> Other, advisory board member. <br><b>Pierre-Fabre<\/b> Other, advisory board member. <br><b>Seagen<\/b> Other, advisory board member. <br><b>T-One Therapeutics<\/b> Other, advisory board member. <br><b>A. Bardelli, <\/b> <br><b>Guardand Health<\/b> Other, Consulting\/advisory role. <br><b>Inivata<\/b> Other, Consulting\/advisory role\u000d\u000aScientific advisory board. <br><b>Neophore<\/b> Other, Research support\u000d\u000aCofounder and shareholder\u000d\u000aScientific advisory board. <br><b>AstraZeneca<\/b> Research support. <br><b>Boehringer-Ingelheim<\/b> Other, Research support. <br><b>Kither<\/b> Shareholder. <br><b>Roche\/Genentech<\/b> Scientific advisory board.<br><b>D. Regge, <\/b> None..<br><b>S. Marsoni, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9351","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"14","PosterboardNumber":"15","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"900","PresenterBiography":null,"PresenterDisplayName":"Luca Lazzari, PhD","PresenterKey":"bba4387b-abfa-48fe-a474-1359058d7490","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"900. Development and validation of an artificial-intelligence-based pathomics biomarker to predict resistance to first-line treatment in metastatic colorectal cancer","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Development and validation of an artificial-intelligence-based pathomics biomarker to predict resistance to first-line treatment in metastatic colorectal cancer","Topics":null,"cSlideId":""},{"Abstract":"Large-scale combination drug screens are largely considered intractable due to the immense number of possible combinations. Existing approaches use ad hoc fixed experimental designs then train machine learning models to impute novel combinations. We introduce BATCHIE, an orthogonal approach that adaptively conducts experiments in batches. BATCHIE uses information theory and probabilistic modeling to design each batch to be maximally informative based on the results of previous experiments. BATCHIE is fully modular, allowing any Bayesian probabilistic model to be used and any study constraints to be incorporated while maintaining optimality guarantees.<br \/>Results: In retrospective simulations on public combination screens, BATCHIE saved 10s of thousands to 100s of thousands of experiments relative to non-adaptive baselines. We conducted a prospective study focusing on pediatric sarcomas with BATCHIE. Our study covered 16 cell lines spanning Ewing sarcoma (EWS), osteosarcoma, rhabdomyosarcoma, as well as non-sarcoma cancers and non-cancer lines. We used a drug library of 206 drugs at two doses. After 15 rounds of BATCHIE-driven data collection, we observed 54K unique combinations, covering 4% of the experimental landscape. On unobserved validation data, the BATCHIE model predictions were highly accurate (Pearson&#8217;s rho=0.91, p&#60;10-30) and detected the rare (0.004%) combinations with significant synergy (AUC of ROC=0.85, p&#60;10-5). We further investigated 10 combinations that BATCHIE predicted to have high therapeutic index (TI) for a broad selection of EWS lines, meaning a large differential effect between the predicted viabilities of the control lines and the target lines. We found that the TI scores for the top hits were significantly larger than the rest of the screen (p&#60;10<sup>-<\/sup>50), with the median top hit TI score lying in the 98th percentile of observed TI scores. We further validated 6 of the top hits in an ex vivo study on 2 patient-derived EWS samples, again finding significantly large TI values (p&#60;10-13), with the median ex vivo TI score lying in the 96th percentile of observed TI scores. The top hits also exhibited biologically plausible rationales including combining PARP inhibitors with topoisomerase 1 inhibitors and alkylating agents, despite our model utilizing no prior knowledge on the molecular targets of our drug library. Combining PARP inhibitors with topoisomerase 1 inhibitors comprise 3 of the 6 currently open phase II clinical combination trials for EWS.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Combination studies,Machine learning,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>C. Tosh<\/b><sup>1<\/sup>, M. Tec<sup>2<\/sup>, J. White<sup>1<\/sup>, J. F. Quinn<sup>1<\/sup>, G. Ibanez Sanchez<sup>1<\/sup>, P. Calder<sup>1<\/sup>, A. L. Kung<sup>1<\/sup>, F. S. Dela Cruz<sup>1<\/sup>, W. Tansey<sup>1<\/sup>; <br\/><sup>1<\/sup>Memorial Sloan Kettering Cancer Center, New York, NY, <sup>2<\/sup>Harvard University, Cambridge, MA","CSlideId":"","ControlKey":"5126d32d-68fb-4f9d-99cc-10a091244d5d","ControlNumber":"6602","DisclosureBlock":"&nbsp;<b>C. Tosh, <\/b> None..<br><b>M. Tec, <\/b> None.&nbsp;<br><b>J. White, <\/b> <br><b>SpringWorks Therapeutics<\/b> Independent Contractor, Stock.<br><b>J. F. Quinn, <\/b> None..<br><b>G. Ibanez Sanchez, <\/b> None..<br><b>P. Calder, <\/b> None.&nbsp;<br><b>A. L. Kung, <\/b> <br><b>Emendo Biotherapeutic<\/b> Stock, Other, Scientific Advisory Board. <br><b>Karyopharm Therapeutic<\/b> Other, Scientific Advisory Board. <br><b>Imago BioSciences<\/b> Stock, Other, Scientific Advisory Board. <br><b>DarwinHealth<\/b> Other, Scientific Advisory Board. <br><b>Isabl<\/b> Stock, Other, Scientific Advisory Board, co-founder. <br><b>Labcorp<\/b> Other, Royalty income. <br><b>F. S. Dela Cruz, <\/b> <br><b>Eisai<\/b> Other, Institutional research support. <br><b>Y-mAbs Therapeutics<\/b> Other, Institutional research support.<br><b>W. Tansey, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9352","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"15","PosterboardNumber":"16","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"901","PresenterBiography":null,"PresenterDisplayName":"Christopher Tosh","PresenterKey":"88d5bee3-2f6d-418b-af22-7f6bc6d66129","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"901. BATCHIE: An active learning platform for scalable combination drug screens","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"BATCHIE: An active learning platform for scalable combination drug screens","Topics":null,"cSlideId":""},{"Abstract":"Accurately predicting drug sensitivity and understanding what is driving it are major challenges in drug discovery. Graphs are a natural framework for capturing diverse pharmacological data for efficacy predictions, thanks to their ability to integrate multimodal data and represent relationships such as gene-gene or drug-target interactions as edges. They have also had proven success across a range of other drug discovery tasks including repositioning and target identification. In this study, we sought to address the explainability challenges of drug response predictions. Recent developments in the field of Graph AI have led to improvements in interpretability mechanisms that highlight parts of a graph which are driving predictions. We have conducted a comprehensive review of multiple major approaches for tackling drug efficacy prediction using graph methods, benchmarking the performance and interpretability of these algorithms across indications.<br \/>Methods: We assembled a combined dataset of GDSC1 and GDSC2<sup> <\/sup>drug response data in cell lines, with multiomic cell line data and drug target and chemical structure data. We then applied graph-based approaches for the prediction of binarized IC50 on an indication-by-indication basis. Approach 1 involved the creation of a &#8216;GDSC knowledge graph&#8217;, where drug response and cell line &#8216;omic information is represented in an unweighted knowledge graph: cell lines are connected to genes expressed in them, drugs are connected to genes they target, and so on. We then used state-of-the-art graph embedding techniques to predict IC50 using paired drug and cell line embeddings. In Approach 2 we used a weighted knowledge graph instead, and generated embeddings using heterogeneous graph neural networks (HGNNs). In Approach 3, we modelled response prediction as a graph classification task, where one single graph captures one drug-cell line interaction. The graph classifier and HGNN models both have in-built interpretability mechanisms, including graph attention, that can signify the genes in the cell line which were most important for the eventual prediction. We can also integrate biomedical prior knowledge with all these models by capturing gene-pathway and gene-gene data in the graphs.<br \/>Results: Our models outperformed benchmark models including DNNs and GBMs, and identified both established and novel response biomarkers in NSCLC cell lines (AUC = 0.94, Accuracy = 89%). We have also applied our models to Breast Cancer, Pancreatic Cancer, Colorectal Cancer and Haematological malignancies with similar predictive performance and explainability.<br \/>Conclusions:Our graph analytical framework for response predictions showed better performance than benchmarking models and provided insights from explainability. This framework is easily extendable to response and &#8216;omic data from any disease model and patient studies.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Preclinical,Graph,Biomarker,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>J. Cohen-Setton<\/b><sup>1<\/sup>, K. Bulusu<sup>1<\/sup>, J. Dry<sup>2<\/sup>, B. Sidders<sup>1<\/sup>; <br\/><sup>1<\/sup>AstraZeneca UK, Cambridge, United Kingdom, <sup>2<\/sup>Tempus AI, Boston, MA","CSlideId":"","ControlKey":"95005130-6a65-4d01-9dcf-17eab7e74a6c","ControlNumber":"6886","DisclosureBlock":"<b>&nbsp;J. Cohen-Setton, <\/b> <br><b>AstraZeneca UK<\/b> Employment, Stock. <br><b>K. Bulusu, <\/b> <br><b>AstraZeneca UK<\/b> Employment, Stock. <br><b>J. Dry, <\/b> <br><b>AstraZeneca<\/b> Employment. <br><b>B. Sidders, <\/b> <br><b>AstraZeneca UK<\/b> Employment, Stock.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9353","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"16","PosterboardNumber":"17","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"902","PresenterBiography":null,"PresenterDisplayName":"Jake Cohen-Setton, MS,BA","PresenterKey":"1a76e529-233b-4bdb-994a-96a687d8e196","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"902. Explainable AI: Graph machine learning for response prediction and biomarker discovery","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Explainable AI: Graph machine learning for response prediction and biomarker discovery","Topics":null,"cSlideId":""},{"Abstract":"Altered cellular state and plasticity have been increasingly identified as drivers of poor prognosis and treatment-resistance in cancer. Identifying therapeutics that correct altered cellular state and plasticity meets a broad need in the field of oncology, particularly in tumors resistant to standard-of-care therapy. Tumor plasticity and altered cellular states encompass many potential configurations, including dedifferentiated and transdifferentiated tumors, so classifying tumors based on their specific cell state profile is critical to identifying the gene drivers that are specific to that altered state. For that reason, we have developed AURIGIN - a platform that combines a comprehensive single-cell OMICs atlas of human development with an AI\/ML framework that can classify cell state plasticity and identify the genes and pathways that drive those specific altered cellular states. AURIGIN is more comprehensive than previously disclosed single cell atlases in that it focuses and enriches the diverse stem, progenitor, and developmental states commonly involved in plastic cell states of cancer. The platform standardizes and integrates these states with multiple atlases of differentiated adult tissues to create a unified atlas of human development. In addition, the AI\/ML paradigm of AURIGIN is embedded with developmental biology models that enable it to deconvolute state heterogeneity within tumor indications for precise identification of the most relevant gene targets for novel therapies. AURIGIN also unifies classified plasticity across tissue types by identifying altered cellular states that span multiple indications. Furthermore, we present the implementation of AURIGINDRIVE ML models that integrate pathway information, physical interaction datasets, and regulatory annotations to accurately predict the gene targets at the top of hierarchy of control of tumor plasticity. AURIGIN also enables and accelerates target validation by identifying models that map to the relevant classified plastic states. Similarly, AURIGIN defines clinically relevant patient selection and treatment efficacy biomarkers that are specifically defined from the classified plastic cellular state. We demonstrate the success of AURIGIN for therapeutic discovery. In sum, AURIGIN amplifies the value of multiOMIC tumor data in cellular state and plasticity target discovery by mapping the data into a developmental biology-informed ML framework.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Multiomics,Cancer,Differentiation,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>J. DeBartolo III<\/b>, H. Wilson, K. S. Straley, M. Bhatta, S. Sharma, S. Sinicropi-Yao, J. Neef, B. Chan, A. McRiner, M. Bittinger, L. Antipov, K. E. Yen, T. G. Graeber, D. S. Millan; <br\/>Auron Therapeutics, Newton, MA","CSlideId":"","ControlKey":"71eb54fd-56a2-41cd-ac8d-3d9e8e638360","ControlNumber":"7059","DisclosureBlock":"<b>&nbsp;J. DeBartolo, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>H. Wilson, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>K. S. Straley, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>M. Bhatta, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>S. Sharma, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>S. Sinicropi-Yao, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>J. Neef, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>B. Chan, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>A. McRiner, <\/b> <br><b>Auron Therapeutics<\/b> Stock Option. <br><b>M. Bittinger, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>L. Antipov, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>K. E. Yen, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>T. G. Graeber, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option. <br><b>D. S. Millan, <\/b> <br><b>Auron Therapeutics<\/b> Employment, Stock Option.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9354","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"17","PosterboardNumber":"18","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"903","PresenterBiography":null,"PresenterDisplayName":"Joseph DeBartolo","PresenterKey":"79459f3e-a13c-41a6-8632-26b24612a61f","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"903. AURIGIN: A comprehensive single-cell OMICs atlas of human development and an AI\/ML framework to classify and identify the drivers of tumor plasticity and altered cellular state","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AURIGIN: A comprehensive single-cell OMICs atlas of human development and an AI\/ML framework to classify and identify the drivers of tumor plasticity and altered cellular state","Topics":null,"cSlideId":""},{"Abstract":"T cell inducing vaccines are key for the development of effective therapies against cancer and infectious diseases. Peptides, presented by Human Leukocyte Antigens (HLAs), are the targets of T cells, and their identification is therefore critical to the development of such vaccines. Here, we present the latest improvement in our EDGE<sup>TM<\/sup> (<u>E<\/u>pitope <u>D<\/u>iscovery for <u>GE<\/u>nomes) platform to address this critical need. EDGE is comprised of AI models that can predict peptide presentation by HLA class I and class II. Although the models are trained primarily using immunopeptidomics data, EDGE scores are predictive of peptide-HLA immunogenicity. There are three class I presentation models in EDGE: an allele-specific model, a pan-specific model, and a model specific for infectious diseases. The allele-specific model is applicable to a large but pre-defined set of HLA alleles. On a large test dataset, the allele-specific model achieved an average precision (AP) of 63% (PPV40=79%) compared to the AP of a standard best-available public model of 21% (PPV40=28%). A Ph1\/2 clinical study of personalized cancer vaccines encoding neoantigens predicted from the allele-specific model demonstrated a ~50% molecular response (defined as &#62;=30% reduction in circulating tumor DNA relative to baseline) rate with associated extended overall survival (vs non-responders) in metastatic, microsatellite stable colorectal cancer patients. We observed that <u>&#62;<\/u>50% of the mutations were able to elicit T cell responses. The pan-specific class I model uses HLA sequences as input feature when training and, therefore, is applicable to any HLA. On the same test dataset as above, it achieved an AP of 65% (PPV40=81%) and performed better on average for ~40 less-common HLA alleles. Prediction of viral peptide presentation by HLA class I is challenging due to the lack of immunopeptidomics data. The class I model for infectious diseases was specifically optimized to predict for viral peptides and, therefore, performed better than available class I models on published HIV and Influenza A datasets. Prediction of peptide presentation by HLA class II is challenging due to the flexibility in how the longer peptides interact with open HLA grooves as well as the lack of immunopeptidomics data as compared to the class I peptides. The class II model in EDGE, EDGE-II, uses the latest developments in protein large language models, a novel learned HLA allele-deconvolution strategy, and in-house immunopeptidomics data, resulting in improved prediction of peptide presentation by HLA class II and immunogenicity driven by CD4<sup>+<\/sup> T cells. On a benchmark validation dataset, EDGE-II achieved an AP of 71% as compared to AP of 62% of a leading published model. In summary, EDGE<sup>TM<\/sup> provides a comprehensive state-of-the-art platform for the development of vaccines that can induce both CD8<sup>+<\/sup> and CD4<sup>+<\/sup> T cell responses to provide durable benefit to patients.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Vaccines,T cell epitopes,Artificial Intelligence and Machine learning,Immunotherapy,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"J. Klein, D. Sprague, M. Lane, M. Hart, O. Petrillo, I. do Valle, M. Davis, A. Ferguson, A. Allen, K. Jooss, <b>A. Dhanik<\/b>; <br\/>Gritstone bio, Inc., Emeryville, CA","CSlideId":"","ControlKey":"f78936c7-15b9-483e-8e39-f49abf6f59d3","ControlNumber":"7394","DisclosureBlock":"<b>&nbsp;J. Klein, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>D. Sprague, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>M. Lane, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>M. Hart, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>O. Petrillo, <\/b> <br><b>Olivia Petrillo<\/b> Employment, Stock, Stock Option. <br><b>I. do Valle, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>M. Davis, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>A. Ferguson, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>A. Allen, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Fiduciary Officer, Stock, Stock Option. <br><b>K. Jooss, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option. <br><b>A. Dhanik, <\/b> <br><b>Gritstone bio, Inc.<\/b> Employment, Stock, Stock Option.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9355","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"18","PosterboardNumber":"19","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"904","PresenterBiography":null,"PresenterDisplayName":"Ankur Dhanik","PresenterKey":"ed547dc5-3a3f-460d-9e5c-a315d6076f36","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"904. AI platform provides an EDGE and enables state-of-the-art identification of peptide-HLAs for the development of T cell inducing vaccines","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"AI platform provides an EDGE and enables state-of-the-art identification of peptide-HLAs for the development of T cell inducing vaccines","Topics":null,"cSlideId":""},{"Abstract":"Immune phenotypes (IP), defined by the tumor-infiltrating lymphocyte (TIL) distribution within the tumor microenvironment (TME), is prognostic and predictive of treatment response. Here, machine learning (ML) models that characterize the TME were deployed in non-small cell lung cancer (NSCLC) and head and neck squamous cell carcinoma (HNSCC) to exhaustively label TILs directly from hematoxylin and eosin (H&#38;E)-stained whole slide images (WSI), compute IP and quantify TIL distribution, tasks which are manually untenable.<br \/>ML-powered TME models (PathAI, Boston, MA; commercially available as PathExplore&#8482;) for NSCLC and HNSCC that quantify tissue regions (e.g. tumor, epithelium, and stroma) and cells (e.g. lymphocytes) in H&#38;E-stained WSI were deployed on 126 NSCLC and 103 HNSCC commercial samples. Ground truth CD3 and CD8 scores were obtained from paired immunohistochemically-stained WSI (HALO, Indica Labs, Albuquerque, NM). Inflamed, desert, or excluded IPs (based on data-driven cutoffs) were inferred from the mean TIL density in epithelium and stroma (slide-level IP, sIP), and from the fraction of &#8220;hot&#8221; patches in all 100um x 100um patches tiling the tumor and stroma areas (patch-level IP, pIP). TIL spatial distribution was measured by the Morisita-Horn index that computes the patch-wise overlap between TILs and cancer cells (MHI, ranging from 0 to 1), and epithelial-stromal interface distance index (EDI) indicating the hot stromal patch bias toward the epithelium (-EDI) or stroma (+EDI).<br \/>ML-predicted TIL densities highly correlated with ground truth CD3+ and CD8+ cell densities (NSCLC\/HNSCC CD3, CD8: tumor Pearson r= 0.88\/0.85, 0.74\/0.74; epithelium r= 0.76\/0.71, 0.88\/0.62; stroma r= 0.74\/0.87, 0.61\/0.76). High s- and pIP agreement was seen (NSCLC 93% and HNSCC 83%); 6\/26 discordant cases were driven by TIL hotspots with high density (116%-310% of the cutoff) but few (median = 26%) hot patches in the epithelium. MHI was higher for the inflamed vs excluded IP (p &#60; 0.0001 for NSCLC and HNSCC) and intra-group variability was high (NSCLC\/HNSCC inflamed: 0.66&#177;0.11\/0.31&#177;0.14, excluded: 0.51&#177;0.12\/0.26&#177;0.17, desert: 0.48&#177;0.09\/0.28&#177;0.17; mean&#177;std). EDI was lowest and negative in inflamed IP but near zero in desert and excluded IP (NSCLC\/HNSCC inflamed: -43&#177;4um\/-184&#177;19um, excluded: 1.6&#177;4um\/-41&#177;13um, desert: 18&#177;4um\/-14&#177;13; mean&#177;sem). Excluded and desert IPs had roughly equal + and - EDI cases (NSCLC +\/-: 57\/46; HNSCC +\/-: 39\/29).<br \/>ML-powered IP prediction using TIL distribution enables accurate and rapid profiling of the TME using routine histopathology. pIPs were concordant with sIPs and highlight TIL heterogeneity. Spatial markers (MHI and EDI) reveal differences between IP classes and intra-group heterogeneity relevant for drug discovery and patient stratification. Investigating prognostic associations of these markers is a promising direction for future studies.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Tumor infiltrating lymphocytes,Machine learning,Tumor microenvironment,Head and neck squamous cell carcinoma,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>N. Le<\/b><sup>1<\/sup>, B. Rahsepar<sup>1<\/sup>, J. Hipp<sup>1<\/sup>, J. Conway<sup>1<\/sup>, Y. Gerardin<sup>1<\/sup>, E. Krause<sup>1<\/sup>, C. Shen<sup>1<\/sup>, R. Biju<sup>1<\/sup>, M. Nercessian<sup>1<\/sup>, N. Indorf<sup>1<\/sup>, S. Degryse<sup>1<\/sup>, M. Markey<sup>1<\/sup>, V. Mountain<sup>1<\/sup>, P. Vaidya<sup>2<\/sup>, W. Wijaya<sup>2<\/sup>, A. Shrotre<sup>2<\/sup>, P. Caplazi<sup>2<\/sup>, D. Inzunza<sup>2<\/sup>, J. Palma<sup>2<\/sup>, E. Huntzicker<sup>2<\/sup>, C. Tribouley<sup>2<\/sup>, D. Chen<sup>2<\/sup>, R. Prediou<sup>2<\/sup>, F. Chen<sup>2<\/sup>, K. Kolahi<sup>2<\/sup>; <br\/><sup>1<\/sup>PathAI, Inc., Boston, MA, <sup>2<\/sup>AbbVie, Chicago, IL","CSlideId":"","ControlKey":"b64ef822-c74e-4095-a8ad-43db731a3d7e","ControlNumber":"7494","DisclosureBlock":"<b>&nbsp;N. Le, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>B. Rahsepar, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>J. Hipp, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>J. Conway, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>Y. Gerardin, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>E. Krause, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>C. Shen, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>R. Biju, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>M. Nercessian, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>N. Indorf, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>S. Degryse, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>M. Markey, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>V. Mountain, <\/b> <br><b>PathAI<\/b> Employment, Stock Option. <br><b>P. Vaidya, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>W. Wijaya, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>A. Shrotre, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>P. Caplazi, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>D. Inzunza, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>J. Palma, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>E. Huntzicker, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>C. Tribouley, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>D. Chen, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>R. Prediou, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>F. Chen, <\/b> <br><b>AbbVie<\/b> Employment, Stock. <br><b>K. Kolahi, <\/b> <br><b>AbbVie<\/b> Employment, Stock.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9356","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"19","PosterboardNumber":"20","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"905","PresenterBiography":null,"PresenterDisplayName":"Nhat Le, PhD","PresenterKey":"23ae5114-0729-494c-95d7-01aa312b61c2","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"905. ML quantification of tumor-Infiltrating lymphocytes distinguishes immune-phenotypes and reveals phenotypic heterogeneity","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"ML quantification of tumor-Infiltrating lymphocytes distinguishes immune-phenotypes and reveals phenotypic heterogeneity","Topics":null,"cSlideId":""},{"Abstract":"We develop SPIDER, a zero-shot model which can predict the abundance for a large scale (&#62;2,000) of surface proteins from single-cell transcriptomes in various contexts. This is to overcome the challenges in current single-cell protein abundance quantification tools (e.g., flow cytometry, CITE-seq) and computational models (e.g., totalVI, Seurat, cTPnet), where routinely only &#60;300 surface proteins can be quantified or predicted. Comprehensive benchmarking on four external validation sets shows that the prediction accuracy of SPIDER outperforms other state-of-the-art methods including Seurat, totalVI, and cTPnet, with a prediction accuracy elevated as much as 42.5% in new contexts. We further conduct case studies in cancers by applying SPIDER to predict the abundance of &#62;2,500 surface proteins on scRNA-seq datasets of hepatocellular carcinoma (HCC) and colorectal cancer liver metastasis (RCRLM), where the predicted surface protein abundance data is analyzed to demonstrate the broad downstream applications of SPIDER including facilitating cell type annotation, disease biomarker\/target identification, and cell-cell interaction (CCI) inference. For instance, in these datasets we find that SPIDER can reveal (novel) disease biomarkers that are overlooked by solely observing transcript expression, such as CD44\/PIK3IP1 in hepatocytes\/ &#947;&#948;2 T cells as a positive\/negative HCC biomarker, demonstrating the capability of SPIDER to compensate for the limitations in the RNA modality. In conclusion, we propose the SPIDER model which can provide valuable information on the abundance of a large scale of surfaceomes in single cells, and can be further used to gain new insights into cancers via promoting cell type annotation, disease biomarker\/target identification, and CCI inference.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Single cell,Protein expression,Cancer,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>R. Chen<\/b>, B. Chen, J. Zhou; <br\/>Michigan State University, East Lansing, MI","CSlideId":"","ControlKey":"902d09f6-af22-4b0d-9916-af6266c26b56","ControlNumber":"7499","DisclosureBlock":"&nbsp;<b>R. Chen, <\/b> None..<br><b>B. Chen, <\/b> None..<br><b>J. Zhou, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9357","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"20","PosterboardNumber":"21","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"906","PresenterBiography":null,"PresenterDisplayName":"Ruoqiao Chen","PresenterKey":"d3a472e7-4cb7-46e8-8d4c-4d27f6d2cffc","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"906. Large-scale surface protein abundance prediction from single-cell transcriptomes with a zero-shot model and its applications to cancer research","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Large-scale surface protein abundance prediction from single-cell transcriptomes with a zero-shot model and its applications to cancer research","Topics":null,"cSlideId":""},{"Abstract":"Precision oncology hinges on accurate prediction of patient-specific treatment response from tumor molecular inputs. While deep learning (DL) models achieve state-of-the-art response prediction in cell lines, existing methods do not readily translate to the clinic where training data is limited. Here, we have developed and validated ScreenDL, a novel DL framework designed explicitly for use in clinical precision oncology applications. The underlying architecture of ScreenDL consists of two fully connected branches dedicated to learning rich embeddings of a drug&#8217;s chemical structure and a tumor&#8217;s transcriptomic profile respectively. These tumor omic and drug molecular embeddings are fed into a shared response prediction subnetwork which outputs predicted ln(IC50) values. The ScreenDL training schema incorporates three phases, each designed to improve clinical response prediction: (1) an initial pretraining phase leverages large-scale cell line pharmacogenomic datasets to extract patterns\/relationships linking tumor omics and drug response; (2) subsequent transfer learning integrates pharmacogenomic data from patient-derived models of cancer, adapting the pretrained model to a more patient-relevant context; (3) patient-level omics and drug screening data (e.g., from matched patient-derived organoid (PDO) models) is integrated through patient-specific fine-tuning, generating a patient-specific response prediction model. Importantly, biomaterial from surgical tumor resection is often available for organoid establishment and patient-specific drug screening in practical clinical scenarios. To assess the utility of our ScreenDL framework for clinical response prediction, we applied ScreenDL to predict treatment response in 50 advanced\/metastatic triple negative breast cancer (TNBC) patient-derived xenograft models (PDX). We leveraged tumor omics profiles for each PDX and drug screening data from matched PDX-derived organoids (PDxOs), mirroring the combination of patient-level tumor omic characterization and functional drug screening in matched PDOs, a protocol currently being piloted in Functional Precision Oncology trials at the University of Utah Huntsman Cancer Institute. After cell line pretraining, ScreenDL achieves a modest median Pearson correlation per drug of 0.15 relative to 0.03 for the leading compared model. However, transfer learning and subsequent PDX-specific fine-tuning significantly improve performance, producing median Pearson correlations per drug of 0.39 and 0.51, respectively. These results demonstrate the ability of our ScreenDL framework to dramatically improve response prediction in clinically relevant domains, bringing DL-based precision treatment selection closer to clinical application.<b><i><\/i><\/b>","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Drug sensitivity,Cancer therapy,Machine learning,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>C. Sederman<\/b>, T. Di Sera, Y. Qiao, X. Huang, B. E. Welm, A. L. Welm, G. Marth; <br\/>University of Utah, Salt Lake City, UT","CSlideId":"","ControlKey":"4f11ca04-59e9-40bd-8c8f-1ae564fb3cb4","ControlNumber":"7513","DisclosureBlock":"&nbsp;<b>C. Sederman, <\/b> None..<br><b>T. Di Sera, <\/b> None..<br><b>Y. Qiao, <\/b> None..<br><b>X. Huang, <\/b> None..<br><b>B. E. Welm, <\/b> None..<br><b>A. L. Welm, <\/b> None..<br><b>G. Marth, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9358","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"21","PosterboardNumber":"22","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"907","PresenterBiography":null,"PresenterDisplayName":"Casey Sederman","PresenterKey":"6dd188df-fe43-42be-8f01-6988834fdf2f","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"907. ScreenDL: A transfer learning framework integrating tumor omics and functional drug screening for personalized clinical drug response prediction","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"ScreenDL: A transfer learning framework integrating tumor omics and functional drug screening for personalized clinical drug response prediction","Topics":null,"cSlideId":""},{"Abstract":"Multi-omics research has enhanced our understanding of cancer heterogeneity and progression. Investigating molecular data through multi-omics approaches is crucial for unraveling the complex biological mechanisms underlying cancer, thereby enabling more effective diagnosis, treatment, and prevention strategies. However, predicting patient outcomes through integration of all available multi-omics data is still an under-study research direction. Here, we present SeNMo (<u>Se<\/u>lf-normalizing <u>N<\/u>etwork for <u>M<\/u>ulti-<u>o<\/u>mics), a deep neural network that ensures the zero mean and unit variance of activations across network layers using the self-normalizing technique. Such normalizing techniques are critical in stable and robust learning of deep learning models. SeNMo is particularly efficient in handling multi-omics data characterized by high-width (many features) and low-length (fewer samples) attributes. We trained SeNMo for the task of overall survival of patients using pan-cancer multi-omics data involving 28 cancer sites from the Genomic Data Commons (GDC). The training multi-omics data includes gene expression, DNA methylation, miRNA expression, and protein expression modalities. We tested the model's performance on the Moffitt Cancer Center's internal data involving RNA expression and protein expression data. We evaluated the model&#8217;s performance in predicting patient&#8217;s overall survival using the concordance index (C-Index), which provides a robust measure of the model's predictive capability. SeNMo performed consistently well in the training regime, reflected by the validation C-Index&#8805;0.6 on GDC's public data. In the testing regime on Moffitt's private data, SeNMo performed with a C-Index of 0.68. The model's performance increased when tested on low-dimensional data or when tested on single omic data such as RNA or protein expression data with a C-Index of 0.7. SeNMo proved to be a mini-foundation model for multi-omics oncology data because it demonstrated robust performance, adaptability across molecular data types, and universal approximator capabilities for the scale of molecular data it was trained on. SeNMo can be further scaled to any cancer site and molecular data type. It can also be fine-tuned for other downstream tasks such as treatment response prediction, risk stratification, patient subgroup identification, and others. Its ability to accurately predict patient outcomes and adapt to various downstream tasks indicates a new era in cancer research and treatment. For future research, SeNMo offers a powerful tool for uncovering deeper insights into the complex nature of cancer and sets a precedent for how artificial intelligence can be leveraged to handle the vast and intricate data in the biomedical field. We believe SeNMo and similar models are poised to transform the oncology landscape, offering hope for more effective, efficient, and patient-centric cancer care.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Deep learning,Multiomics,Overall survival,Cancer,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"A. Waqas<sup>1<\/sup>, <b>A. Tripathi<\/b><sup>1<\/sup>, S. Ahmed<sup>1<\/sup>, A. Mukund<sup>1<\/sup>, P. Stewart<sup>1<\/sup>, M. Naeini<sup>2<\/sup>, H. Farooq<sup>3<\/sup>, G. Rasool<sup>1<\/sup>; <br\/><sup>1<\/sup>Moffitt Cancer Center, Tampa, FL, <sup>2<\/sup>University of South Florida, Tampa, FL, <sup>3<\/sup>University of Minnesota, Minneapolis, MN","CSlideId":"","ControlKey":"b346eff4-db1e-4acb-ae53-1a62d0a4406e","ControlNumber":"7934","DisclosureBlock":"&nbsp;<b>A. Waqas, <\/b> None..<br><b>A. Tripathi, <\/b> None..<br><b>S. Ahmed, <\/b> None..<br><b>A. Mukund, <\/b> None..<br><b>P. Stewart, <\/b> None..<br><b>M. Naeini, <\/b> None..<br><b>H. Farooq, <\/b> None..<br><b>G. Rasool, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9359","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"22","PosterboardNumber":"23","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"908","PresenterBiography":null,"PresenterDisplayName":"Aakash Tripathi","PresenterKey":"44070449-eb00-47b4-8526-7db0c2ddb94b","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"908. SeNMo: A self-normalizing deep learning model for enhanced multi-omics data analysis in oncology","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"SeNMo: A self-normalizing deep learning model for enhanced multi-omics data analysis in oncology","Topics":null,"cSlideId":""},{"Abstract":"Formalin-Fixed Paraffin-Embedded (FFPE) specimens, widely utilized in clinical cancer diagnostics, present significant challenges by introducing artifacts into genomic data. This study aimed to profile these FFPE-induced genomic alterations, with a particular focus on single-nucleotide variants (SNVs), small insertions and deletions (indels), and copy-number variations (CNVs), and to develop computational methods for filtering out such artifacts. Our primary focus was twofold: first, to comprehensively characterize the unique error profile of FFPE specimens observed through whole-genome sequencing (WGS), and second, to construct artifact classifiers and noise filters for SNV\/indels and CNVs. We utilized machine learning (ML) and signal-processing techniques on a dataset of FFPE and matched fresh-frozen (FF) samples. The dataset of 52 FFPE-FF pairs were obtained from four different medical institutes and from various cancers including liver, breast, colon, stomach, and lung cancer, with varied FFPE archiving times. We also analyzed additional FFPE-only samples to refine our methods. Our methodology incorporated advanced computational approaches, including stacking ensemble, transfer learning, and wavelet transform, to enhance robustness and accuracy. The method's design was centered around the notion of not only achieving high performance in distinguishing true signals from FFPE-induced artifacts but also addressing the real-world challenges posed by the varying quality and conditions of clinical FFPE samples. In the analysis, we found peculiar patterns of FFPE-specific error profile, including well-known cytosine deamination and novel mutational signatures. The classifier, building on our findings, effectively differentiated true genomic variants from FFPE-induced artifacts for both SNVs and indels, demonstrating a sensitivity of 0.97, specificity of 0.87, and an F1 score of 0.94 for SNVs. For indels, it achieved a sensitivity of 0.91, specificity of 0.91, and an F1 score of 0.91. The CNV filter notably enhanced the signal-to-noise ratio (SNR) of CNV depth profiles, increasing it from 13dB to 17.5dB on average. Furthermore, we conducted evaluations on two critical measures in cancer and clinical genomics: homologous recombination deficiency (HRD) and tumor mutational burden (TMB), achieving post-filtering concordance rates of 0.99 for HRD&#8212;correctly identifying all 8 HRD-positive patients in our dataset&#8212;and 0.96 for SNV-based TMB and 0.87 for indel-based TMB. Additionally, a post hoc procedure for sensitive detection of cancer driver mutations resulted in concordance rates of 0.94 for SNVs, 0.91 for indels, and 0.95 for oncogene amplification. Taken together, our study advances FFPE WGS analysis in cancer diagnostics by effectively filtering artifacts and addressing challenges with older, degraded samples, enhancing clinical applicability.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"FFPE,Genomics,Whole genome sequencing,Machine learning,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>J. Lim<\/b><sup>1<\/sup>, S. Park<sup>1<\/sup>, W.-C. Lee<sup>2<\/sup>, R. Kim<sup>1<\/sup>, S. Lee<sup>2<\/sup>, J. Lee<sup>1<\/sup>, B.-L. Oh<sup>1<\/sup>, Y. Ju<sup>1<\/sup>; <br\/><sup>1<\/sup>Genome Insight Technology, Inc., Daejeon, Korea, Republic of, <sup>2<\/sup>Genome Insight, Inc., San Diego, CA","CSlideId":"","ControlKey":"87a074ff-9b93-43a5-885b-1cafbeca4e14","ControlNumber":"7954","DisclosureBlock":"&nbsp;<b>J. Lim, <\/b> None..<br><b>S. Park, <\/b> None..<br><b>W. Lee, <\/b> None..<br><b>R. Kim, <\/b> None..<br><b>S. Lee, <\/b> None..<br><b>J. Lee, <\/b> None..<br><b>B. Oh, <\/b> None..<br><b>Y. Ju, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9360","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"23","PosterboardNumber":"24","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"909","PresenterBiography":null,"PresenterDisplayName":"Joonoh Lim, MD;PhD","PresenterKey":"d66829cb-b89f-4ce7-8a14-20e6976aab92","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"909. Enhancing genomic analysis in cancer diagnostics: A machine learning approach for removing artifacts in FFPE specimens","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Enhancing genomic analysis in cancer diagnostics: A machine learning approach for removing artifacts in FFPE specimens","Topics":null,"cSlideId":""},{"Abstract":"<b>Background: <\/b>Tumor ploidy and heterogeneity demonstrated to be pivotal in predicting immunotherapy response in cutaneous melanoma in several independent cohorts (Liu NatMed2019, Tarantino BioRXiv2022). Their estimation can guide more personalized and rational utilization of these immunotherapies. However, 1) the biology underpinning ploidy and heterogeneity is unknown; and 2) these findings were derived in patients using retrospective research tumor-normal paired whole exome sequencing which is not performed for clinical management.<br \/><b>Methods: <\/b>This study addresses this gap by employing deep learning models to predict these crucial markers using routinely available clinical assays, including H&#38;E images. Attention-based computer vision models enable the identification of key morphological features in H&#38;E slides. Segmentation of tumor tissue to perform automated masking, enhances ploidy inference.Moreover, biologically informed neural networks (P-Net, Elmarakeby Nature2021) uncover transcriptional and genomic features linked to ploidy and tumor heterogeneity. Our models are trained on publicly available data (e.g., Liu et al Nature Medicine 2019; TCGA SKCM) from melanoma cohorts and further validated in independent cohorts to ensure robustness.<br \/><b>Results: <\/b>We developed and validated automated tumor tissue masking, enabling the prediction of Whole Genome Doubling (WGD) from H&#38;E Slides with an AUC &#62; 0.75. Attention-based models identify distinct Tumor Microenvironment (TME) structures predictive of high tumor heterogeneity. P-Net application revealed the Calmodulin pathway, previously associated with regulating proliferation in cancer and targeted with chemotherapy, as intricately linked to high tumor heterogeneity, providing valuable insights into underlying mechanisms.<br \/><b>Conclusion: <\/b>In conclusion, our study strategically harnesses and integrates existing datasets to rigorously test, refine, and validate hypotheses concerning the biological and therapeutic implications of genomic heterogeneity and ploidy. Notably, our predictive models with automated tumor masking demonstrate a remarkable AUC &#62;0.75 for biomarkers traditionally challenging to derive from clinical assays. This breakthrough opens avenues for novel therapeutic strategies targeting genomic heterogeneity and ploidy, providing a transformative potential to enhance patient care and outcomes.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Melanoma\/skin cancers,Machine learning,Biomarkers,Immune checkpoint blockade,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>M. Glettig<\/b>, G. Tarantino, T. Aprati, H. Elmarakeby, D. Liu; <br\/>Dana-Farber Cancer Institute, Boston, MA","CSlideId":"","ControlKey":"38761883-e9aa-40e8-bf9c-3840e8f0d9d8","ControlNumber":"8012","DisclosureBlock":"&nbsp;<b>M. Glettig, <\/b> None..<br><b>G. Tarantino, <\/b> None..<br><b>T. Aprati, <\/b> None..<br><b>H. Elmarakeby, <\/b> None..<br><b>D. Liu, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9361","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"24","PosterboardNumber":"25","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"910","PresenterBiography":null,"PresenterDisplayName":"Marc Glettig","PresenterKey":"693c6a37-5306-4b32-a084-8072459d9def","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"910. Clinical inference and biological dissection of tumor ploidy and heterogeneity in cutaneous melanoma for immunotherapy response using deep learning","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Clinical inference and biological dissection of tumor ploidy and heterogeneity in cutaneous melanoma for immunotherapy response using deep learning","Topics":null,"cSlideId":""},{"Abstract":"Cachexia is a debilitating syndrome characterized by loss of skeletal muscle tissue that affects over 50% of cancer patients. Defining cachexia for the purposes of epidemiologic analyses has historically been determined by specific weight loss over specific time, and more recently relied on technically challenging interpretation of imaging studies. Subjective appetite or weight loss (AWL) as documented from clinician notes may offer another method of defining a similar phenotype. Although annotation of free-text notes at scale is challenging, we hypothesized that natural language processing (NLP) might successfully annotate AWL from cancer diagnosis medical notes and that such annotations would follow patterns expected from classic cachexia studies.<br \/>We created a gold-standard dataset for NLP training and validation by manually labeling AWL in a cohort of 762 free-text initial consultation notes that were extracted from lung and pancreatic adenocarcinoma electronic health records. Using these labels, we fine-tuned a pre-trained neural Longformer model to classify whether a patient has symptoms of cachexia.<br \/>The AWL model was evaluated on a cohort of 391 pan-cancer notes independent of the training cohort and achieved an AUC of 0.92, precision of 0.88, recall of 0.95, and accuracy of 0.94. To test whether the labels generated by this model behaved as expected from classic cachexia studies, we applied the model to 46,980 initial consultation notes from a pan-cancer cohort of patients with tumor genomic profiling from MSK-IMPACT, an FDA-authorized tumor sequencing assay. Overall, AWL was present in 28% of the patients and it was associated with gastrointestinal cancers, which is expected from previous studies of cachexia. Our analysis revealed that esophagogastric and pancreatic cancer patients had the highest rates of cachexia at around 67%. We also observed that patients with cachexia symptoms have a reduced overall survival compared to patients without (HR=1.80, 95% CI=[1.75, 1.85]), which held in several specific cancers including NSCLC (HR=1.79, 95% CI=[1.66, 1.94]), pancreatic cancer (HR=1.34, 95% CI=[1.22, 1.47]), and colorectal cancer (HR=1.71, 95% CI=[1.55, 1.89]). Cachexia symptoms were more prevalent in male patients than in female patients. Underweight patients by BMI at presentation were most likely to have cachexia symptoms.<br \/>These results reciprocate well-established information about cancer cachexia, demonstrating that our text classification NLP model can be reliably used to predict AWL from free-text medical notes. AWL may thus be a viable means of studying correlates of cachexia at scale in real-world cohorts.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Cachexia,Machine learning,,,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>T. Park<\/b>, K. Pichotta, C. J. Fong, N. Schultz, P. Iyengar, J. Jee, E. Reznik; <br\/>Memorial Sloan Kettering Cancer Center, New York, NY","CSlideId":"","ControlKey":"996d1794-9938-4fe8-89e9-d8e675ec66fd","ControlNumber":"8027","DisclosureBlock":"&nbsp;<b>T. Park, <\/b> None..<br><b>K. Pichotta, <\/b> None..<br><b>C. J. Fong, <\/b> None..<br><b>N. Schultz, <\/b> None.&nbsp;<br><b>P. Iyengar, <\/b> <br><b>AstraZeneca<\/b> Other, Advisory board. <br><b>Incyte<\/b> Grant\/Contract.<br><b>J. Jee, <\/b> None..<br><b>E. Reznik, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9362","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"25","PosterboardNumber":"26","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"911","PresenterBiography":null,"PresenterDisplayName":"Tricia Park","PresenterKey":"8070c98c-5db2-4648-9ea1-859bd0778e6e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"911. Automatic identification of subjective appetite or weight loss in clinician notes empowers studies of cachexia","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Automatic identification of subjective appetite or weight loss in clinician notes empowers studies of cachexia","Topics":null,"cSlideId":""},{"Abstract":"<b>Background: <\/b>Immune Checkpoint Inhibitors (ICIs) are a cornerstone in the treatment of cancers such as Non-Small Cell Lung Cancer (NSCLC). Despite the standard use of biomarkers such as PD-L1 expression for selecting ICI regimens, recent studies suggest missed opportunities for benefit in PD-L1 low\/negative patients. Therefore, there is an urgent need for new biomarker strategies capable of guiding the use of ICIs in NSCLC. We introduce and validate an AI-powered radiology tool for ICI patient selection that provides interpretable predictions by quantifying aspects of tumor biology on baseline CT scans directly associated with ICI efficacy, such as tumor heterogeneity and twistedness of the tumor-associated vasculature.<br \/><b>Methods: <\/b>We analyzed CT scans of 439 patients treated with ICI at 4 institutions (D1-D4) using the Picture Health Px platform. Experienced radiologists and physicians across institutions delineated target lesions on baseline CT scans. A deep learning model was used to segment pulmonary vessels. CheckpointPx v1.11, an interpretable neural network incorporating quantitative features extracted from within the tumor and its vasculature, was trained to predict ICI response (defined as disease control per RECIST best overall response) on n=247 patients (D1-D3). It was assessed with respect to response and progression free-survival (PFS) on 192 patients (D2-D4), with D4 (n=105) being an external validation set. CheckpointPx was also evaluated within PDL1 subsets among testing set patients where available (n=138).<br \/><b>Results: <\/b>The cohort was predominantly late stage (Stage 3\/4) (&#62;85%) and was mixed with respect to ICI line of treatment (1st-4th). 122 of 247 (49%) and 119 of 192 (62%) were responders in training and test cohorts respectively. CheckpointPx included 16 features, such as entropy-based heterogeneity and quantitative vessel tortuosity (twistedness). The model predicted response to ICI with an AUC=0.65 on the test set. The CheckpointPx High Risk group significantly stratified patients by PFS (HR=1.67 [1.22-2.28], p=0.001). This separation remained significant within the subset of PDL1-negative (HR=2.71 [1.35-5.44], p=0.005) and PDL1-positive patients (HR=2.05 [1.22-3.46], p=0.007).<br \/><b>Conclusions: <\/b>From baseline radiology, CheckpointPx was shown to strongly predict ICI outcomes across multiple institutions, NSCLC stages, and lines of ICI. Furthermore, the tool stratified patients by ICI benefit within both PDL1-positive and negative subsets - suggesting the potential of CheckpointPx to address critical gaps in the NSCLC biomarker landscape. CheckpointPx is driven by interpretable imaging biomarkers, and thus its predictions are tied to specific and quantifiable phenotypic attributes of the tumor and its microenvironment.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Lung cancer: non-small cell,Immune checkpoint blockade,Response,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>A. Hiremath<\/b><sup>1<\/sup>, S. Lee<sup>2<\/sup>, J. Lee<sup>2<\/sup>, P. Kim<sup>3<\/sup>, K. Zhang<sup>1<\/sup>, S. Lee<sup>4<\/sup>, M. Yadav<sup>5<\/sup>, M. Chuchuca<sup>5<\/sup>, T. Um<sup>5<\/sup>, M. Nam<sup>6<\/sup>, L.-Y. Chung<sup>5<\/sup>, H. Kim<sup>5<\/sup>, J. Yu<sup>7<\/sup>, T. Djunadi<sup>8<\/sup>, L. Kim<sup>9<\/sup>, Y. Oh<sup>10<\/sup>, S. Yoon<sup>5<\/sup>, Z. Shah<sup>11<\/sup>, Y. Kim<sup>5<\/sup>, I. Hong<sup>12<\/sup>, G. Kang<sup>12<\/sup>, J. Jang<sup>12<\/sup>, A. Cho<sup>12<\/sup>, S. Lee<sup>13<\/sup>, C. Nam<sup>12<\/sup>, T. Hong<sup>12<\/sup>, Y. S. Velichko<sup>5<\/sup>, A. Gupta<sup>14<\/sup>, V. Velcheti<sup>15<\/sup>, A. Madabhushi<sup>1<\/sup>, N. Braman<sup>1<\/sup>, Y. Chae<sup>5<\/sup>; <br\/><sup>1<\/sup>Picture Health, Cleveland, OH, <sup>2<\/sup>Kyungpook National Univeristy, Daegu, Korea, Republic of, <sup>3<\/sup>The University of Texas at Austin, Austin, TX, <sup>4<\/sup>School of Medicine at UCI, Irvine, CA, <sup>5<\/sup>Feinberg School Of Medicine, Northwestern University, Chicago, IL, <sup>6<\/sup>Lincoln Medical Center, Bronx, NY, USA, New York, NY, <sup>7<\/sup>Dignity Health - St. Rose Dominican Hospital, Henderson, NV, <sup>8<\/sup>Richmond University Medical Center, Staten Island, NY, <sup>9<\/sup>Ascension Saint Francis, Evanston, IL, <sup>10<\/sup>John H. Stroger, Jr. Hospital of Cook County, Chicago, IL, <sup>11<\/sup>Roswell Park Comprehensive Cancer Center, Buffalo, NY, <sup>12<\/sup>Northwestern University, Chicago, IL, <sup>13<\/sup>Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, <sup>14<\/sup>University Hospitals Cleveland Medical Center, Cleveland, OH, <sup>15<\/sup>Laura and Isaac, New York, NY","CSlideId":"","ControlKey":"52220932-de28-4a9f-a3db-1a2e9f519133","ControlNumber":"8112","DisclosureBlock":"<b>&nbsp;A. Hiremath, <\/b> <br><b>Picture Health<\/b> Employment, Stock, Patent.<br><b>S. Lee, <\/b> None..<br><b>J. Lee, <\/b> None..<br><b>P. Kim, <\/b> None.&nbsp;<br><b>K. Zhang, <\/b> <br><b>Picture Health<\/b> Employment, Stock. <br><b>Sirona Medical<\/b> Employment, Stock.<br><b>S. Lee, <\/b> None..<br><b>M. Yadav, <\/b> None..<br><b>M. Chuchuca, <\/b> None..<br><b>T. Um, <\/b> None..<br><b>M. Nam, <\/b> None..<br><b>L. Chung, <\/b> None..<br><b>H. Kim, <\/b> None..<br><b>J. Yu, <\/b> None..<br><b>T. Djunadi, <\/b> None..<br><b>L. Kim, <\/b> None..<br><b>Y. Oh, <\/b> None..<br><b>S. Yoon, <\/b> None..<br><b>Z. Shah, <\/b> None..<br><b>Y. Kim, <\/b> None..<br><b>I. Hong, <\/b> None..<br><b>G. Kang, <\/b> None..<br><b>J. Jang, <\/b> None..<br><b>A. Cho, <\/b> None..<br><b>S. Lee, <\/b> None..<br><b>C. Nam, <\/b> None..<br><b>T. Hong, <\/b> None..<br><b>Y. S. Velichko, <\/b> None.&nbsp;<br><b>A. Gupta, <\/b> <br><b>GE Healthcare<\/b> Financial Interests, Institutional, Funding, Research support for ongoing AI projects around chest radiography. <br><b>Picture Health<\/b> Stock. <br><b>V. Velcheti, <\/b> <br><b>ITeos Therapeutics<\/b> Advisory board. <br><b>Bristol Myers Squibb<\/b> Advisory board. <br><b>Merck<\/b> Advisory board. <br><b>AstraZeneca\/MedImmune<\/b> Advisory board. <br><b>GSK<\/b> Advisory board. <br><b>Amgen<\/b> Advisory board. <br><b>Elevation Oncology<\/b> Advisory board. <br><b>Merus<\/b> Advisory board. <br><b>Taiho Oncology<\/b> Advisory board. <br><b>Genentech<\/b> Institutional, Research Funding. <br><b>Trovagene<\/b> Institutional, Research Funding. <br><b>Eisai<\/b> Institutional, Research Funding. <br><b>OncoPlex Diagnostics<\/b> Institutional, Research Funding. <br><b>Alkermes<\/b> Institutional, Research Funding. <br><b>NantWorks<\/b> Institutional, Research Funding. <br><b>Genoptix<\/b> Institutional, Research Funding. <br><b>Altor BioScience<\/b> Institutional, Research Funding. <br><b>Atreca<\/b> Institutional, Research Funding. <br><b>Heat Biologics<\/b> Institutional, Research Funding. <br><b>Leap Therapeutics<\/b> Institutional, Research Funding. <br><b>A. Madabhushi, <\/b> <br><b>Picture Health<\/b> Stock, Patent. <br><b>Elucid Bioimaging<\/b> Stock. <br><b>Inspirata Inc<\/b> Stock. <br><b>SimBioSys<\/b> Other, Advisory Board. <br><b>AstraZeneca<\/b> Other, Sponsored research agreements. <br><b>Boehringer-Ingelheim<\/b> Other, Sponsored research agreements. <br><b>Eli-Lilly<\/b> Other, Sponsored research agreements. <br><b>Bristol Myers-Squibb.<\/b> Other, Sponsored research agreements. <br><b>Inspirata Inc<\/b> Grant\/Contract. <br><b>Frederick National Laboratory<\/b> Other, Advisory Committee. <br><b>N. Braman, <\/b> <br><b>Picture Health<\/b> Employment, Stock, Patent. <br><b>Tempus<\/b> Employment, Stock, Patent. <br><b>IBM Research<\/b> Employment, Stock, Patent. <br><b>Y. Chae, <\/b> <br><b>Picture Health Inc<\/b> Grant\/Contract. <br><b>Abbvie<\/b> Grant\/Contract. <br><b>BMS<\/b> Grant\/Contract. <br><b>Biodesix<\/b> Grant\/Contract. <br><b>Freenome<\/b> Grant\/Contract. <br><b>Predicine<\/b> Grant\/Contract. <br><b>Roche\/Genentech<\/b> Advisory board. <br><b>AstraZeneca<\/b> Advisory board. <br><b>Foundation Medicine<\/b> Advisory board. <br><b>Neogenomics<\/b> Advisory board. <br><b>Guardant Health<\/b> Advisory board. <br><b>Boehringher Ingelheim<\/b> Advisory board. <br><b>Biodesix<\/b> Advisory board. <br><b>Immuneoncia<\/b> Advisory board. <br><b>Lilly Oncology<\/b> Advisory board. <br><b>Merck<\/b> Advisory board. <br><b>Takeda<\/b> Advisory board. <br><b>Lunit<\/b> Advisory board. <br><b>Tempus<\/b> Advisory board. <br><b>BMS, Regeneron, NeoImmunTech, Esai<\/b> Advisory board.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9363","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"26","PosterboardNumber":"27","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"912","PresenterBiography":null,"PresenterDisplayName":"Amogh Hiremath","PresenterKey":"431d027b-6f1e-4312-b991-7e285361c06b","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"912. CheckpointPx, an interpretable radiology AI tool, predicts checkpoint blockade benefit independent of PDL1 status in non-small cell lung cancers (NSCLC): A multi-institutional validation study","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"CheckpointPx, an interpretable radiology AI tool, predicts checkpoint blockade benefit independent of PDL1 status in non-small cell lung cancers (NSCLC): A multi-institutional validation study","Topics":null,"cSlideId":""},{"Abstract":"Our goal was to study the spatial complexity of HPV negative OC by integrating scRNAseq and spatial transcriptomics from 11 samples including 5 from never smokers never drinkers (NSND). We used Turing Biosystems proprietary graph database engine and automated reasoning AI to analyze and model the cell-cell biochemical and cellular interactions in the TME. The tumors H&#38;E images, Visium 10X, and single cell 10X data were pre-processed using standard methods. QC-based genes and cells filtering, gene expression normalization, dimensionality reduction, clustering of Visium spots, and identification of spatially variable genes were performed. We generated multiple networks from tumor data and prior biological knowledge to integrate different layers of information: single-cell and spatial transcriptomics data, cell-cell interactions networks, cell neighboring, spatial correlation networks. We first used a novel network-based technique to identify the spatial distribution of any cell subtypes (e.g. CAF, T cells), by integrating differentially expressed genes from scRNAseq, prior knowledge and prior data (e.g. TCGA). We used a multilayer network approach to integrate the different networks of data and an automated reasoning AI analysis which allows to interpret the results based on a reasoning on biological and clinical knowledge in opposition to machine learning methods based on statistical patterns. We identified CAFs\/T cells\/IFN-g to be strongly correlated within the tumor islets interacting with the stroma in NSND while they were more correlated within the stromal regions in smokers.<b> <\/b>We also identified 2 or 3 subtypes of tumor islets areas based on their functional states (e.g., immune pathways activated or metabolic differences), allowing us to unravel a more detailed map of the intratumoral heterogeneity when compared to histopathology annotations.<b> <\/b>In order to get some insights into the functional impact of the spatial distribution of cells,<b> <\/b>the tumors were then represented as multilayer networks to identify all possible cell-cell interactions in the TME. This was followed by a spatial simulation of these interactions using logic (e.g., inhibition, activation) and correlative (e.g., gene expression, imaging features correlations) interactions in the networks to identify spatial interactions. From that we analysed all the possible known protein-protein and metabolite-protein interactions between the cell types analysed and mapped the tumors with the gene expressions corresponding to the pairs of interacting proteins (or enzymes linked to metabolites). We found an interaction between CAF and Tregs via CXCL12 (CAFs) and CXCR4 (Tregs). In conclusion, automated reasoning AI integrating scRNAseq and spatial transcriptomics allows an in-depth analysis of cells spatial distribution and its functional impact in OC.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Cancer associated fibroblasts,Stromal-epithelial interactions,Tumor microenvironment,Squamous cell carcinoma,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"K. Mahtouk<sup>1<\/sup>, M. Vincent<sup>2<\/sup>, Y. Le Meitour<sup>1<\/sup>, B. Vanbervliet-Defrance<sup>1<\/sup>, S. Canjura<sup>1<\/sup>, C. Degletagne<sup>1<\/sup>, L. Tonon<sup>3<\/sup>, L. Michon<sup>1<\/sup>, J. Bouaoud<sup>1<\/sup>, A. Excoffier<sup>3<\/sup>, P. Zrounba<sup>3<\/sup>, R. Boutonnet<sup>2<\/sup>, A. Amara<sup>2<\/sup>, <b>P. Saintigny<\/b><sup>3<\/sup>; <br\/><sup>1<\/sup>Cancer Research Center of Lyon, Lyon, France, <sup>2<\/sup>Turing Biosystems, Lyon, France, <sup>3<\/sup>Center Léon Bérard, Lyon, France","CSlideId":"","ControlKey":"84fe66cf-a7ce-4d2a-aea6-adf2c93aca85","ControlNumber":"8198","DisclosureBlock":"&nbsp;<b>K. Mahtouk, <\/b> None.&nbsp;<br><b>M. Vincent, <\/b> <br><b>Turing Biosystems<\/b> Employment.<br><b>Y. Le Meitour, <\/b> None..<br><b>B. Vanbervliet-Defrance, <\/b> None..<br><b>S. Canjura, <\/b> None..<br><b>C. Degletagne, <\/b> None..<br><b>L. Tonon, <\/b> None..<br><b>L. Michon, <\/b> None..<br><b>J. Bouaoud, <\/b> None..<br><b>A. Excoffier, <\/b> None..<br><b>P. Zrounba, <\/b> None.&nbsp;<br><b>R. Boutonnet, <\/b> <br><b>Turing Biosystems<\/b> Employment. <br><b>A. Amara, <\/b> <br><b>Turing Biosystems<\/b> Employment. <br><b>P. Saintigny, <\/b> <br><b>Turing Biosystems<\/b> Grant\/Contract.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9364","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"27","PosterboardNumber":"28","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"913","PresenterBiography":null,"PresenterDisplayName":"Pierre Saintigny, MD;PhD","PresenterKey":"cdec0acb-3122-4a27-bb0f-d369994b376e","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"913. Automated reasoning artificial intelligence (AI) to model the cell-cell biochemical and cellular interactions in the tumor microenvironment (TME) of oral cancer (OC)","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Automated reasoning artificial intelligence (AI) to model the cell-cell biochemical and cellular interactions in the tumor microenvironment (TME) of oral cancer (OC)","Topics":null,"cSlideId":""},{"Abstract":"An emerging predictive parameter of immunotherapy response is the patient&#8217;s tumor immune status, generally classified as &#8220;inflamed&#8221;, \"immune excluded&#8221; and &#8220;desert&#8221;. Historically, classification was performed semi-quantitatively with somewhat subjective parameters as evidenced by the recent Delphi Workshop consensus. There are a variety of approaches to classifying immune status, most based upon analysis of H&#38;E images (counting tumor infiltrating lymphocytes, TILs), or counting subpopulations of immune cells using immunologic staining. However, use of multiplexed or multiple stains has recently been explored to better quantify the counts and types of immune cells in individual tissue compartments. While the immune microenvironment represents an important parameter in predicting patient response, other regions such as the extracellular matrix (ECM) may yield complementary information, as collagen-rich ECMs may present a barrier to drug diffusion and the orientation of fibers may direct the migration of malignant cells.<br \/>Here we present a proof of concept virtual staining enhanced image analysis pipeline, which converts autofluorescence signals from a single tissue section into virtual H&#38;E and Masson&#8217;s Trichrome along with virtual detection of pan cytokeratin (AE1\/AE3\/PCK26) and CD45 (LCA) positive cells. We apply image analysis to the panel of virtual stains to study the spatial and case-by-case heterogeneity of tumor collagen frameworks and immune phenotype.<br \/>Using a standard slide scanner (Axio Scan Z1, Zeiss), multiple autofluorescence images were captured from unstained sections (4-6um thick) of lung tissue. The virtual staining was performed by four deep neural networks trained in a supervised learning fashion. Select chemical stains were performed on previously scanned tissues and reviewed by pathologists side-by-side with virtual stains to ensure consistency and quality control. Four perfectly registered WSI virtual stain images were generated from each tissue section. The multi-stain results were rendered from a variety of lung cancers, including tissue microarray slides. Image analysis was performed using HALO (Indica Labs) and custom python scripts. We identified unique areas of tumor and adjacent stroma with heterogeneous immune phenotype and collagen characteristics, suggesting that an interplay might exist that could be utilized to improve patient selection or prognosis when deploying advanced AI tools. Future work includes applying this virtual stain technique retrospectively to cases with known immunotherapy treatment responses to determine the prognostic significance of the combined immune\/ECM phenotype.","Actions":[{"Icon":null,"Label":"View Abstract","SubType":null,"Type":"ViewAbstract","Url":null}],"Activity":"Abstract Submission","AdditionalFields":[{"Key":"Topics","Value":"++BCS01-03 Artificial intelligence and machine\/deep learning,,"},{"Key":"Keywords","Value":"Machine learning,Immunotherapy,Fluorescence imaging,Predictive biomarkers,"},{"Key":"ePosterClassification","Value":""},{"Key":"ePosterNote","Value":""},{"Key":"VideoType","Value":""},{"Key":"cSlidePresentationId","Value":""},{"Key":"ePosterLink","Value":""},{"Key":"WebcastProgramPlannerLink","Value":""}],"AdditionalFiles":null,"AllowAttendeeRating":null,"AttendeeRatingAvg":null,"AttendeeRatingCount":null,"AuthorBlock":"<b>S. Alexanian<\/b>, Y. Rivenson, N. Xuan, B. Cone, Z. Fang, S. Meyering, L. A. V. Carvalho, D. Palacios, R. Kozikowski; <br\/>Pictor Labs, Inc., Los Angeles, CA","CSlideId":"","ControlKey":"21469dc5-4e56-4c8f-b9cd-74cf3dbdcc38","ControlNumber":"8404","DisclosureBlock":"<b>&nbsp;S. Alexanian, <\/b> <br><b>Agilent Technologies<\/b> Independent Contractor. <br><b>Bristol-Myers Squibb<\/b> Independent Contractor. <br><b>CompuMed<\/b> Independent Contractor. <br><b>Incyte<\/b> Independent Contractor. <br><b>Indica Labs<\/b> Independent Contractor. <br><b>Leica Bioscience<\/b> Independent Contractor. <br><b>Merck KGaA Healthcare<\/b> Independent Contractor. <br><b>Roche Diagnostics<\/b> Independent Contractor. <br><b>Sellas Life Sciences<\/b> Independent Contractor. <br><b>Stemline Therapeutics<\/b> Independent Contractor. <br><b>Transcenta Therapeutics<\/b> Independent Contractor.<br><b>Y. Rivenson, <\/b> None..<br><b>N. Xuan, <\/b> None.&nbsp;<br><b>B. Cone, <\/b> <br><b>Agilent Technologies<\/b> Independent Contractor. <br><b>Incyte<\/b> Independent Contractor. <br><b>Roche Tissue Diagnostics<\/b> Employment.<br><b>Z. Fang, <\/b> None..<br><b>S. Meyering, <\/b> None..<br><b>L. A. V. Carvalho, <\/b> None..<br><b>D. Palacios, <\/b> None..<br><b>R. Kozikowski, <\/b> None.","End":"4\/7\/2024 5:00:00 PM","HasWebcast":null,"Highlights":[],"Id":"9365","IsPresentation":"True","IsSessionOrganizer":"False","Keywords":null,"MediaSource":null,"OtherContent":null,"PlayerUrl":null,"PlayerUrlReason":"cslide-player-enabled is not true","PositionInSession":"28","PosterboardNumber":"29","PresentationFiles":null,"PresentationMediaItemId":null,"PresentationMediaItemKey":null,"PresentationNumber":"914","PresenterBiography":null,"PresenterDisplayName":"Serge Alexanian, MD","PresenterKey":"1ac8905f-f9a9-4378-b8c0-497c02b874d4","PresenterPhoto":null,"SearchResultActions":null,"SearchResultBody":"914. Combination analysis of tumor-associated collagen frameworks and tumor immune phenotype of lung carcinomas using virtual staining","SearchResultFooter":"","SearchResultHeader":"Apr  7 2024  1:30PM","SessionId":"193","SessionOnDemand":"False","SessionTitle":"Artificial Intelligence and Machine\/Deep Learning 1","ShowChatLink":"false","Start":"4\/7\/2024 1:30:00 PM","Status":"Presenting","Tags":null,"ThumbnailUrl":null,"Title":"Combination analysis of tumor-associated collagen frameworks and tumor immune phenotype of lung carcinomas using virtual staining","Topics":null,"cSlideId":""}]